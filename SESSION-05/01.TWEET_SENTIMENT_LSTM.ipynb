{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01.TWEET_SENTIMENT_LSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPkaCHG3xEoY2GZ/sZzfNeo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TrUN7oJhPm0a"},"source":["#CONNECT TO GOOGLE DRIVE "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhLd364XQheP","executionInfo":{"status":"ok","timestamp":1622952136299,"user_tz":-330,"elapsed":27718,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"2616509c-cec5-412d-d68c-0f0036e94ed8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1WZNhoYIfxEH"},"source":["## Dataset Preview\n","\n","Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"887K2KziQigM","executionInfo":{"status":"ok","timestamp":1622952136982,"user_tz":-330,"elapsed":692,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"eee66a41-6f72-467d-c45c-280e96dd8005"},"source":["#READ TWEETS.CSV \n","\n","import pandas as pd \n","path='/content/drive/MyDrive/ENDB2/SESSION_05/data_weights/'\n","df=pd.read_csv(path+'tweets.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweets</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Obama has called the GOP budget social Darwini...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>In his teen years, Obama has been known to use...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>IPA Congratulates President Barack Obama for L...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>RT @wardollarshome: Obama has approved more ta...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              tweets  labels\n","0  Obama has called the GOP budget social Darwini...       1\n","1  In his teen years, Obama has been known to use...       0\n","2  IPA Congratulates President Barack Obama for L...       0\n","3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n","4  RT @wardollarshome: Obama has approved more ta...       1"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHSt9tXnRBs2","executionInfo":{"status":"ok","timestamp":1622952136985,"user_tz":-330,"elapsed":29,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"25482414-7fe3-4c9e-b4b6-c89c3ba8f631"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1364, 2)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQ-piRX5SlPC","executionInfo":{"status":"ok","timestamp":1622952136987,"user_tz":-330,"elapsed":24,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"3bc9f6ee-5ab1-4dca-b0c6-1c6e6704b12a"},"source":["df.labels.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    931\n","1    352\n","2     81\n","Name: labels, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45TxrtX5SpTp","executionInfo":{"status":"ok","timestamp":1622952140757,"user_tz":-330,"elapsed":3787,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"bb3e56b1-7508-46f8-a8d7-e5a84af3715b"},"source":["# Import Library\n","import random\n","import torch, torchtext\n","from torchtext import data \n","\n","# Manual Seed\n","SEED = 43\n","torch.manual_seed(SEED)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f6e2a009330>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"P0R8SmNkOHAo"},"source":["#CREATE FIELD :HOW DATA IS PROCESSED "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHySnMQZOiYr"},"source":["Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n","Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-f5uO65XRSF"},"source":["fields = [('tweet', Tweet), ('label', Label)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5UE_GuzhYl5e"},"source":["example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hxyC1MOdVXXS","executionInfo":{"status":"ok","timestamp":1622952176823,"user_tz":-330,"elapsed":101,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"781a13de-700c-40b4-fe2e-e9fbaee557ec"},"source":["example[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torchtext.legacy.data.example.Example at 0x7f6dd3418690>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"KsxmVLp2YoEv"},"source":["twitterDataset = torchtext.legacy.data.Dataset(example, fields)\n","# ALTERNATE APPROACH \n","#twitterDataset = data.TabularDataset(path=path+\"tweets.csv\", format=\"CSV\", fields=fields, skip_header=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohTDLkNoZsSu"},"source":["(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fCntCYMZzYF","executionInfo":{"status":"ok","timestamp":1622952176827,"user_tz":-330,"elapsed":89,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"c4d51aba-0e55-4804-8c2f-c714e019a0de"},"source":["len(train), len(valid)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1159, 205)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LetlwfVmZ4-q","executionInfo":{"status":"ok","timestamp":1622952176828,"user_tz":-330,"elapsed":84,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"1ab54f43-ac20-4081-8f1a-6669234d18b0"},"source":["vars(train.examples[11])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': 1,\n"," 'tweet': ['@sweetbay',\n","  'That',\n","  'was',\n","  'Paul',\n","  'Ryan',\n","  \"'s\",\n","  'budget',\n","  '.',\n","  'How',\n","  'did',\n","  'Obama',\n","  \"'s\",\n","  'budget',\n","  'do',\n","  '?',\n","  'Getting',\n","  'educated',\n","  'on',\n","  'the',\n","  'facts',\n","  'is',\n","  'the',\n","  'first',\n","  'step',\n","  'in',\n","  'losing',\n","  'that',\n","  'liberalism',\n","  '!']}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"6klZETccZ8YF"},"source":["#Build vocabulary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhLPPWsCadqn"},"source":["Tweet.build_vocab(train)\n","Label.build_vocab(train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlctgnQnagwc","executionInfo":{"status":"ok","timestamp":1622952176832,"user_tz":-330,"elapsed":77,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"6f55ca37-2e74-4e2d-e9aa-a5d9908654a1"},"source":["print('Size of input vocab : ', len(Tweet.vocab))\n","print('Size of label vocab : ', len(Label.vocab))\n","print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n","print('Labels : ', Label.vocab.stoi)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size of input vocab :  4651\n","Size of label vocab :  3\n","Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n","Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-ZHYJ1tajd8","executionInfo":{"status":"ok","timestamp":1622952176834,"user_tz":-330,"elapsed":71,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"5099ef6e-3527-44a8-be58-5416ec737cb9"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"5sgMzYcwanne"},"source":["train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = 32, \n","                                                            sort_key = lambda x: len(x.tweet),\n","                                                            sort_within_batch=True, device = device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nf5dL5eedXb1","executionInfo":{"status":"ok","timestamp":1622952187767,"user_tz":-330,"elapsed":10997,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"0ba3ba41-a593-49dd-d538-c3c83075fc44"},"source":["next(iter(train_iterator))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\n","[torchtext.legacy.data.batch.Batch of size 32]\n","\t[.tweet]:('[torch.cuda.LongTensor of size 32x8 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n","\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"w_y7NGIuR3QZ"},"source":["import os, pickle\n","with open(path+'tokenizer.pkl', 'wb') as tokens: \n","    pickle.dump(Tweet.vocab.stoi, tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_bIZ3mth2qm"},"source":["## DEFINING OUR MODEL \n","\n","We use the Embedding and LSTM modules in PyTorch to build a simple model for classifying tweets.\n","\n","In this model we create three layers. \n","1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n","2. That’s then fed into a 2 stacked-LSTMs with 100 hidden features (again, we’re compressing down from the 300-dimensional input like we did with images). We are using 2 LSTMs for using the dropout.\n","3. Finally, the output of the LSTM (the final hidden state after processing the incoming tweet) is pushed through a standard fully connected layer with three outputs to correspond to our three possible classes (negative, positive, or neutral)."]},{"cell_type":"code","metadata":{"id":"t36SCE4lgooi"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class classifier(nn.Module):\n","    \n","    # Define all the layers used in model\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n","        \n","        super().__init__()          \n","        \n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        # LSTM layer\n","        self.encoder = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           dropout=dropout,\n","                           batch_first=True)\n","        # try using nn.GRU or nn.RNN here and compare their performances\n","        # try bidirectional and compare their performances\n","        \n","        # Dense layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        # text = [batch size, sent_length]\n","        embedded = self.embedding(text)\n","        # embedded = [batch size, sent_len, emb dim]\n","      \n","        # packed sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n","        \n","        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n","        #hidden = [batch size, num layers * num directions,hid dim]\n","        #cell = [batch size, num layers * num directions,hid dim]\n","    \n","        # Hidden = [batch size, hid dim * num directions]\n","        dense_outputs = self.fc(hidden)   \n","        \n","        # Final activation function softmax\n","        output = F.softmax(dense_outputs[0], dim=1)\n","            \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-gC4gGlAgw6J"},"source":["# Define hyperparameters\n","size_of_vocab = len(Tweet.vocab)\n","embedding_dim = 300\n","num_hidden_nodes = 100\n","num_output_nodes = 3\n","num_layers = 2\n","dropout = 0.2\n","\n","# Instantiate the model\n","model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPoe0W5lhaRb","executionInfo":{"status":"ok","timestamp":1622952188532,"user_tz":-330,"elapsed":23,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"898b944c-975f-43e5-cdd9-c32b007f07f1"},"source":["print(model)\n","\n","#No. of trianable parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    \n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["classifier(\n","  (embedding): Embedding(4651, 300)\n","  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n","  (fc): Linear(in_features=100, out_features=3, bias=True)\n",")\n","The model has 1,637,203 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IH0a-lR_hhR1"},"source":["import torch.optim as optim\n","\n","# define optimizer and loss\n","optimizer = optim.Adam(model.parameters(), lr=2e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# define metric\n","def binary_accuracy(preds, y):\n","    #round predictions to the closest integer\n","    _, predictions = torch.max(preds, 1)\n","    \n","    correct = (predictions == y).float() \n","    acc = correct.sum() / len(correct)\n","    return acc\n","    \n","# push to cuda if available\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STvkNIBvibMQ"},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    # initialize every epoch \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    # set the model in training phase\n","    model.train()  \n","    \n","    for batch in iterator:\n","        \n","        # resets the gradients after every batch\n","        optimizer.zero_grad()   \n","        \n","        # retrieve text and no. of words\n","        tweet, tweet_lengths = batch.tweet  \n","        \n","        # convert to 1D tensor\n","        predictions = model(tweet, tweet_lengths).squeeze()  \n","        \n","        # compute the loss\n","        loss = criterion(predictions, batch.label)        \n","        \n","        # compute the binary accuracy\n","        acc = binary_accuracy(predictions, batch.label)   \n","        \n","        # backpropage the loss and compute the gradients\n","        loss.backward()       \n","        \n","        # update the weights\n","        optimizer.step()      \n","        \n","        # loss and accuracy\n","        epoch_loss += loss.item()  \n","        epoch_acc += acc.item()    \n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FarrOPhib7h"},"source":["def evaluate(model, iterator, criterion):\n","    \n","    # initialize every epoch\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    # deactivating dropout layers\n","    model.eval()\n","    \n","    # deactivates autograd\n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","        \n","            # retrieve text and no. of words\n","            tweet, tweet_lengths = batch.tweet\n","            \n","            # convert to 1d tensor\n","            predictions = model(tweet, tweet_lengths).squeeze()\n","            \n","            # compute loss and accuracy\n","            loss = criterion(predictions, batch.label)\n","            acc = binary_accuracy(predictions, batch.label)\n","            \n","            # keep track of loss and accuracy\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcfcERc5iiHJ","executionInfo":{"status":"ok","timestamp":1622952191868,"user_tz":-330,"elapsed":3351,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"b831a7de-c315-4f5c-9f6a-95aed6348a33"},"source":["N_EPOCHS = 10\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","     \n","    # train the model\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    \n","    # evaluate the model\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    # save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), path+'saved_weights.pt')\n","    \n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\tTrain Loss: 1.068 | Train Acc: 50.58%\n","\t Val. Loss: 1.014 |  Val. Acc: 58.93% \n","\n","\tTrain Loss: 0.994 | Train Acc: 64.82%\n","\t Val. Loss: 0.951 |  Val. Acc: 65.18% \n","\n","\tTrain Loss: 0.930 | Train Acc: 68.53%\n","\t Val. Loss: 0.900 |  Val. Acc: 67.86% \n","\n","\tTrain Loss: 0.869 | Train Acc: 72.42%\n","\t Val. Loss: 0.856 |  Val. Acc: 72.77% \n","\n","\tTrain Loss: 0.824 | Train Acc: 75.04%\n","\t Val. Loss: 0.836 |  Val. Acc: 75.00% \n","\n","\tTrain Loss: 0.794 | Train Acc: 78.08%\n","\t Val. Loss: 0.818 |  Val. Acc: 75.89% \n","\n","\tTrain Loss: 0.774 | Train Acc: 78.97%\n","\t Val. Loss: 0.809 |  Val. Acc: 75.89% \n","\n","\tTrain Loss: 0.759 | Train Acc: 80.49%\n","\t Val. Loss: 0.802 |  Val. Acc: 76.79% \n","\n","\tTrain Loss: 0.743 | Train Acc: 82.01%\n","\t Val. Loss: 0.796 |  Val. Acc: 77.23% \n","\n","\tTrain Loss: 0.729 | Train Acc: 83.28%\n","\t Val. Loss: 0.792 |  Val. Acc: 77.23% \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aANS4I7DcDH_"},"source":["#LOADING MODEL AND TOKENIZER \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4kWmJ8Qbd7d3"},"source":["#load weights and tokenizer\n","\n","model_path=path+'/saved_weights.pt'\n","model.load_state_dict(torch.load(model_path));\n","model.eval();\n","tokenizer_file = open(path+'./tokenizer.pkl', 'rb')\n","tokenizer = pickle.load(tokenizer_file)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFn6uUWKeJoI"},"source":["#INFERENCING :\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ouYAbSr8eViT"},"source":["import spacy\n","nlp = spacy.load('en')\n","\n","def classify_tweet(tweet):\n","    \n","    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n","    \n","    # tokenize the tweet \n","    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n","    # convert to integer sequence using predefined tokenizer dictionary\n","    indexed = [tokenizer[t] for t in tokenized]        \n","    # compute no. of words        \n","    length = [len(indexed)]\n","    # convert to tensor                                    \n","    tensor = torch.LongTensor(indexed).to(device)   \n","    # reshape in form of batch, no. of words           \n","    tensor = tensor.unsqueeze(1).T  \n","    # convert to tensor                          \n","    length_tensor = torch.LongTensor(length)\n","    # Get the model prediction                  \n","    prediction = model(tensor, length_tensor)\n","\n","    _, pred = torch.max(prediction, 1) \n","    \n","    return categories[pred.item()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zIHPmJTDeeuk","executionInfo":{"status":"ok","timestamp":1622952192498,"user_tz":-330,"elapsed":29,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"da23f688-2833-4f2d-b9c3-a325aed061ec"},"source":["classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Positive'"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"FUEvkjmaelEX"},"source":["# DATA AUGMENTATION "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xnai2jS203J_"},"source":["## Discussion on Data Augmentation Techniques \n","\n","You might wonder exactly how you can augment text data. After all, you can’t really flip it horizontally as you can an image! :D \n","\n","In contrast to data augmentation in images, augmentation techniques on data is very specific to final product you are building. As its general usage on any type of textual data doesn't provides a significant performance boost, that's why unlike torchvision, torchtext doesn’t offer a augmentation pipeline. Due to powerful models as transformers, augmentation tecnhiques are not so preferred now-a-days. But its better to know about some techniques with text that will provide your model with a little more information for training. \n"]},{"cell_type":"markdown","metadata":{"id":"G4CUGCRK0gjC"},"source":[""]},{"cell_type":"code","metadata":{"id":"An_DzCfn0d5s"},"source":["# BACK TRANSLATE "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jh_E57ME0stb"},"source":["### Back Translation\n","\n","Another popular approach for augmenting text datasets is back translation. This involves translating a sentence from our target language into one or more other languages and then translating all of them back to the original language. We can use the Python library googletrans for this purpose. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":491},"id":"sHYz6-v10jbh","executionInfo":{"status":"error","timestamp":1622959406511,"user_tz":-330,"elapsed":2764,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"b755e886-5423-43dd-bee5-a98dccef87d3"},"source":["!pip install googletrans\n","\n","import random\n","import googletrans\n","from googletrans import Translator\n","\n","translator = Translator()\n","sentence = ['this is dog']\n","\n","available_langs = list(googletrans.LANGUAGES.keys()) \n","trans_lang = random.choice(available_langs) \n","print(trans_lang)\n","print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")\n","\n","translations = translator.translate(sentence, dest=trans_lang) \n","t_text = [t.text for t in translations]\n","print(t_text)\n","\n","translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n","en_text = [t.text for t in translations_en_random]\n","print(en_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: googletrans in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletrans) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->googletrans) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->googletrans) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->googletrans) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->googletrans) (2.10)\n","uk\n","Translating to ukrainian\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9ebea8ca3139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Translating to {googletrans.LANGUAGES[trans_lang]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# this code will be updated when the format is changed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_acquirer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         params = utils.build_params(query=text, src=src, dest=dest,\n\u001b[1;32m     77\u001b[0m                                     token=token)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# this will be the same as python code after stripping out a reserved word 'var'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRE_TKK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# unescape special ascii characters such like a \\x3d(=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"]}]},{"cell_type":"markdown","metadata":{"id":"1RsxDM_j0h1a"},"source":[""]}]}