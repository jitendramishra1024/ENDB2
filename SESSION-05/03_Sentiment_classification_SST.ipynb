{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03.Sentiment_classification_SST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEP5ZQ6OqPoF",
        "outputId": "50241474-f416-4e13-be73-66d796f68d07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLVcpnSc29kJ"
      },
      "source": [
        "#ref \n",
        "#https://github.com/garima-mahato/END2/blob/main/Session5-FirstHands-on/Sentiment_Analysis_using_LSTM_RNN.ipynb"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6bNkrXLpvvv"
      },
      "source": [
        "path='/content/drive/MyDrive/ENDB2/SESSION_05/data_weights/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dn1fCqWnXfQ",
        "outputId": "21627ef9-5d77-4000-b034-89fc333c169b"
      },
      "source": [
        "#Install pytreebank\n",
        "! pip install pytreebank==0.2.7\n",
        "! pip install google_trans_new\n",
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytreebank==0.2.7 in /usr/local/lib/python3.7/dist-packages (0.2.7)\n",
            "Requirement already satisfied: google_trans_new in /usr/local/lib/python3.7/dist-packages (1.1.9)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omFPfgvqpaHc"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2mSIqwapank"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzXOcWCTsUrf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext.legacy\n",
        "from torchtext import datasets\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "import pytreebank\n",
        "\n",
        "import google_trans_new \n",
        "from google_trans_new import google_translator  \n",
        "import random\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os, pickle"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_mzC9Gcsml4"
      },
      "source": [
        "#GET DATASET\n",
        "dataset = pytreebank.load_sst()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6chTSS_uuc7A",
        "outputId": "91edc3e6-2db4-4324-d0f5-ab42562ba55d"
      },
      "source": [
        "#SEE ONE LABEL AND TEXT OF TRAIN DATASET \n",
        "dataset['train'][0].to_labeled_lines()[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKnFo2GVuqMn"
      },
      "source": [
        "#LETS SEPARATE TRAIN AND TEST \n",
        "data_train = [example.to_labeled_lines()[0] for example in dataset[\"train\"]]\n",
        "data_test = [example.to_labeled_lines()[0] for example in dataset[\"test\"]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYW3C2J1vuO-",
        "outputId": "644f0f20-2259-4cbb-e84c-336f341bc85a"
      },
      "source": [
        "len(data_train), len(data_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 2210)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8lwdup3vx32"
      },
      "source": [
        "train = pd.DataFrame(data_train, columns = ['label', 'sentence'])\n",
        "test = pd.DataFrame(data_test, columns = ['label', 'sentence'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "h2s1c2f4wFlr",
        "outputId": "326d8d8e-d195-4b25-8e63-7ce564178770"
      },
      "source": [
        "\n",
        "train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      3  The Rock is destined to be the 21st Century 's...\n",
              "1      4  The gorgeously elaborate continuation of `` Th...\n",
              "2      3  Singer/composer Bryan Adams contributes a slew...\n",
              "3      2  You 'd think by now America would have had eno...\n",
              "4      3               Yet the act is still charming here ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "VDo_u_JWwI68",
        "outputId": "a16203b9-fab3-45be-dff2-bee9cc182efe"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      2                     Effective but too-tepid biopic\n",
              "1      3  If you sometimes like to go to the movies to h...\n",
              "2      4  Emerges as something rare , an issue movie tha...\n",
              "3      2  The film provides some great insight into the ...\n",
              "4      4  Offers that rare combination of entertainment ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hYsmhEsZReO",
        "outputId": "94abe7b2-dc58-4d82-8972-3c6730a995b6"
      },
      "source": [
        "len(train),len(test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 2210)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp-M27E5Zxc7"
      },
      "source": [
        "# AUGMENTATION STRATEGY \n",
        "# WE WILL APPLY BELOW 4 AUGMENTATION STRATEGY \n",
        "# RANDOM INSERT (5%)\n",
        "# RANDOM DELETE (5%)\n",
        "# RANDOM SWAP   (20%)\n",
        "# BACK TRANSLATE (70%)\n",
        "# we will chnage the ratio in later phase "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZIknJU_jVit"
      },
      "source": [
        "#BACK TRANSLATE \n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWDm2Oikd1LJ"
      },
      "source": [
        "def back_translate(sentence):\n",
        "  \"\"\" Google translate the input sentence and translate back\"\"\"\n",
        "  available_langs = list(google_trans_new.LANGUAGES.keys()) \n",
        "  trans_lang = random.choice(available_langs) \n",
        "  translator = google_translator()  \n",
        "  translate_text = translator.translate(sentence,lang_tgt=trans_lang) \n",
        "  translate_back = translator.translate(translate_text,lang_tgt='en')\n",
        "  return (translate_back)\n",
        "\n",
        "# #TEST \n",
        "# result= back_translate('India has recently overtaken the US in terms of the number of people who have received at least one dose of the Covid vaccine')\n",
        "# print(result)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5lJpAl5kN9t"
      },
      "source": [
        "# RANDOM DELETE "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spTIVrPikr7p",
        "outputId": "b7380b56-0df7-44ae-cf24-c8c4acb58bac"
      },
      "source": [
        "def random_deletion(sentence, p=0.5): \n",
        "    words = sentence.split()\n",
        "    if len(words) == 1: # return if single word\n",
        "        return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)] \n",
        "    else:\n",
        "        return (' '.join(remaining))\n",
        "\n",
        "#TEST \n",
        "result= random_deletion('India has recently overtaken the US in terms of the number of people who have received at least one dose of the Covid vaccine')\n",
        "print(result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "has overtaken the terms the of received least dose of the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92jy77NHlAUL"
      },
      "source": [
        "# RANDOM SWAp\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVMuIiwPlXnW",
        "outputId": "1da9c59d-3fe3-4efe-da89-97a4297104da"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    words = sentence.split()\n",
        "    if len(words) == 1: # return if single word\n",
        "        return words\n",
        "    length = range(len(words)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        words[idx1], words[idx2] = words[idx2], words[idx1] \n",
        "    return (' '.join(words))\n",
        "\n",
        "#TEST \n",
        "result= random_swap('India has recently overtaken the US in terms of the number of people who have received at least one dose of the Covid vaccine')\n",
        "print(result)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "US has recently overtaken of India in terms of of number received dose who have the at least one people the the Covid vaccine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOvcaiR3lii8"
      },
      "source": [
        "# RANDOM INSERT"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc_Q81z_nXgU",
        "outputId": "ba6ad90c-6734-4143-acce-67bf104be6c6"
      },
      "source": [
        "def remove_stopwords(sentence):\n",
        "    from nltk.corpus import stopwords\n",
        "    tokenized = sentence #custom_tokenize(sentence) #data['text'].apply(custom_tokenize) # Tokenize tweets\n",
        "    lower_tokens = [t.lower() for t in tokenized] #tokenized.apply(lambda x: [t.lower() for t in x]) # Convert tokens into lower case\n",
        "    alpha_only = [t for t in lower_tokens if t.isalpha()] #lower_tokens.apply(lambda x: [t for t in x if t.isalpha()]) # Remove punctuations\n",
        "    no_stops = [t for t in alpha_only if t not in stopwords.words('english')] #alpha_only.apply(lambda x: [t for t in x if t not in stopwords.words('english')]) # remove stop words\n",
        "\n",
        "    return no_stops\n",
        "\n",
        "def get_synonyms(word):\n",
        "    import nltk\n",
        "    from nltk.corpus import wordnet\n",
        "    synonyms = []\n",
        "      \n",
        "    for syn in wordnet.synsets(word):\n",
        "        for l in syn.lemmas():\n",
        "            synonyms.append(l.name())\n",
        "            # if l.antonyms():\n",
        "            #     antonyms.append(l.antonyms()[0].name())\n",
        "    synonyms = list(set(synonyms))\n",
        "    if len(synonyms) > 0:\n",
        "      new_synonym = random.choice(synonyms)\n",
        "    else:\n",
        "      new_synonym = word\n",
        "\n",
        "    return new_synonym\n",
        "def random_insertion(sentence, n=4): \n",
        "    from random import randrange\n",
        "    sentence= sentence.split()\n",
        "    words = remove_stopwords(sentence) \n",
        "    if len(words)<=0:\n",
        "      words = sentence\n",
        "    for _ in range(n):\n",
        "        word = random.choice(words)\n",
        "        new_synonym = get_synonyms(word)\n",
        "        sentence.insert(randrange(len(sentence)+1), new_synonym)\n",
        "    return \" \".join(sentence)\n",
        "\n",
        "#TEST \n",
        "result= random_insertion('India has recently overtaken the US in terms of the number of people who have received at least one dose of the Covid vaccine')\n",
        "print(result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "India has recently overtaken vaccinum the US in terms of the number of vaccine people who have received at least one dose late uracil of the Covid vaccine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roMgzRb8n-23"
      },
      "source": [
        "BACK_TRANSLATE_FRACTION = 0.10\n",
        "RANDOM_INSERT_FRACTION = 0.9\n",
        "RANDOM_DELETE_FRACTION = 0.05\n",
        "RANDOM_SWAP_FRACTION =0.3\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZVA2u0xhr9J",
        "outputId": "642adfab-8889-4e9b-9a47-2df50ef41725"
      },
      "source": [
        "df_bt=train.sample(frac=BACK_TRANSLATE_FRACTION)\n",
        "df_bt['sentence'] = df_bt['sentence'].apply(lambda x: back_translate(x))\n",
        "len(train),len(df_bt)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 854)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVuuu3mfh9OR",
        "outputId": "861c4eeb-a08e-4faf-898f-e674b652a0e0"
      },
      "source": [
        "df_ri=train.sample(frac=RANDOM_INSERT_FRACTION)\n",
        "df_ri['sentence'] = df_ri['sentence'].apply(lambda x: random_insertion(x))\n",
        "len(train),len(df_ri)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 7690)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ4TcpUejMIu",
        "outputId": "2649a49a-488f-490f-9d8f-ddb535d7598c"
      },
      "source": [
        "df_rd=train.sample(frac=RANDOM_DELETE_FRACTION)\n",
        "df_rd['sentence'] = df_rd['sentence'].apply(lambda x: random_deletion(x))\n",
        "len(train),len(df_rd)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 427)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emv9u-rYp8Fx"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bku94HRcjpFr",
        "outputId": "ad218964-e7d6-42d0-e0a1-656d610c6694"
      },
      "source": [
        "df_rs=train.sample(frac=RANDOM_SWAP_FRACTION)\n",
        "df_rs['sentence'] = df_rs['sentence'].apply(lambda x: random_swap(x))\n",
        "len(train),len(df_rs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 2563)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0K8q6KvkGiI",
        "outputId": "a04f0bcc-6afd-4057-d3ca-67208eba0f6d"
      },
      "source": [
        "train_final = pd.concat([train,df_bt,df_ri, df_rd,df_rs], ignore_index=True)\n",
        "len(train_final)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWKXZwfYlDJP"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "3617JVelsdLD",
        "outputId": "9c0fd739-543f-43f1-8bbe-072879ac3af8"
      },
      "source": [
        "train_final.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      3  The Rock is destined to be the 21st Century 's...\n",
              "1      4  The gorgeously elaborate continuation of `` Th...\n",
              "2      3  Singer/composer Bryan Adams contributes a slew...\n",
              "3      2  You 'd think by now America would have had eno...\n",
              "4      3               Yet the act is still charming here ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXgt07lGVrjj"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZQ8WTmYeie4",
        "outputId": "dea11b25-394d-45c0-e767-c034dfb44017"
      },
      "source": [
        "print(len(train_final))\n",
        "print(train_final.isnull().sum())\n",
        "train_final = train_final.dropna()\n",
        "print(train_final.isnull().sum())\n",
        "print(len(train_final))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20078\n",
            "label       0\n",
            "sentence    0\n",
            "dtype: int64\n",
            "label       0\n",
            "sentence    0\n",
            "dtype: int64\n",
            "20078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEzeBXySsAr2"
      },
      "source": [
        "#STANDARD TEXT CLEANING PIPELINE \n",
        "\n",
        "def remove_stopwords(text):\n",
        "    from nltk.corpus import stopwords\n",
        "    text = str(text).lower()\n",
        "    stopword = stopwords.words('english')\n",
        "    #text=[word for word in text if word not in stopword]\n",
        "    text=[word for word in text.split() if word not in (stopword)]\n",
        "    return \" \".join(text)\n",
        "\n",
        "# def  clean_text(text):\n",
        "#     text = str(text).lower()\n",
        "#     #replace multiple space with single space \n",
        "#     text = re.sub(r\"\\s+\", \" \", str(text))\n",
        "#     #replace single charcter words \n",
        "#     text = re.sub(r\"\\b[a-zA-Z0-9]\\b\", \"\", str(text))\n",
        "#     #remove anything except a-z0-9\n",
        "#     text = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", str(text))\n",
        "#     #remove number \n",
        "#     text =  re.sub(r\"\\d+\", \"\", str(text))\n",
        "#     return text \n",
        "\n",
        "def  clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s\\n\\t\\-]\",\"\",str(text))\n",
        "    text = text.replace(\"-\", \" \") #replace hyphens with spaces\n",
        "    text = text.replace(\"\\t\", \" \")\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    #replace multiple space with single space \n",
        "    text = re.sub(r\"\\s+\", \" \", str(text))\n",
        "    #replace single charcter words \n",
        "    text = re.sub(r\"\\b[a-zA-Z0-9]\\b\", \"\", str(text))\n",
        "    # #remove anything except a-z0-9\n",
        "    #text = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", str(text))\n",
        "    #remove number \n",
        "    text =  re.sub(r\"\\d+\", \"\", str(text))\n",
        "    return text "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87PNEdVjQh8T"
      },
      "source": [
        "\n",
        "#stopword"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7lmIs-AsNGh"
      },
      "source": [
        "#train_final['sentence'] = train_final['sentence'].apply(remove_stopwords)\n",
        "\n",
        "train_final['sentence'] = train_final['sentence'].apply(clean_text)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4lNLdLZfAu3",
        "outputId": "7eeb381e-7d40-4e4e-b6ca-d796082c3681"
      },
      "source": [
        "print(len(train_final))\n",
        "print(train_final.isnull().sum())\n",
        "train_final = train_final.dropna()\n",
        "print(train_final.isnull().sum())\n",
        "print(len(train_final))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20078\n",
            "label       0\n",
            "sentence    0\n",
            "dtype: int64\n",
            "label       0\n",
            "sentence    0\n",
            "dtype: int64\n",
            "20078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaYqnX2-Uaku"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "PMmWUJOIP4yc",
        "outputId": "6ac9a839-6bb5-4326-bf43-8d11c1d171a9"
      },
      "source": [
        "train_final.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>the rock is destined to be the st century  new...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>the gorgeously elaborate continuation of the l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>singercomposer bryan adams contributes  slew o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>you  think by now america would have had enoug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>yet the act is still charming here</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      3  the rock is destined to be the st century  new...\n",
              "1      4  the gorgeously elaborate continuation of the l...\n",
              "2      3  singercomposer bryan adams contributes  slew o...\n",
              "3      2  you  think by now america would have had enoug...\n",
              "4      3                yet the act is still charming here "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYCjt0ByKldi"
      },
      "source": [
        "train_final1=train_final.copy()\n",
        "def return_word_count(sent):\n",
        "  l=sent.split(\" \")\n",
        "  return len(l)\n",
        "\n",
        "train_final1['sen_len']=train_final1['sentence'].apply(return_word_count)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQmKNC5MMnOJ",
        "outputId": "1f00758b-ab2e-48b2-f876-194def035918"
      },
      "source": [
        "len(train_final1[(train_final1.sen_len<=2)])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK7vvTBjNuey"
      },
      "source": [
        "#lets remove the sentence having less than equal to 2 word length"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR8PL24HN2kB"
      },
      "source": [
        "train_final1=train_final1[(train_final1.sen_len>=2)]\n",
        "train_final=train_final1[['label','sentence']].reset_index(drop=True)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "ill0f-KgOdjB",
        "outputId": "6fb850eb-c43d-4ced-8517-ce6ba6deefba"
      },
      "source": [
        "train_final.tail()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20065</th>\n",
              "      <td>1</td>\n",
              "      <td>the chateau has one very funny joke funny  few...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20066</th>\n",
              "      <td>0</td>\n",
              "      <td>this garbage just thing is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20067</th>\n",
              "      <td>2</td>\n",
              "      <td>away far</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20068</th>\n",
              "      <td>0</td>\n",
              "      <td>if you work being rewarded assumes you script ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20069</th>\n",
              "      <td>0</td>\n",
              "      <td>pity this rather who sees anyone mishmash</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                           sentence\n",
              "20065      1  the chateau has one very funny joke funny  few...\n",
              "20066      0                         this garbage just thing is\n",
              "20067      2                                          away far \n",
              "20068      0  if you work being rewarded assumes you script ...\n",
              "20069      0         pity this rather who sees anyone mishmash "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAtY6M4CfGHw"
      },
      "source": [
        "train_final.to_csv(path+'train_final.csv', index=False)\n",
        "test.to_csv(path+'test.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmEwSQ44gdpm"
      },
      "source": [
        "train_final =pd.read_csv(path+'train_final.csv')\n",
        "test=pd.read_csv(path+'test.csv')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "blC6Mp7GkXIR",
        "outputId": "e6cb74ed-d82e-4a69-f6b0-abbaab8df780"
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = sns.barplot(x=train_final['label'].unique(), y=train_final['label'].value_counts())\n",
        "ax.set(xlabel = 'Labels')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 0, 'Labels')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLxNZYrfqEAS"
      },
      "source": [
        "#DEFINE FIELD "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu_piDN-rZEg"
      },
      "source": [
        "Text = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "#Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)\n",
        "Label = torchtext.legacy.data.LabelField(dtype = torch.int64)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NITwJ2LvhujC"
      },
      "source": [
        "#Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:\n",
        "#Text and Label ->Field \n",
        "#sentence and label ->column of dataframe "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Dp6egtcqs7"
      },
      "source": [
        "datafields = [('sentence', Text),('label', Label)]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcPE4B0rhxmj"
      },
      "source": [
        "# lets convert from pandas to list to torchtext"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IxOJCSMdmW3"
      },
      "source": [
        "train_example = [torchtext.legacy.data.Example.fromlist([train_final.sentence[i],train_final.label[i]], datafields) for i in range(train_final.shape[0])] \n",
        "test_example = [torchtext.legacy.data.Example.fromlist([test.sentence[i],test.label[i]], datafields) for i in range(test.shape[0])]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVuRkbZbx57r"
      },
      "source": [
        "import os, pickle\n",
        "with open(path+'train_example.pkl', 'wb') as train_it: \n",
        "    pickle.dump(train_example, train_it)\n",
        "import os, pickle\n",
        "with open(path+'test_example.pkl', 'wb') as train_it: \n",
        "    pickle.dump(test_example, train_it)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfi3XXAFklqa"
      },
      "source": [
        "#CREATE DATASET"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Fyy6L4k-4o"
      },
      "source": [
        "train_data = torchtext.legacy.data.Dataset(train_example, datafields)\n",
        "valid_data = torchtext.legacy.data.Dataset(test_example, datafields)\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvPCKZT1wnu-"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vbBdyX4wxi-"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAZeXQpotBZa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5PO_PDOk_bG",
        "outputId": "bf63632c-fe20-4ee2-f8bb-9dc7c93d45e5"
      },
      "source": [
        "(len(train_data), len(valid_data))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20070, 2210)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RWPces-luFl",
        "outputId": "b6889366-a8f6-4779-e5c7-b014371ea05e"
      },
      "source": [
        "print(vars(train_data[5]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sentence': ['whether', 'or', 'not', 'you', 're', 'enlightened', 'by', 'any', 'of', 'derrida', ' ', 'lectures', 'on', 'the', 'other', 'and', 'the', 'self', 'derrida', 'is', 'an', 'undeniably', 'fascinating', 'and', 'playful', 'fellow'], 'label': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qJZCMXDsZW6",
        "outputId": "ecee317b-9dc2-4019-c07b-1c3b5e338fc8"
      },
      "source": [
        "vars(train_data.examples[11])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2,\n",
              " 'sentence': ['you',\n",
              "  'should',\n",
              "  'pay',\n",
              "  'nine',\n",
              "  'bucks',\n",
              "  'for',\n",
              "  'this',\n",
              "  'because',\n",
              "  'you',\n",
              "  'can',\n",
              "  'hear',\n",
              "  'about',\n",
              "  'suffering',\n",
              "  'afghan',\n",
              "  'refugees',\n",
              "  'on',\n",
              "  'the',\n",
              "  'news',\n",
              "  'and',\n",
              "  'still',\n",
              "  'be',\n",
              "  'unaffected']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6dPqRWLmu_K",
        "outputId": "e373a846-749c-494e-d2b6-3bee00e89c67"
      },
      "source": [
        "print(vars(valid_data[5]))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sentence': ['Perhaps', 'no', 'picture', 'ever', 'made', 'has', 'more', 'literally', 'showed', 'that', 'the', 'road', 'to', 'hell', 'is', 'paved', 'with', 'good', 'intentions', '.'], 'label': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1NutoEerEW6"
      },
      "source": [
        "# LETS  CREATE VOCABULARY\n",
        "# WE CAN CREATE VOCAB OR WE CAN USE PRETRAINED VOCAB "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai3SEmuh-K4p"
      },
      "source": [
        "# MAX_VOCAB_SIZE = 18000\n",
        "\n",
        "# Text.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "# Label.build_vocab(train_data)\n",
        "\n",
        "Text.build_vocab(train_data)\n",
        "Label.build_vocab(train_data)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svNxusCfCLeY"
      },
      "source": [
        "#OPTION 2 :\n",
        "# MAX_VOCAB_SIZE = 18_000\n",
        "\n",
        "# Text.build_vocab(train_data,  \n",
        "#                  vectors = \"glove.6B.100d\", \n",
        "#                  unk_init = torch.Tensor.normal_)\n",
        "\n",
        "# Label.build_vocab(train_data)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2NuF6dC0UJS"
      },
      "source": [
        "#Text.vocab.vectors"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M57RKHTAP8D",
        "outputId": "31e713d8-5524-45a3-8f10-1f8cdb540c5f"
      },
      "source": [
        "print('Size of input vocab : ', len(Text.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Text.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  21574\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [(' ', 19643), ('the', 17108), ('and', 10507), ('of', 10384), ('to', 7083), ('is', 5989), ('it', 5554), ('that', 4517), ('in', 4475), ('as', 2963)]\n",
            "Labels :  defaultdict(None, {3: 0, 1: 1, 2: 2, 4: 3, 0: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbkOVODLAmXK"
      },
      "source": [
        "#Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, \n",
        "#which is almost, but not quite, like the data loader we used on images."
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoSBK5kCnfxA"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuelJelrDotq"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
        "                                                                            (train_data, valid_data),\n",
        "                                                                            batch_size = BATCH_SIZE,\n",
        "                                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                                            sort_within_batch= True, \n",
        "                                                                            device = device,\n",
        "                                                                            shuffle=True)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6gkGTa1kSfJ"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCWncleWK7I7",
        "outputId": "dfba3c35-81c7-4df1-b8b2-9b3c3773d33a"
      },
      "source": [
        "print('Train')\n",
        "for batch in train_iterator:\n",
        "    print(f'Text matrix size: {batch.sentence[0].size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for batch in test_iterator:\n",
        "    print(f'Text matrix size: {batch.sentence[0].size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([128, 26])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([128, 7])\n",
            "Target vector size: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr8ZN7-bxiHE"
      },
      "source": [
        "# SAVE TOKENIZER \n",
        "import os, pickle\n",
        "with open(path+'tokenizer_SST.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Text.vocab.stoi, tokens)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKZiALKvD0oV"
      },
      "source": [
        "# LETS CREATE OUR MODEL "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riHSNGuFF99n"
      },
      "source": [
        "## DEFINING OUR MODEL \n",
        "\n",
        "We use the Embedding and LSTM modules in PyTorch to build a simple model for classifying sentences.\n",
        "\n",
        "In this model we create three layers. \n",
        "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
        "2. Thats then fed into a 2 stacked-LSTMs with 100 hidden features (again, were compressing down from the 300-dimensional input like we did with images). We are using 2 LSTMs for using the dropout.\n",
        "3. Finally, the output of the LSTM (the final hidden state after processing the incoming sentences) is pushed through a standard fully connected layer with three outputs to correspond to our three possible classes (0,1,2,3,4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBVzrzu5E50D"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# class classifier(nn.Module):\n",
        "    \n",
        "#     # Define all the layers used in model\n",
        "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,bidirectional, dropout):\n",
        "        \n",
        "#         super().__init__()          \n",
        "        \n",
        "#         # Embedding layer\n",
        "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "#         # LSTM layer\n",
        "#         self.encoder = nn.LSTM(embedding_dim, \n",
        "#                            hidden_dim, \n",
        "#                            num_layers=n_layers, \n",
        "#                            dropout=dropout,\n",
        "#                            bidirectional=bidirectional,\n",
        "#                            batch_first=True)\n",
        "#         # try using nn.GRU or nn.RNN here and compare their performances\n",
        "#         # try bidirectional and compare their performances\n",
        "        \n",
        "#         # Dense layer\n",
        "#         self.fc1 = nn.Linear(hidden_dim, 512)\n",
        "#         self.fc2 = nn.Linear(512, output_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        \n",
        "    # def forward(self, text, text_lengths):\n",
        "        \n",
        "    #     # text = [batch size, sent_length]\n",
        "    #     embedded = self.embedding(text)\n",
        "    #     # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "    #     # packed sequence\n",
        "    #     packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "    #     packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "    #     #hidden = [batch size, num layers * num directions,hid dim]\n",
        "    #     #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "    #     # Hidden = [batch size, hid dim * num directions]\n",
        "    #     #dense_outputs = self.fc(hidden)   \n",
        "    #     output = F.relu(self.fc1(hidden))\n",
        "    #     #         output = self.dropout(output)\n",
        "    #     output = self.fc2(output)\n",
        "    #     output = F.softmax(output[0], dim=1)\n",
        "        \n",
        "    #     # Final activation function softmax\n",
        "    #     # output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "    #     return output\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, output_dim, n_layers,\n",
        "                 bidirectional, dropout, pad_index):\n",
        "        # Constructor\n",
        "        super().__init__()\n",
        "\n",
        "        # embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "\n",
        "        # lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim1,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim1 * 2, hidden_dim2)\n",
        "        self.fc2 = nn.Linear(hidden_dim2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # activation function\n",
        "        self.act = nn.Softmax() #\\ F.log_softmax(outp)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        # text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "\n",
        "        # packed sequence\n",
        "        packed_embedded = pack_padded_sequence(embedded, text_lengths.to('cpu'), batch_first=True) # unpad\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        # packed_output shape = (batch, seq_len, num_directions * hidden_size)\n",
        "        # hidden shape  = (num_layers * num_directions, batch, hidden_size)\n",
        "\n",
        "        # concat the final forward and backward hidden state\n",
        "        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        # output, output_lengths = pad_packed_sequence(packed_output)  # pad the sequence to the max length in the batch\n",
        "\n",
        "        rel = self.relu(cat)\n",
        "        dense1 = self.fc1(rel)\n",
        "\n",
        "        drop = self.dropout(dense1)\n",
        "        preds = self.fc2(drop)\n",
        "\n",
        "        # Final activation function\n",
        "        # preds = self.act(preds)\n",
        "        # preds = preds.argmax(dim=1).unsqueeze(0)\n",
        "        return preds\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5YFigRGGlX_"
      },
      "source": [
        "#HYPER PARAMETER "
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfz40PkWGsJV"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Text.vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 256\n",
        "num_output_nodes = len(Label.vocab)\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "PAD_IDX = Text.vocab.stoi[Text.pad_token]\n",
        "\n",
        "hidden_dim2 = 128\n",
        "bi_directional = True\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, hidden_dim2, num_output_nodes, num_layers, bi_directional, dropout = dropout, pad_index=PAD_IDX)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVKTr7sNIWyR",
        "outputId": "11368076-06e8-4183-d468-913133f8d972"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(21574, 100, padding_idx=1)\n",
            "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (act): Softmax(dim=None)\n",
            ")\n",
            "The model has 4,533,853 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv77fZU8JxQJ"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# # define metric\n",
        "# def binary_accuracy(preds, y):\n",
        "#     #round predictions to the closest integer\n",
        "#     _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "#     correct = (predictions == y).float() \n",
        "#     acc = correct.sum() / len(correct)\n",
        "#     return acc\n",
        "\n",
        "\n",
        "# define metric\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rtvWQjOKc2R"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.sentence\n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        # acc = binary_accuracy(predictions, batch.label)   \n",
        "\n",
        "        # compute the categorical accuracy\n",
        "        acc = categorical_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            text, text_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            # compute the binary accuracy\n",
        "            # acc = binary_accuracy(predictions, batch.label)   \n",
        "\n",
        "            # compute the categorical accuracy\n",
        "            acc = categorical_accuracy(predictions, batch.label)  \n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKWtkBQRoaZc"
      },
      "source": [
        "# load train and test iteraror\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xYYNmgbKreb",
        "outputId": "d762d20d-877a-48d7-dc6c-b78d5ccf43eb"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_loss_epoch=[]\n",
        "valid_loss_epoch=[]\n",
        "train_acc_epoch=[]\n",
        "valid_acc_epoch=[]\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(\"epoch :---->\",epoch)\n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), path+'saved_weights_SST.pt')\n",
        "\n",
        "    train_loss_epoch.append(train_loss)\n",
        "    valid_loss_epoch.append(valid_loss)\n",
        "    train_acc_epoch.append(train_acc)\n",
        "    valid_acc_epoch.append(valid_acc)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :----> 0\n",
            "\tTrain Loss: 1.572 | Train Acc: 26.83%\n",
            "\t Val. Loss: 1.572 |  Val. Acc: 24.82% \n",
            "\n",
            "epoch :----> 1\n",
            "\tTrain Loss: 1.534 | Train Acc: 31.41%\n",
            "\t Val. Loss: 1.549 |  Val. Acc: 28.12% \n",
            "\n",
            "epoch :----> 2\n",
            "\tTrain Loss: 1.483 | Train Acc: 34.72%\n",
            "\t Val. Loss: 1.535 |  Val. Acc: 32.85% \n",
            "\n",
            "epoch :----> 3\n",
            "\tTrain Loss: 1.415 | Train Acc: 39.06%\n",
            "\t Val. Loss: 1.526 |  Val. Acc: 33.52% \n",
            "\n",
            "epoch :----> 4\n",
            "\tTrain Loss: 1.326 | Train Acc: 44.13%\n",
            "\t Val. Loss: 1.502 |  Val. Acc: 32.60% \n",
            "\n",
            "epoch :----> 5\n",
            "\tTrain Loss: 1.208 | Train Acc: 49.97%\n",
            "\t Val. Loss: 1.505 |  Val. Acc: 34.00% \n",
            "\n",
            "epoch :----> 6\n",
            "\tTrain Loss: 1.077 | Train Acc: 55.85%\n",
            "\t Val. Loss: 1.522 |  Val. Acc: 32.89% \n",
            "\n",
            "epoch :----> 7\n",
            "\tTrain Loss: 0.961 | Train Acc: 60.92%\n",
            "\t Val. Loss: 1.592 |  Val. Acc: 33.64% \n",
            "\n",
            "epoch :----> 8\n",
            "\tTrain Loss: 0.857 | Train Acc: 65.45%\n",
            "\t Val. Loss: 1.616 |  Val. Acc: 33.62% \n",
            "\n",
            "epoch :----> 9\n",
            "\tTrain Loss: 0.738 | Train Acc: 70.77%\n",
            "\t Val. Loss: 1.819 |  Val. Acc: 32.84% \n",
            "\n",
            "epoch :----> 10\n",
            "\tTrain Loss: 0.646 | Train Acc: 74.61%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 32.05% \n",
            "\n",
            "epoch :----> 11\n",
            "\tTrain Loss: 0.568 | Train Acc: 78.09%\n",
            "\t Val. Loss: 2.130 |  Val. Acc: 31.26% \n",
            "\n",
            "epoch :----> 12\n",
            "\tTrain Loss: 0.480 | Train Acc: 81.54%\n",
            "\t Val. Loss: 2.454 |  Val. Acc: 30.94% \n",
            "\n",
            "epoch :----> 13\n",
            "\tTrain Loss: 0.402 | Train Acc: 84.87%\n",
            "\t Val. Loss: 2.642 |  Val. Acc: 30.44% \n",
            "\n",
            "epoch :----> 14\n",
            "\tTrain Loss: 0.346 | Train Acc: 87.42%\n",
            "\t Val. Loss: 3.333 |  Val. Acc: 29.69% \n",
            "\n",
            "epoch :----> 15\n",
            "\tTrain Loss: 0.279 | Train Acc: 89.94%\n",
            "\t Val. Loss: 3.116 |  Val. Acc: 29.46% \n",
            "\n",
            "epoch :----> 16\n",
            "\tTrain Loss: 0.233 | Train Acc: 91.88%\n",
            "\t Val. Loss: 3.475 |  Val. Acc: 29.78% \n",
            "\n",
            "epoch :----> 17\n",
            "\tTrain Loss: 0.208 | Train Acc: 92.50%\n",
            "\t Val. Loss: 3.616 |  Val. Acc: 29.72% \n",
            "\n",
            "epoch :----> 18\n",
            "\tTrain Loss: 0.192 | Train Acc: 93.21%\n",
            "\t Val. Loss: 3.805 |  Val. Acc: 29.01% \n",
            "\n",
            "epoch :----> 19\n",
            "\tTrain Loss: 0.273 | Train Acc: 90.93%\n",
            "\t Val. Loss: 3.642 |  Val. Acc: 30.26% \n",
            "\n",
            "epoch :----> 20\n",
            "\tTrain Loss: 0.126 | Train Acc: 96.15%\n",
            "\t Val. Loss: 4.478 |  Val. Acc: 29.00% \n",
            "\n",
            "epoch :----> 21\n",
            "\tTrain Loss: 0.103 | Train Acc: 97.09%\n",
            "\t Val. Loss: 4.738 |  Val. Acc: 28.90% \n",
            "\n",
            "epoch :----> 22\n",
            "\tTrain Loss: 0.096 | Train Acc: 97.01%\n",
            "\t Val. Loss: 4.753 |  Val. Acc: 29.54% \n",
            "\n",
            "epoch :----> 23\n",
            "\tTrain Loss: 0.091 | Train Acc: 97.25%\n",
            "\t Val. Loss: 4.895 |  Val. Acc: 28.41% \n",
            "\n",
            "epoch :----> 24\n",
            "\tTrain Loss: 0.083 | Train Acc: 97.42%\n",
            "\t Val. Loss: 5.059 |  Val. Acc: 29.77% \n",
            "\n",
            "epoch :----> 25\n",
            "\tTrain Loss: 0.088 | Train Acc: 97.31%\n",
            "\t Val. Loss: 5.285 |  Val. Acc: 29.99% \n",
            "\n",
            "epoch :----> 26\n",
            "\tTrain Loss: 0.123 | Train Acc: 96.06%\n",
            "\t Val. Loss: 5.045 |  Val. Acc: 30.57% \n",
            "\n",
            "epoch :----> 27\n",
            "\tTrain Loss: 0.052 | Train Acc: 98.76%\n",
            "\t Val. Loss: 5.681 |  Val. Acc: 29.93% \n",
            "\n",
            "epoch :----> 28\n",
            "\tTrain Loss: 0.044 | Train Acc: 99.00%\n",
            "\t Val. Loss: 5.899 |  Val. Acc: 29.84% \n",
            "\n",
            "epoch :----> 29\n",
            "\tTrain Loss: 0.042 | Train Acc: 98.96%\n",
            "\t Val. Loss: 6.808 |  Val. Acc: 28.34% \n",
            "\n",
            "epoch :----> 30\n",
            "\tTrain Loss: 0.086 | Train Acc: 97.44%\n",
            "\t Val. Loss: 5.649 |  Val. Acc: 30.09% \n",
            "\n",
            "epoch :----> 31\n",
            "\tTrain Loss: 0.051 | Train Acc: 98.63%\n",
            "\t Val. Loss: 6.310 |  Val. Acc: 27.92% \n",
            "\n",
            "epoch :----> 32\n",
            "\tTrain Loss: 0.046 | Train Acc: 98.78%\n",
            "\t Val. Loss: 6.681 |  Val. Acc: 29.11% \n",
            "\n",
            "epoch :----> 33\n",
            "\tTrain Loss: 0.031 | Train Acc: 99.27%\n",
            "\t Val. Loss: 6.573 |  Val. Acc: 28.63% \n",
            "\n",
            "epoch :----> 34\n",
            "\tTrain Loss: 0.049 | Train Acc: 98.66%\n",
            "\t Val. Loss: 6.834 |  Val. Acc: 29.24% \n",
            "\n",
            "epoch :----> 35\n",
            "\tTrain Loss: 0.064 | Train Acc: 98.07%\n",
            "\t Val. Loss: 7.017 |  Val. Acc: 29.44% \n",
            "\n",
            "epoch :----> 36\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.32%\n",
            "\t Val. Loss: 7.174 |  Val. Acc: 29.58% \n",
            "\n",
            "epoch :----> 37\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.63%\n",
            "\t Val. Loss: 7.335 |  Val. Acc: 30.15% \n",
            "\n",
            "epoch :----> 38\n",
            "\tTrain Loss: 0.017 | Train Acc: 99.73%\n",
            "\t Val. Loss: 7.980 |  Val. Acc: 29.55% \n",
            "\n",
            "epoch :----> 39\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.76%\n",
            "\t Val. Loss: 8.511 |  Val. Acc: 29.50% \n",
            "\n",
            "epoch :----> 40\n",
            "\tTrain Loss: 0.013 | Train Acc: 99.78%\n",
            "\t Val. Loss: 8.602 |  Val. Acc: 30.02% \n",
            "\n",
            "epoch :----> 41\n",
            "\tTrain Loss: 0.012 | Train Acc: 99.83%\n",
            "\t Val. Loss: 8.982 |  Val. Acc: 29.72% \n",
            "\n",
            "epoch :----> 42\n",
            "\tTrain Loss: 0.011 | Train Acc: 99.82%\n",
            "\t Val. Loss: 9.213 |  Val. Acc: 29.20% \n",
            "\n",
            "epoch :----> 43\n",
            "\tTrain Loss: 0.010 | Train Acc: 99.85%\n",
            "\t Val. Loss: 9.286 |  Val. Acc: 29.98% \n",
            "\n",
            "epoch :----> 44\n",
            "\tTrain Loss: 0.009 | Train Acc: 99.87%\n",
            "\t Val. Loss: 9.882 |  Val. Acc: 29.55% \n",
            "\n",
            "epoch :----> 45\n",
            "\tTrain Loss: 0.085 | Train Acc: 98.27%\n",
            "\t Val. Loss: 5.912 |  Val. Acc: 28.08% \n",
            "\n",
            "epoch :----> 46\n",
            "\tTrain Loss: 0.125 | Train Acc: 96.04%\n",
            "\t Val. Loss: 6.999 |  Val. Acc: 27.22% \n",
            "\n",
            "epoch :----> 47\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.66%\n",
            "\t Val. Loss: 6.697 |  Val. Acc: 28.55% \n",
            "\n",
            "epoch :----> 48\n",
            "\tTrain Loss: 0.012 | Train Acc: 99.88%\n",
            "\t Val. Loss: 7.324 |  Val. Acc: 29.43% \n",
            "\n",
            "epoch :----> 49\n",
            "\tTrain Loss: 0.009 | Train Acc: 99.89%\n",
            "\t Val. Loss: 7.533 |  Val. Acc: 29.38% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZa5aOZLcVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "ba17b772-992a-4056-b966-65de4a2f9a2d"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set()\n",
        "plt.style.use(\"dark_background\")\n",
        "\n",
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "axs[0, 0].plot(train_loss_epoch)\n",
        "axs[0, 0].set_title(\"Training Loss\")\n",
        "axs[0, 1].plot(valid_loss_epoch)\n",
        "axs[0, 1].set_title(\"Test Loss\")\n",
        "axs[1, 0].plot(train_acc_epoch)\n",
        "axs[1, 0].set_title(\"Training Accuracy\")\n",
        "axs[1, 1].plot(valid_acc_epoch)\n",
        "axs[1, 1].set_title(\"Test Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxpo1F2LaKJ_"
      },
      "source": [
        "valid_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hg8ZMXNxrRU"
      },
      "source": [
        "# LOAD  SAVED MODEL \n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtF_YG1Sx0Za"
      },
      "source": [
        "model_path=path+'/saved_weights_SST.pt'\n",
        "model.load_state_dict(torch.load(model_path));\n",
        "model.eval();\n",
        "tokenizer_file = open(path+'./tokenizer_SST.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_text(tweet):\n",
        "    \n",
        "    categories = {0: \"0\", 1:\"1\", 2:\"2\", 3:\"3\", 4:\"4\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "    print(prediction)\n",
        "\n",
        "    #_, pred = torch.max(prediction, 1) \n",
        "    pred = prediction.argmax(1, keepdim = True)\n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Pm22UW3qeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4facb5b9-898c-45dd-e879-170d41922cc0"
      },
      "source": [
        "#for individual prediction \n",
        "classify_text(\"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal good bad worst   \")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0949,  0.4165, -0.6372,  0.0369,  0.4248]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fal43ZIjki9H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "bd5c19e0-8f40-41dc-f70e-ca736ad92f0b"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           sentence\n",
              "0      2                     Effective but too-tepid biopic\n",
              "1      3  If you sometimes like to go to the movies to h...\n",
              "2      4  Emerges as something rare , an issue movie tha...\n",
              "3      2  The film provides some great insight into the ...\n",
              "4      4  Offers that rare combination of entertainment ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4DKpnU9ihDP",
        "outputId": "3379d9b7-66f0-4e35-dd33-a32172f8b5d2"
      },
      "source": [
        "test1=test\n",
        "test1['pred_label']=test1.sentence.apply(classify_text)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3078,  1.2896,  0.1728, -1.5646, -0.1101]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4161,  0.1042, -0.1097,  0.0644, -0.3221]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6206,  0.1491, -0.6236,  0.1699, -0.1086]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5344,  0.5611,  0.4555, -1.3419, -1.6299]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2199,  0.1831, -0.6567,  0.3254,  0.2096]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0675,  0.8603,  0.1173, -1.1683, -0.0209]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2753,  0.4004,  0.0816, -0.4917, -0.3760]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8836,  0.5974,  0.2771, -1.2468, -0.9441]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6391, -0.0900, -0.5580,  0.7644, -0.3473]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4424, -0.4595, -0.6098,  1.3568, -1.0912]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0529,  0.4287, -0.4626, -0.2167,  0.2522]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5197,  0.3087, -0.4092, -0.0141, -0.2418]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2348,  0.1410, -0.3565,  0.0886,  0.0260]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3815,  0.9570,  0.6859, -2.1213, -0.6462]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3242, -0.1596, -0.1727,  0.2744, -1.0441]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7497, -0.0385, -0.2371,  0.2438, -0.5232]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2487,  0.2616, -0.2129, -0.3465, -0.9871]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3143,  0.3097, -0.0843, -0.2933, -0.2357]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3298, -0.0090, -0.5257,  0.3473,  0.1469]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5456, -0.2809, -0.3261,  0.6559, -0.2376]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8841,  0.2042, -0.5570,  0.2246, -0.5151]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0303, -0.0592, -0.6039,  0.5725,  0.5327]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1056,  0.0274,  0.1828, -0.1779, -1.1488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1342, -0.5124, -0.3099,  1.0738, -0.8511]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0185, -0.3419, -0.2144,  0.5248, -0.7003]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1186, -0.4922, -0.5187,  1.2378, -0.7526]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2940,  1.2911,  0.1244, -1.7293, -0.5079]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6079, -0.6529, -0.3965,  1.0961, -1.1198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4632,  0.2338, -0.2137, -0.1156, -0.2911]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0135,  0.3639, -0.2786, -0.0832,  0.0768]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2078, -0.5934, -0.9025,  1.6741, -0.5860]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0011,  0.2555, -0.5851,  0.0975,  0.4376]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3710,  0.5416, -0.2359, -0.4396, -0.2779]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2443,  0.3727, -0.1390, -0.6872,  0.0431]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0756,  0.0108, -0.2370,  0.1977,  0.1671]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4691, -0.0792, -0.2885,  0.2708, -0.1498]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7551,  0.1604, -0.3789,  0.2889, -0.5792]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5624, -0.2325, -0.3990,  0.5914, -0.1917]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 9.8745e-01,  4.8595e-01, -2.3633e-05, -4.6029e-01, -1.0240e+00]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1163,  0.5471,  0.0899, -0.6558, -0.0131]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3544,  0.7178, -0.5663, -0.3892,  0.6506]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7368,  0.2847, -0.2439, -0.1221, -0.5393]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5543, -0.1078, -0.4752,  0.5228, -0.1578]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0068,  0.0352, -0.4303,  0.0542,  0.4959]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5952, -0.5018, -0.4381,  1.0783, -1.2352]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1524,  0.7760, -0.1068, -0.7757,  0.0996]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5964, -0.4788, -0.2925,  0.9844, -0.3164]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9355, -0.6352, -0.6322,  1.5290, -0.4973]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9105, -0.5548, -0.8403,  1.5448, -0.2968]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3307,  0.7083,  0.2422, -0.9844, -0.5520]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7325, -0.0610, -0.3942,  0.4120, -0.4225]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0184,  0.5611, -0.3119, -0.5782,  0.2864]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4516,  0.3110,  0.1518, -0.7383,  0.5511]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2817,  0.0902, -0.4723,  0.3081,  0.0297]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1711, -0.2863, -0.5263,  0.8781, -0.7901]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6157, -0.0044, -0.6182,  0.5940, -0.1930]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8444, -0.1134, -0.2707,  0.3478, -0.5359]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1886,  0.1911, -0.2108, -0.1631,  0.0471]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1224, -0.0501, -0.6406,  0.5661,  0.3447]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3553, -0.2286, -0.5527,  0.8464,  0.0476]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4230,  0.2070, -0.4473,  0.0898, -0.1518]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8466,  0.1795, -0.6797,  0.2796, -0.3195]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4261,  0.1453, -0.6803,  0.4225,  0.0141]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4138,  0.2200,  0.1457, -0.1968, -0.5751]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4011,  0.2324, -0.4298, -0.1423,  0.0401]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1833,  0.6216, -0.2123, -0.7637, -0.0303]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1846, -0.4375, -0.1436,  0.8239, -1.0294]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5676, -0.2645, -0.7656,  1.0007, -0.0124]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6470, -0.2591, -0.5579,  0.9768, -0.2936]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0793,  0.1992, -0.3650,  0.0328,  0.3614]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6616,  0.3013, -0.3892,  0.0225, -0.4308]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4470,  0.0467,  0.0797, -0.4131, -0.2834]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1053,  0.2215, -0.5472,  0.2071,  0.2389]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1326,  0.5192, -0.0892, -0.5903, -0.0369]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0853,  0.3178,  0.0087, -0.3413, -1.0991]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0437,  1.7025,  0.1559, -2.3094, -0.3194]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3921,  0.0144, -0.3391,  0.3307, -0.1915]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3266, -0.3102, -0.5924,  1.1770, -1.0072]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5022, -0.0296, -0.3902,  0.6383, -0.3608]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2236,  0.6955, -0.2502, -0.8821,  0.4706]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1417,  0.6484, -0.5645, -0.3774,  0.1574]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7416, -0.0722, -0.6188,  0.8759, -0.4358]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6604,  0.0240, -0.0866, -0.0505, -0.4175]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2708, -0.0511, -0.4962,  0.5390,  0.0672]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0893,  0.4629, -0.4553, -0.4333,  0.5072]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1475,  0.3676, -0.1505, -0.2623, -0.0804]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7121,  0.0332, -0.4799,  0.2299, -0.2902]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4983, -0.1814, -0.3960,  0.4960, -0.1254]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3805,  0.0375,  0.1891,  0.3112, -1.6088]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0106,  0.3516, -0.0767, -0.1047, -1.1075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5002,  0.7528, -0.1773, -0.7804, -0.4668]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3359,  0.4603, -0.3419, -0.2877,  0.5539]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5472,  0.1954, -0.0038, -0.4169, -0.3761]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3428,  0.6582, -0.1573, -0.8135, -0.2291]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3479,  0.1951, -0.2464, -0.2651, -0.0277]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2605,  0.2631, -0.3569, -0.0566, -0.0332]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6987, -0.2635, -0.0810,  0.6772, -1.6710]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4880, -0.1183, -0.5030,  0.7556, -0.2329]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3304,  0.3316, -0.6945,  0.0843,  0.1552]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3411,  0.3730,  0.2903, -0.3077, -1.6859]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4710,  0.2299, -0.1004, -0.4282, -0.2108]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3242,  0.1126, -0.1108, -0.1813,  0.5398]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0922,  0.5385, -0.1117, -0.8796,  0.0690]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0978,  0.2688, -0.3705, -0.1428,  0.4521]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4014,  0.3707, -0.3879, -0.1586, -0.1281]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0566, -0.2148, -0.3046,  0.9287, -0.9910]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2922,  0.0390, -0.4165,  0.4336, -0.0470]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2417, -0.4121, -0.1768,  0.8074, -1.0599]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1740, -0.3002, -0.7749,  1.3470, -0.7463]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7489, -0.5591, -0.7172,  1.6016, -0.3095]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1628,  0.3475, -0.1899, -0.3906,  0.3886]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2279, -0.1542, -0.7638,  0.9248, -0.7271]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8709, -0.0884, -0.5428,  0.7584, -0.5735]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5764, -0.0469,  0.4312, -0.3847, -0.6500]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6289,  0.1777, -0.1239, -0.2772, -0.4261]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0824e+00,  3.8346e-02, -4.9473e-04, -2.1003e-01, -8.8081e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8280, -0.2504, -0.5550,  0.7966, -0.4325]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1601,  0.8289, -0.0670, -1.0967, -0.1580]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7254,  0.1225, -0.4137,  0.3066, -0.5419]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0605,  0.1440, -0.3158,  0.1293,  0.1524]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0979, -0.0301, -0.4279,  0.4274,  0.2139]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7773,  0.1919, -0.2718, -0.0571, -0.5667]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1394,  0.0153, -0.3142,  0.2549, -0.8791]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5876, -0.0995,  0.1998,  0.3970, -1.8006]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1746,  0.3632, -0.0195, -0.4000, -0.2304]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7986, -0.1987, -0.1740,  0.3439, -0.5180]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5744, -0.1725,  0.0691, -0.0132, -0.3386]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6116,  0.1007, -0.2951,  0.2818, -0.4504]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3365,  0.5662, -0.3502, -0.3689, -0.1602]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3075,  0.2429, -0.6252,  0.1298,  0.1412]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3674,  0.4918, -0.2529, -0.5636, -0.1305]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9964, -0.1007,  0.0754, -0.2432, -0.7908]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2822,  0.1109, -0.5273,  0.2801,  0.0993]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9948,  0.0269, -0.1994,  0.1698, -0.8731]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5684, -0.3963, -0.1451,  0.7995, -1.3750]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2657, -0.0447, -0.6073,  0.6298,  0.6926]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8783, -0.2507, -0.0726,  0.4187, -1.7359]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7482, -0.2277, -0.5225,  0.8946, -0.4230]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8564, -0.0453, -0.1355,  0.3131, -0.7181]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7259, -0.7476, -0.6227,  1.7212, -1.2253]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2907,  0.6193, -0.1034, -0.7262, -0.2371]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1812,  0.6138, -0.2445, -0.6115,  0.3352]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7812, -0.0526, -0.3233,  0.3421, -0.5054]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2546,  0.4416, -0.1489, -0.4250,  0.3538]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4932,  0.2103, -0.1736, -0.1637, -0.3017]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0787, -0.0829,  0.0071,  0.2151, -0.9987]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8808,  0.4299, -0.6438,  0.2004, -0.5881]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1922,  0.3400, -0.1436, -0.3901, -1.0050]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3551,  0.5896, -0.1233, -0.8046, -0.2127]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1248, -0.1162, -0.0877,  0.1030, -0.9217]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1590, -0.1561, -0.3075,  0.5926, -0.9637]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4994,  0.8021, -0.2362, -0.8549, -0.4088]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0838,  0.2622,  0.1188, -0.3086, -0.1833]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4636,  0.1324, -0.5498,  0.3421, -0.1125]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5689, -0.2841, -0.7514,  1.1757, -0.0665]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2945,  0.1633, -0.4785,  0.1561,  0.0472]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5909, -0.1356, -0.6252,  0.9001, -0.2491]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3487, -0.0691, -0.4266,  0.5405, -0.0651]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9989, -0.5654, -0.6636,  1.2523, -0.4147]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0892, -0.1551, -0.2394,  0.5625, -0.9519]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3472,  0.0592, -0.2941,  0.4123, -1.2653]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0873,  0.5062, -0.3769, -0.3439,  0.0832]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3158, -0.7053,  0.1275,  0.9990, -1.2376]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7860,  0.3086, -0.1999, -0.0839, -0.7542]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5019,  0.1947, -0.6734,  0.2825, -0.0544]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2256, -0.2565, -0.4687,  0.8131, -0.8606]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8841,  0.2933, -0.2467, -0.0427, -0.7926]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9265,  0.2043, -0.3476,  0.2190, -0.7670]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4356,  0.0044, -0.5589,  0.3811, -0.0040]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7136, -0.0236, -0.7781,  0.7281, -0.2015]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8103, -0.1812, -0.2682,  0.2773, -0.3914]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7723,  0.2882,  0.1273, -0.3161, -0.7727]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0293,  0.1632, -0.5740,  0.0184,  0.5822]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7472, -0.2225, -0.4177,  0.8150, -0.5383]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7156, -0.1137, -0.6285,  0.5303, -0.1343]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3263,  0.1196, -0.2849, -0.0131, -0.0322]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9741, -0.1917,  0.0154,  0.2930, -1.9151]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2428,  0.1815, -0.6600,  0.2277,  0.7165]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6718,  0.1326, -0.2943,  0.2146, -0.5366]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8741, -0.7256, -0.7566,  1.9438, -0.4506]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2597, -0.1650, -0.4134,  0.6302,  0.0197]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5973,  0.0755, -0.6536,  0.5954, -0.2529]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3177,  0.2369, -0.0052, -0.3871, -0.2285]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 5.2371e-01, -2.7539e-06, -3.1803e-01,  2.3110e-01, -2.1619e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1530, -0.1416, -0.2687,  0.4894, -0.8692]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6714,  0.0684, -0.1276, -0.0128, -0.5397]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0274,  0.3787, -0.2745, -0.2765,  0.1955]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4208,  0.1383, -0.5203,  0.1170,  0.0300]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2004, -0.0554, -0.1272, -0.0287,  0.1551]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8686, -0.5922, -0.7002,  1.7000, -0.4936]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2978, -0.5170, -0.5847,  1.5366, -1.0227]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5641,  0.2766, -0.3977,  0.0864, -0.3948]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2433,  0.0603, -0.3171,  0.2109,  0.0126]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9940, -0.6645, -0.3643,  1.2231, -0.5911]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6295,  0.7631,  0.0288, -1.0781, -0.6803]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2750,  0.3571, -0.3789, -0.0780, -0.1132]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2578,  0.2079, -0.2564,  0.0372, -0.1053]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7865, -0.5327, -0.8350,  1.5822, -0.2551]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2165,  0.3378, -0.2403, -0.2762, -0.0277]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9975,  0.2382, -0.0307, -0.2264, -0.9694]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1843, -0.3014, -0.3671,  0.8007, -0.9086]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6243, -0.4913, -0.8848,  1.7299, -0.1328]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9754, -0.3839, -0.4165,  1.0637, -0.7165]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6841e-01,  7.2856e-01,  2.0012e-04, -9.3922e-01, -3.9580e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4496, -0.0068, -0.5182,  0.4272, -0.0177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4260,  0.0182,  0.1835, -0.3015, -0.3841]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0833, -0.0618,  0.1759, -0.2270, -0.9180]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3548, -0.2464,  0.1098,  0.3973, -1.3664]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9419, -0.3769, -0.2502,  0.8470, -0.7175]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1630,  0.0732, -0.8032,  0.5757,  0.3920]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3220, -0.0734, -0.4829,  0.3856,  0.1628]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0321, -0.1641, -0.6934,  0.8750, -0.5788]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9899,  0.0113, -0.4082,  0.5277, -0.7750]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6245,  0.3022, -0.4647,  0.0485, -0.3435]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0490,  0.5189, -0.3591, -0.4660,  0.3386]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6843, -0.4363, -0.7692,  1.4141, -0.1749]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1543,  0.1150, -0.7208,  0.5255,  0.6230]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9132, -0.2288, -0.7318,  1.1928, -0.4912]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3721, -0.4887, -0.4762,  1.2858, -1.0172]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1723,  0.5315, -0.6223, -0.1394,  0.1458]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0879,  0.0225, -0.6424,  0.6080, -0.7194]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2912, -0.2858, -0.6604,  1.0109, -0.8284]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5754,  0.3209, -0.2490, -0.2699, -0.3479]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5536,  0.1863,  0.0968, -0.4853, -0.4413]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1458, -0.0215, -0.7200,  0.9449,  0.4736]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5403, -0.2027, -0.2779,  0.5049, -0.2234]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4983,  0.8757, -0.4295, -0.9514,  0.8111]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1343,  0.2071, -0.2458, -0.1409,  0.3779]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1579,  0.3189, -0.4243,  0.0155,  0.0624]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5471,  0.3968, -0.7855, -0.0126,  0.0741]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1192,  0.1723, -0.6278,  0.3623,  0.2520]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6094,  0.0740, -0.4430,  0.1547, -0.1791]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5757,  0.2320, -0.3050, -0.2159, -1.2714]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4125,  0.0242, -0.0549, -0.1147, -0.2162]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3649,  0.0546, -0.4893,  0.1603,  0.1205]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6709, -0.1509, -0.0120,  0.1886, -0.5360]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1363, -0.0649, -0.3159,  0.4534, -0.8946]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0249,  0.9172,  0.3215, -1.2891, -0.3317]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7614,  0.2100, -0.2738, -0.1256, -0.5207]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0039,  0.4659, -0.3305, -0.2363,  0.1280]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0318, -0.4005, -0.7753,  1.4204, -0.5691]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3659, -0.6256, -0.7316,  1.4393, -0.7516]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7812,  0.2446, -0.5045,  0.1290, -0.4702]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8020, -0.0394,  0.6073, -0.3785, -1.9523]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2005,  0.5739, -0.2792, -0.6886,  0.1208]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6039,  0.1860, -0.1936, -0.0529, -0.4543]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1153,  0.5030,  0.4892, -1.2260, -0.0197]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2667,  0.1655,  0.2349, -0.5853, -0.2252]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4398, -0.0268, -0.6643,  0.5937,  0.0902]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5072, -0.2321,  0.6520,  0.0290, -2.6963]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5467,  0.0668, -0.5295,  0.4352, -0.2171]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8516, -0.6506, -0.4707,  1.2093, -1.4005]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4807, -0.3312, -0.5480,  0.9000, -0.0328]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4163,  0.1361, -0.1516, -0.1251, -0.2538]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2182,  0.3144, -0.4576, -0.1422,  0.1537]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3128, -0.2868, -0.0665,  0.4507, -1.1368]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0266,  0.3955, -0.1973, -0.0362, -1.0642]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5668,  0.4447, -0.1732, -0.4125, -0.4934]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0228, -0.0675, -0.6598,  0.6858, -0.5460]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0615,  0.4032, -0.4534, -0.2631,  0.3987]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2566, -0.3294, -0.4676,  0.8443, -0.8352]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0657,  0.0432, -0.0986, -0.1406, -0.8136]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5033,  0.6681, -0.2569, -0.7244,  0.7170]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5943, -0.0393, -0.7504,  0.8138, -0.1743]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1277,  0.1782, -0.4329,  0.2277,  0.1401]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5049, -0.0538, -0.1703,  0.0690, -0.2517]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0143,  0.3632, -0.1674, -0.2115,  0.0227]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6902, -0.0359, -0.3937,  0.5263, -0.4265]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2434, -0.3799, -0.2000,  0.9426, -1.1736]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0919, -0.3633, -0.7244,  1.2143, -0.6138]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4371, -0.3750, -0.4374,  0.8103, -0.0172]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7363,  0.0363, -0.3420,  0.2119, -0.4172]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6180, -0.9427, -0.7107,  2.1846, -1.1235]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1587e-01,  3.4295e-01, -3.0760e-01,  2.7684e-04, -1.7298e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5773,  0.3963, -0.3330, -0.1154, -1.3981]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1867, -0.4620, -0.5511,  1.2074, -0.8078]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4217, -0.3671, -0.3858,  0.8478, -1.0233]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5875,  0.1803, -0.3814, -0.0447, -0.2395]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0414,  0.8038,  0.2062, -1.0867, -0.2113]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2104,  0.4848, -0.5803, -0.0697, -0.9754]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9777, -0.1614, -0.5346,  0.7378, -0.5692]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3092,  0.2330, -0.4458,  0.0785, -0.0444]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0177,  0.6278,  0.4228, -1.1942, -0.2147]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2543,  0.2975, -0.5697,  0.0497,  0.1131]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8017,  0.1078, -0.4570,  0.2736, -0.5096]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7386,  0.0824, -0.2054, -0.0912, -0.4274]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0572,  0.2047, -0.2365, -0.1075,  0.2855]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9866,  0.2008,  0.1834, -0.3979, -1.0333]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4202,  0.3923, -0.4938, -0.0759, -0.1235]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2435,  0.1228, -0.1809,  0.0763, -0.0956]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6622,  0.3699,  0.6419, -0.6265, -1.0690]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4860, -0.5733, -0.9052,  1.5704, -0.7964]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7965, -0.9963, -0.2744,  1.8029, -1.5160]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4962,  0.2960, -0.0292, -0.2756, -0.5181]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1481, -0.4004, -0.1686,  0.7443, -0.9528]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4515,  0.1097, -0.4481,  0.2629, -0.1644]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8951,  0.5161,  1.0754, -1.3452, -2.5520]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0390,  0.5016, -0.3616, -0.3859,  0.2067]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1485,  0.3884, -0.0564, -0.5813, -0.0359]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7394, -0.0291, -0.3388,  0.5479, -0.5564]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3000,  0.4655, -0.1985, -0.3363, -0.2487]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0837,  0.6785, -0.0493, -1.0194,  0.1786]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7078, -0.0305, -0.4183,  0.5442, -0.4873]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0456,  1.0691,  0.5554, -1.1981, -0.6568]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1730,  0.4929, -0.4864, -0.1195,  0.0396]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6276, -0.0200, -0.1318,  0.6381, -0.7485]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4266,  0.2931,  0.0341, -0.4691, -0.4140]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3093,  0.6681, -0.5203, -0.4556,  0.5840]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3067,  0.3550, -0.1676, -0.3550, -0.1497]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0829,  0.0604, -0.4905,  0.2914, -0.7007]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1428,  0.1720, -0.2234, -0.0759,  0.3639]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6121,  0.3872, -0.4803, -0.0324, -0.3651]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5630,  0.1492,  0.1897, -0.2603, -0.6843]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8520,  0.5725, -0.2528, -0.4800, -0.7602]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9650,  0.0174, -0.1391,  0.1093, -0.8258]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2462,  0.0932,  0.0134, -0.1455, -0.1868]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9716, -0.1851, -0.1981,  0.3951, -0.7465]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0919,  0.3236, -0.4836, -0.2325,  0.5195]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6233, -0.0844, -0.2111,  0.0827, -0.2174]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1812,  0.4587,  0.3702, -1.1889, -0.1981]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3360,  0.6383, -0.1014, -0.7787,  0.3714]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3113e-02,  6.1500e-01, -1.5297e-01, -6.5220e-01, -4.8209e-04]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5828,  0.0553, -0.7128,  0.4557, -1.0016]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4131,  0.2071, -0.5503,  0.2299, -0.0455]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6726,  0.7674,  0.2623, -0.9129, -0.9754]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0960,  0.3212, -0.7508,  0.3121,  0.3251]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4931,  0.0566, -0.5867,  0.4928, -0.1458]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6127,  0.0971, -0.2491, -0.1345, -0.2396]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9330,  0.0891, -0.4805,  0.3720, -0.6373]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0820,  0.2504, -0.9106,  0.2565,  0.7776]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4299, -0.0442, -0.2885,  0.3357, -0.1944]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3251,  0.2131,  0.0761, -0.3100, -0.3447]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7937, -0.5849, -0.4508,  1.2540, -0.4175]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7526,  0.0852, -0.1791, -0.0257, -0.5828]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6193,  0.0098, -0.4484,  0.3367, -0.2579]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9224, -0.1271, -0.3342,  0.5701, -0.6645]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7763, -0.2025, -0.5068,  0.8261, -0.4406]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4832,  0.1978, -0.0202, -0.2837, -0.4449]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2715,  0.0824, -0.6036,  0.4203,  0.1314]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5202,  0.1164, -0.3068,  0.1460, -0.2984]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0174,  0.0225, -0.2669,  0.2263, -0.8185]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8978,  0.0605, -0.0123, -0.1550, -0.6948]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7324, -0.1930, -0.5340,  0.9119, -0.4303]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5885,  0.2127, -0.4912,  0.3352, -0.3636]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5506, -0.3234, -0.4692,  0.8769, -1.0867]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9541, -0.1016, -0.4260,  0.6228, -0.7017]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1347,  0.3609, -0.0860, -0.6672,  0.1265]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0940,  0.2242, -0.0328, -0.4060,  0.0795]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6986,  0.1291, -0.3750,  0.1519, -0.4408]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2265,  0.0513, -0.3319,  0.1894,  0.0855]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1283,  0.3129, -0.3034,  0.0290, -0.0452]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0165,  0.3700, -0.4985, -0.1643,  0.3297]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7983,  0.0084, -0.6383,  0.5890, -0.3353]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6119,  0.5961,  0.0362, -0.8280, -0.5988]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5908,  0.3935, -0.3528, -0.2724,  0.8558]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1074,  0.2670, -0.6249,  0.1494,  0.3319]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3685,  0.3378, -0.3292, -0.1558, -0.1650]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3998,  0.0684, -0.1756, -0.1604, -0.1344]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6451, -0.4035, -0.5759,  1.3586, -0.4196]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1066,  0.2252, -0.5011,  0.0047,  0.3200]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4465, -0.0894, -0.2773,  0.2304, -0.0548]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2655, -0.0546, -0.5278,  0.7722, -1.0206]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7252, -0.6572, -0.0549,  1.1837, -1.5002]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4232, -0.2468, -0.6082,  0.9722, -1.0668]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7630, -0.0730, -0.5576,  0.5147, -0.2709]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2169,  0.2802, -0.4743,  0.1202,  0.0482]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0032,  0.2843, -0.3059, -0.1068,  0.2429]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1079,  0.1836, -0.4712,  0.1670,  0.2031]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7427,  0.0054, -0.4051,  0.2912, -0.3958]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4485,  0.3471, -0.2535, -0.1896, -0.3290]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1720,  0.3474, -0.4517, -0.1726,  0.5327]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1447,  0.2384, -0.2687,  0.0455, -0.0324]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4088,  0.4720, -0.1019, -0.7284,  0.6741]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0647,  0.9111, -0.1138, -1.1451,  0.0994]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1930,  0.3150, -0.3883, -0.0692,  0.0349]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3369,  0.4772, -0.0915, -0.6867, -0.1939]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2959,  0.0755, -0.2014,  0.0778, -0.0741]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2461, -0.8906, -0.9663,  2.2306, -0.5756]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1787, -0.4103, -0.0899,  0.4508, -0.8450]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5009,  0.5072, -0.2777, -0.4746, -0.3030]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0539,  0.4170, -0.2909, -0.4400,  0.2085]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4045,  0.1931, -0.2518, -0.0708, -0.2258]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0542, -0.0774, -0.1762,  0.2933, -0.9071]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0739, -0.0556, -0.0775, -0.0840, -0.8087]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7722,  0.1131, -0.2579, -0.0422, -0.4816]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1174, -0.3729, -0.4469,  0.6151, -0.5836]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3374,  0.3778,  0.0259, -0.5021, -0.3359]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1621, -0.0631, -0.3181,  0.4355, -0.9504]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0785,  0.5426, -0.3700, -0.4369,  0.2771]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3060, -0.4829, -0.0767,  0.6331, -1.0443]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5655,  0.2958, -0.1204, -0.3229, -0.4177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7823, -0.1029, -0.1770,  0.2215, -0.5458]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2901,  0.5283, -0.3010, -0.4216, -0.1405]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0088,  0.6053, -0.2263, -0.5726,  0.0968]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5827, -0.0807, -0.7359,  0.6176,  0.0209]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0150,  0.2289, -0.2486, -0.0505,  0.1454]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7736, -0.4994, -0.7843,  1.3790, -0.1518]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0356,  0.0255, -0.5333,  0.5088, -0.7064]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3386,  0.1193,  0.0934,  0.0414, -1.4479]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4037,  0.7529, -0.0585, -1.2804,  0.6750]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7362,  0.3951,  0.2776, -0.6918, -0.8959]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3484,  0.1237, -0.5866,  0.4203, -0.0375]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1581,  0.2055, -0.4750,  0.1031,  0.1739]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0310, -0.1628, -0.6723,  0.9486,  0.3927]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2403,  0.4590, -0.2625, -0.4833, -0.0549]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5160,  0.2050,  0.5778, -0.7911, -0.7758]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0696,  0.6622, -0.2697, -0.6054,  0.0504]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4422,  0.3895,  0.2099, -0.7635, -0.4163]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0829, -0.2011, -0.1934,  0.4214, -0.8639]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7600,  1.1111,  0.4524, -1.5848, -1.1791]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2515,  0.5094, -0.4799, -0.4633,  0.6509]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7060, -0.0850,  0.1073,  0.0946, -1.6964]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6422, -0.0030, -0.5442,  0.4695, -0.2482]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0500,  0.1392, -0.5076,  0.2207,  0.3177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8312, -0.3852, -0.5065,  1.0499, -0.4697]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0860, -0.1098, -0.3332,  0.4573, -0.7829]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1435, -0.5752, -0.2993,  1.3076, -1.9089]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0831,  0.4047, -0.1131, -0.5145,  0.0399]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7669,  0.9673, -0.1005, -1.2783,  0.8488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7728, -0.1367, -0.3060,  0.4332, -0.5184]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1341, -0.0146, -0.4683,  0.5059, -0.8484]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1108,  0.5205, -0.5367, -0.2257,  0.2253]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6098,  0.1580, -0.3985,  0.0276, -0.2731]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4242,  0.4576,  0.0300, -0.5608, -0.4846]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0599,  0.0592, -0.2625,  0.1887,  0.1406]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4374,  0.7348, -0.2798, -0.7049, -0.3292]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1358,  0.6602, -0.3259, -0.3728, -0.0998]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8963, -0.2104,  0.0624,  0.2884, -0.8419]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8173,  0.1748,  0.2393, -0.1362, -1.0048]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6697,  0.5415,  0.2266, -0.7325, -0.8604]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4085,  0.6855, -0.1738, -0.8839, -0.3108]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2623, -0.7997, -0.9523,  2.2428, -0.6675]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5911, -0.1902, -0.3687,  0.5945, -0.2932]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8165, -0.0456,  0.0959,  0.3107, -1.9367]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5010,  0.4094, -0.5398, -0.0804, -0.1841]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1087,  0.3099,  0.2612, -0.6330, -1.1382]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1996,  0.3237, -0.2029, -0.2529, -0.0736]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6996,  0.0042, -0.4643,  0.2523, -0.2737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2684,  0.6013, -0.1195, -0.5340, -0.3015]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0453, -0.6221, -0.4752,  1.1525, -0.5418]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0630, -0.1433, -0.5003,  0.6209,  0.3246]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5632, -0.2276, -0.7604,  1.0682, -1.0775]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7970,  0.1540, -0.2744,  0.0665, -0.6138]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0514,  0.8645, -0.3682, -0.8253,  0.2547]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6724,  0.5758,  0.0015, -1.0227, -0.5158]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6386,  0.1220,  0.1197, -0.1931, -0.6824]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5600, -0.4074, -0.6831,  1.2596, -0.1006]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8312,  0.3085, -0.2084, -0.3940, -0.5618]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0045,  0.5451, -0.5152, -0.4177,  0.3929]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7753, -0.0071, -0.3065,  0.2614, -0.5029]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3282, -0.1539, -0.5304,  0.6930, -0.9323]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5886, -0.8285, -0.8066,  2.2839, -1.1561]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5021,  0.4206,  0.3811, -0.9079, -0.6859]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2400,  0.0422, -0.6871,  0.6488,  0.6353]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7713,  1.0512, -0.0107, -1.5874,  0.8675]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7805,  0.0378, -0.4754,  0.6031, -0.6100]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5904,  0.6221,  0.0454, -0.7875, -0.6616]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1329, -0.3464, -0.2312,  0.6348, -0.8214]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8068, -0.4251, -0.1868,  0.9116, -0.6339]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2854, -0.3227,  0.0585,  0.2638, -1.0940]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7476, -0.2108, -0.5442,  0.6655, -0.2714]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5184,  0.1493, -0.8683,  0.5956,  0.0235]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4094,  0.1837, -0.3662,  0.1849, -0.2326]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0946, -0.3248, -0.0408,  0.5302, -0.9523]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2200,  0.2357, -0.4054,  0.0957, -0.0048]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3394,  0.0949, -0.6748,  0.4630,  0.0655]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8391,  0.0817, -0.4273,  0.1849, -0.4092]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0508,  0.0756, -0.6263,  0.5023,  0.3383]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9405, -0.0553, -0.4174,  0.3161, -0.5730]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5363,  0.4667,  0.1001, -0.4425, -0.7618]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1524,  0.2882, -0.2565, -0.1753,  0.0452]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2926,  1.1162, -0.0358, -1.3853,  0.2143]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1524,  0.2882, -0.2565, -0.1753,  0.0452]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0281, -0.2996, -0.1661,  0.5772, -0.7906]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0695,  0.8093, -0.2066, -0.7736,  0.0423]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7298,  0.0083, -0.1956,  0.3240, -0.6307]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0562, -0.1608, -1.0275,  1.2252, -0.4627]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6614, -0.0899, -0.4181,  0.4634, -0.2913]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7099,  0.7877,  0.0256, -1.3070, -0.6559]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1799,  0.2350, -0.1581, -0.1683, -0.0518]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7073,  0.3436, -0.3545, -0.2433, -0.4262]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4037,  0.0945, -0.2719,  0.1961, -0.1644]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2272,  0.3840, -0.1030, -0.4804,  0.3496]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6057, -0.1478, -0.5642,  0.7438, -0.2109]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0080,  0.6087,  0.3037, -0.9686, -1.2730]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3332,  0.0163, -0.3696,  0.2756, -1.0816]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0528, -0.3625,  0.0428,  0.6346, -1.0895]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1627,  0.5393, -0.1503, -0.8562,  0.1068]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7328, -0.6907, -0.5579,  1.3692, -0.1670]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6825,  0.0363, -0.5205,  0.1640, -0.1975]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9679, -0.4334, -0.0993,  0.6622, -0.7868]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3911, -0.5148, -0.8252,  1.4611, -0.7480]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5955, -0.0659, -0.5293,  0.6461, -0.2886]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0721,  0.3819, -0.4163,  0.0836,  0.0659]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5749, -0.1449, -0.6830,  0.9439, -0.1906]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8536, -0.0308, -0.4361,  0.4080, -0.5260]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3228,  0.6062, -0.2515, -0.8031, -0.0531]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1768,  0.1136, -0.5197,  0.0967,  0.3451]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3047, -0.5089, -0.4254,  1.2341, -0.9333]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4629, -0.1909, -0.5443,  0.7227, -0.0341]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0643,  0.4244, -0.3047, -0.2735,  0.2086]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2547,  0.3141, -0.2483, -0.3170, -0.0258]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4294, -0.7014, -0.0717,  1.3374, -2.3057]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0056,  0.0523, -0.1421,  0.2420, -0.9294]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6405,  0.4203, -0.1986, -0.3415, -0.5215]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3091,  0.1011,  0.2292, -0.6154, -0.1820]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1523,  0.2313, -0.7026,  0.2764,  0.3109]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8393,  0.5155,  0.0958, -0.7692, -0.9325]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0113, -0.3202, -0.5223,  0.9471, -0.6478]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6721, -0.4195, -0.5299,  1.2717, -0.3474]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1505, -0.4268, -0.5986,  1.3660, -0.8164]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4595, -0.1366,  0.4745, -0.3750, -1.4660]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3190,  1.0213,  0.0315, -1.4710,  0.3635]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6038,  0.5752,  0.3418, -1.0449, -0.7815]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0662,  0.6091, -0.2747, -0.4933,  0.1584]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5916,  0.4400,  0.4011, -1.1547, -0.6556]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0545,  0.6493, -0.3513, -0.5122,  0.2059]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1455,  0.3984, -0.2811, -0.3142,  0.0362]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0689,  0.0869, -0.2779,  0.2260, -0.8907]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2616,  0.6356, -0.2735, -0.5970, -0.1673]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7096, -0.0219,  0.1163, -0.2095, -0.5342]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0642,  0.8732, -0.0036, -1.5176,  0.1048]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2244, -0.1645, -0.4054,  0.6301, -0.9136]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5608,  0.3314,  0.1058, -0.4746, -0.6306]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2585,  0.0405, -0.2341,  0.1044, -0.0229]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1475,  0.3347,  0.2992, -0.7049, -1.2689]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0377,  0.2845, -0.2931, -0.4167,  0.3644]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2613,  0.3461, -0.4444, -0.0498,  0.0392]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2069,  0.2669, -0.4113, -0.0285,  0.0487]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7472,  0.3273, -0.1062, -0.3692, -0.6728]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4369, -0.1908, -0.5909,  1.1412, -1.2213]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5082,  0.2188, -0.2727,  0.0268, -0.2668]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8269,  0.0493, -0.2669,  0.4006, -0.7592]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9262, -0.0196, -0.3968,  0.3777, -0.5998]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6551,  0.1837, -0.2927,  0.0813, -0.4932]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1042,  0.9261, -0.0584, -1.3433,  0.0197]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0070e+00, -7.6951e-01,  1.8537e-03,  1.0711e+00, -1.7007e+00]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9600, -0.2403, -0.9897,  1.3311, -0.3987]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6037,  0.3714, -0.3070, -0.2606, -0.4087]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8706, -0.4189, -0.1980,  0.7521, -0.6303]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4083, -0.5492, -0.1449,  0.6253, -0.9683]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2477, -0.4113, -0.6526,  1.2125, -0.8122]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8583, -0.6286, -0.2058,  0.9578, -0.5455]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0680,  0.1367, -0.1472, -0.0556,  0.0488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0489, -0.2818, -0.5807,  0.7550, -0.5165]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2639,  0.5226, -0.2013, -0.7990, -0.0094]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2477,  0.2802, -0.7669,  0.5387,  0.1115]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8343, -0.0119, -0.5027,  0.6517, -0.6020]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2050,  0.2657, -0.4976,  0.1382,  0.0639]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5414,  0.3304, -0.0807, -0.5191, -0.3568]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7765, -0.0243, -0.4579,  0.2983, -0.3846]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2285,  0.3689, -0.3144, -0.2495,  0.4498]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1675,  0.1607, -0.7028,  0.4110, -0.6892]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4164, -0.4782, -0.2602,  1.2255, -1.2998]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3693,  0.0036, -0.5138,  0.2858,  0.0891]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2362,  0.0308, -0.4627,  0.3367,  0.0983]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1554,  0.7389, -0.1115, -0.8120, -0.1820]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3925,  0.1041, -0.5329,  0.5041, -0.1237]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0680,  0.1367, -0.1472, -0.0556,  0.0488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0458, -0.6404, -0.2570,  1.2162, -1.7236]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5247,  0.1952, -0.4946, -0.0651, -0.0577]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3416,  0.2221, -0.4922,  0.1506, -0.0602]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3109,  0.5427,  0.2834, -0.8340, -0.4828]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3965,  0.5228, -0.0655, -0.5644, -0.3573]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1757,  0.8607,  0.1535, -1.1281, -0.0802]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4020,  0.4545, -0.5985, -0.1361, -0.0183]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6250,  0.1155,  0.0167, -0.3400, -0.4774]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7434, -0.0437, -0.4856,  0.5958, -0.4585]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1193,  0.0981, -0.3753,  0.0813,  0.2820]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8485, -0.3782, -0.8475,  1.3161, -0.2392]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9613, -0.1293,  0.1464,  0.2394, -2.0142]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6997,  0.1085, -0.2791,  0.2627, -0.5734]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5812, -0.3558, -0.5355,  1.0530, -0.1822]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6058, -0.0378, -0.4307,  0.3697, -0.2465]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1447,  0.4102, -0.2769, -0.2162, -0.0227]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8974, -0.0938, -0.2994,  0.3299, -0.6047]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9498,  0.0132, -0.3935,  0.3628, -0.6525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1994,  0.3945,  0.0696, -0.3829, -1.3373]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0079,  0.4354,  0.0120, -0.7485,  0.1583]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0804,  0.2594, -0.3610, -0.2852, -0.6525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0716,  0.1393, -0.6333,  0.3418,  0.3872]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2857, -0.6144, -0.2371,  1.1563, -1.0687]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1618,  1.0083, -0.4386, -0.9953,  0.3981]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9330, -0.3375, -0.7843,  1.2491, -0.4492]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0454, -0.1404, -0.2897,  0.4023, -0.8078]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0613,  0.2104, -0.3568, -0.0501,  0.2216]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5382, -0.2876, -0.6037,  0.8548,  0.0275]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4107,  0.2668, -0.2054, -0.0354, -0.3437]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3134,  0.2618, -0.2644, -0.0590, -0.1572]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0752, -0.5199,  0.1769,  0.3845, -0.9156]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7852,  0.2589, -0.4715,  0.0322, -0.4609]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5327,  0.4663, -0.1533, -0.4875, -0.4812]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2726,  0.7293, -0.1482, -0.9144,  0.3574]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9067,  0.2170, -0.0205, -0.2782, -0.8363]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8317, -1.1023, -0.2465,  2.2960, -2.7252]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3135,  0.0174, -0.7799,  0.6013, -0.7288]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1182, -0.7994, -0.4559,  1.7003, -0.7508]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0754,  0.9623, -0.2221, -1.2289,  0.2552]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2471,  1.0432, -0.5015, -0.9724,  0.5066]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5452,  0.1610, -0.3613,  0.1446, -0.2791]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0199,  0.4091, -0.0649, -0.3785, -1.0021]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4113,  0.6107,  0.2815, -0.9964, -0.5606]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2080,  0.7180,  0.1970, -0.8477, -0.4878]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0888,  0.7336, -0.2971, -0.7664,  0.1141]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3447, -0.4942, -0.5563,  1.2656, -0.9158]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5489, -0.0691, -0.1012, -0.0011, -0.2529]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4454,  0.2708, -0.3234, -0.0528, -0.2299]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7311, -0.8078, -0.8582,  2.2911, -1.2834]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8541, -0.3392, -0.8352,  1.4053, -0.3966]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1681, -0.5156, -0.1546,  1.0236, -1.0018]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4151, -0.3660, -0.1667,  0.7234, -0.2244]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1169,  0.2738, -0.3925, -0.1552,  0.2595]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9088, -0.0780, -0.2833,  0.2276, -0.6157]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1754,  0.4090, -0.3828, -0.2487,  0.4218]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8414, -0.1029, -0.2258,  0.3635, -0.6254]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9716, -0.1112, -0.5738,  0.5381, -0.4697]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8101,  0.1822, -0.5556,  0.0269, -0.3449]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4278, -1.2805, -0.4848,  2.0293, -1.7950]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8837, -0.0702, -0.2538,  0.6593, -0.8584]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6906,  0.5274, -0.4998, -0.3110, -0.3498]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0350,  0.5407, -0.3636, -0.4233,  0.2337]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7358,  0.1853, -0.2362, -0.0688, -0.5411]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2709,  0.4634, -0.0198, -0.6612, -0.2664]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0179, -0.4961, -0.5261,  1.3529, -0.7422]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0525,  0.9363,  0.1590, -1.3988, -0.1698]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0860,  0.3033, -0.3324, -0.1519,  0.1532]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1824,  0.4546,  0.1495, -0.4975, -1.3058]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8200, -0.9696, -1.0114,  2.3945, -1.1184]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6641, -0.2008, -0.3753,  0.4227, -0.2073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7526,  0.4764, -0.2095, -0.5052, -0.5952]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0256,  0.5553, -0.3668, -0.4171,  0.2329]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6354,  0.4575, -0.3793,  0.0190, -0.5887]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6966, -0.2185, -0.5276,  0.8260, -0.3486]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6237,  1.1101,  0.0150, -1.5672,  0.6075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5658, -0.1572, -0.5494,  0.8342, -0.2213]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2529,  0.3152, -0.0816, -0.3563, -0.2118]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3103,  0.2696, -0.0082, -0.2637, -0.3051]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7999,  0.1716, -0.2579,  0.0827, -0.6673]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2801,  0.5492,  0.0780, -0.8758, -0.2983]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6062, -0.0653, -0.5112,  0.5026, -0.2409]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8442,  0.2994, -0.2340, -0.2126, -0.6729]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4717,  0.5876, -0.1812, -0.4100, -0.4948]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2864, -0.0101, -0.3655,  0.3785, -0.0079]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1454,  0.7354, -0.0886, -0.9729,  0.1828]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6308,  0.7381, -0.3216, -0.9478,  0.9602]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8962,  0.1938, -0.1092,  0.0128, -0.9179]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4132,  0.4192,  0.0427, -0.3968, -0.5145]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4229, -0.3457, -0.7422,  1.2235,  0.0583]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1757,  0.1958, -0.0907, -0.2635,  0.0105]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1192,  0.2649, -0.6578,  0.2696,  0.2370]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6478, -0.7564, -0.5049,  1.8204, -1.3346]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3061,  0.3663, -0.4262, -0.1973, -0.0242]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5491,  0.8613, -0.0045, -1.2513,  0.6143]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4023,  0.3401, -0.4307, -0.0703, -0.1123]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0990,  0.0325, -0.6101,  0.6606,  0.2247]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8153, -0.5220, -0.2701,  1.3185, -1.7007]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3257, -0.9985, -0.3368,  1.7063, -1.9107]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6862,  0.3183, -0.1133,  0.2747, -1.9411]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2241,  0.1568, -0.2077, -0.0807,  0.4046]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1636,  0.0178, -0.0084, -0.0040, -0.1163]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1478, -0.6628, -0.0227,  1.1180, -1.0347]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3580,  0.3707, -0.1565, -0.5478, -1.1283]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7654, -0.3749, -0.4544,  0.9854, -0.4115]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1701,  0.4276, -0.1200, -0.3916, -0.1269]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1933, -0.3453, -0.6160,  1.0756, -0.7169]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9824, -0.2405, -0.1981,  0.3263, -0.6190]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0422,  0.2590, -0.3589, -0.0981,  0.2399]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2461,  0.1137,  0.0336, -0.1885, -1.2012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9853, -0.2580, -0.5932,  0.9003, -0.5395]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5449,  0.7554, -0.1385, -1.3315,  0.9161]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5982,  0.3741, -0.1154, -0.4541, -0.4930]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4208, -0.4315, -0.2282,  0.9917, -1.2198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4297,  0.3987, -0.6819,  0.0149, -0.0019]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1550,  0.6257, -0.3264, -0.4652,  0.2916]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3353, -0.0194, -0.3465,  0.6217, -0.2531]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4579,  0.0224, -0.0356,  0.1223, -0.4212]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1550,  1.0090, -0.1127, -1.1012, -0.2085]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0558,  0.2524, -0.2688, -0.1245,  0.1302]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1799,  0.7621, -0.0684, -0.7383, -0.2955]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6937, -0.2690, -0.6282,  1.0609, -0.2863]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3023, -0.2948, -0.5074,  0.9620, -0.9555]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1221,  0.3052,  0.0427, -0.4533, -0.1265]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5980, -0.1051, -0.4459,  0.6487, -0.3246]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3471,  0.1639, -0.1849,  0.0328, -0.2709]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4076,  0.1114, -0.7026,  0.5162, -0.0191]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4868,  0.8060,  0.2557, -1.2179, -0.6878]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1165,  0.1142, -0.4493,  0.1716,  0.1931]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8010, -0.1586, -0.1518,  0.2770, -0.5861]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8432, -0.3407, -0.6200,  0.9932, -0.3224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0411,  0.0758, -0.1184, -0.0147, -0.9190]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2993, -0.3147, -0.4383,  1.0542, -1.0890]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5345, -0.1154, -0.5135,  0.6505, -0.1971]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6461, -0.6676, -0.0193,  1.1585, -1.5075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8730, -0.2382, -0.3432,  0.7783, -0.6779]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6069,  0.3041, -0.1894, -0.2794, -0.4728]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1376,  0.4621, -0.2896, -0.3442, -0.0012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2971,  0.3607, -0.5505, -0.0248,  0.7008]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1999, -0.1012, -0.4050,  0.4937,  0.1086]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0354,  0.6238, -0.0968, -0.6585,  0.0479]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8989, -0.4421, -0.4492,  1.2415, -0.6504]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4478,  0.5684, -0.3605, -0.4902,  0.7216]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0818, -0.4415, -0.6074,  1.1189, -0.6169]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1204, -0.0134, -0.7703,  0.7475,  0.3662]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1054, -0.3661, -0.0181,  0.3782, -1.7853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4997, -0.2577, -0.3295,  0.4464, -0.0797]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4369, -0.1027, -0.6838,  0.8708,  0.0059]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6425,  0.5617, -0.2216, -0.6137, -0.4641]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1130,  0.4059, -0.3312, -0.3242,  0.1081]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5418, -0.1486, -0.5975,  0.5852,  0.0012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8599, -0.5591, -0.3570,  0.9659, -0.4149]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6115,  0.3012, -0.1628, -0.3778, -0.3920]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0686, -0.3934, -0.4064,  0.9710, -0.7147]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3533,  0.2579, -0.3939, -0.0442, -0.0596]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2039, -0.4887, -0.1588,  0.7827, -0.8985]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2216, -0.3030, -0.5065,  0.9629,  0.1152]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4881,  0.1929, -0.2721, -0.0771, -0.2518]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4409,  0.4042, -0.0210, -0.4274, -0.4628]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2137,  0.5133, -0.4099, -0.4161,  0.0550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6489, -0.2218, -0.8746,  1.1740, -0.1002]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4646, -0.1788, -0.4502,  0.6780, -0.1464]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8200, -0.2190, -0.1129,  0.6957, -1.7697]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3234,  0.0322, -0.3769,  0.3146, -0.0234]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0769,  0.3319, -0.0476, -0.5150,  0.0885]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2693,  0.9121, -0.3510, -0.7983, -0.2105]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2230,  0.4225, -0.0360, -0.6541, -0.1038]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0449,  0.2227, -0.3863,  0.1610, -0.8052]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5651,  0.3677,  0.0225, -0.4242, -0.6174]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7104, -0.3172, -0.7187,  1.1645, -0.2504]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3686, -0.4232, -0.8908,  1.7564,  0.0534]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3953,  0.0037, -0.6336,  0.4447,  0.0742]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4460,  0.0987, -0.3273,  0.1505, -0.2288]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7247, -0.0851, -0.6792,  0.7799, -0.2769]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5859,  0.7002, -0.1293, -0.6527, -0.5554]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2865,  0.1573,  0.0948, -0.0880, -1.4008]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1624, -0.4248, -0.8558,  1.4850, -0.6303]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8757,  0.3245, -0.3295, -0.2205, -0.6277]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2054,  0.1085, -0.4007,  0.1158,  0.1433]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2800,  0.7591,  0.1037, -1.0769, -0.4143]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4562,  0.2742, -0.3242, -0.0297, -0.2823]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8923,  1.2859,  0.2260, -1.9598,  0.7120]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1295,  0.1450, -0.4493,  0.3118,  0.1016]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8963, -0.2870, -0.2653,  0.7539, -0.7091]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0970,  1.0091,  0.1066, -1.2968, -0.2899]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8165, -0.3587, -0.6897,  1.2833, -0.4207]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0920, -0.0122, -0.3717,  0.4738, -0.8466]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2199,  0.8802, -0.3247, -1.0582,  0.4505]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0676, -0.3499, -0.1208,  0.4635, -0.8003]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5167,  0.5187,  0.2228, -0.6605, -0.7877]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9899, -0.5760, -0.8705,  1.7521, -0.3856]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7220,  0.0494, -0.4311,  0.4559, -0.5017]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0089,  0.2759, -0.3519,  0.0524,  0.2222]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0041,  0.2068, -0.2800, -0.1383,  0.2865]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1326,  0.5236,  0.1538, -0.9351, -1.0837]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2181, -0.4558, -0.4868,  1.0796, -0.8089]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0856, -0.5519,  0.4513,  0.6223, -2.2407]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1414,  0.4158, -0.3482, -0.5004,  0.2531]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2968,  0.3850, -0.3249, -0.1538, -0.1404]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0583,  0.2539, -0.2578, -0.1592,  0.2959]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3521, -0.0756, -0.5426,  0.5755,  0.0968]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3483, -0.0692, -0.3265,  0.5011, -0.1472]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5735,  0.2351, -0.7116,  0.5166, -0.2631]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7921, -0.6211, -0.2956,  1.0808, -1.3895]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4257, -0.1709, -0.6171,  0.8430, -0.0049]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4398,  0.9337,  0.5445, -1.1466, -2.1251]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4434, -0.1750,  0.1915,  0.2538, -1.5227]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2168, -0.6442, -0.6297,  1.4409, -0.6825]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4844,  0.1662, -0.2441,  0.0380, -0.3264]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3487,  0.3965, -0.5850,  0.1012, -0.0999]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4747, -0.2480, -0.7611,  1.1583, -0.0090]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3326,  0.3169, -0.2568, -0.4995, -0.9686]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4256, -0.0395, -0.5782,  0.7976, -0.1446]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1716,  0.1311, -0.4433,  0.1511,  0.2389]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2222, -0.2119, -0.0928,  0.1208, -0.8106]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0643, -1.4226, -0.9815,  3.2042, -1.4490]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0929,  0.2961, -0.4992,  0.0871,  0.2629]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8206, -0.1726, -0.3589,  0.8222, -0.6892]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2369, -0.2677, -0.4330,  0.8896,  0.0560]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5494, -0.3126,  0.0412,  0.1823, -1.2999]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9319,  0.1698,  0.1854,  0.1628, -1.2854]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4190, -0.1437, -0.4712,  0.7561, -0.1261]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9007, -0.1201, -0.5227,  0.7106, -0.5889]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8834,  0.6014,  0.1654, -0.7887, -2.0761]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1581,  0.0382, -0.2784,  0.2621,  0.0359]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7997, -0.4669, -0.6067,  1.5708, -0.5139]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3983, -0.4433, -0.5878,  1.3359, -0.9495]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1707,  0.9759, -0.5108, -0.8863,  0.4356]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5267,  0.0827, -0.3392,  0.1167, -0.2098]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0716,  0.2921, -0.2836, -0.1872,  0.1589]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0941,  0.1916, -0.1919, -0.1022,  0.0614]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1312,  0.2743, -0.0687, -0.3818, -0.9646]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3928,  0.1757, -0.1910, -0.1017, -0.2275]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4282,  0.1413, -0.4307,  0.0292,  0.0012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6240,  0.1821, -0.2021, -0.0292, -0.5119]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3608,  0.0623, -0.2907,  0.0273,  0.0072]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0713,  0.4385, -0.2833, -0.4307,  0.3193]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7444,  0.5947, -0.1218, -0.7808, -0.6356]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5900,  1.1277,  0.4440, -1.7179, -1.0292]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5210,  0.1182, -0.2208,  0.0409, -0.3337]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4137, -0.2635,  0.6131,  0.1632, -1.7572]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4599, -0.2100,  0.0905,  0.1845, -1.3422]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6304, -0.0515, -0.1907,  0.2613, -0.4280]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6154, -0.1637, -0.2480,  0.3142, -0.3100]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4279, -0.0429, -0.6932,  0.5157,  0.1353]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4546, -0.0259, -0.1368,  0.0587, -0.2245]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2817, -0.2773, -0.3277,  0.8068, -1.0583]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8661, -0.3405, -0.5590,  0.7507, -0.3204]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1048, -0.6299, -0.6189,  1.5143, -0.6554]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4715, -0.8800, -0.7548,  1.9515, -0.8775]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8690,  0.0972, -0.1662,  0.0528, -0.7521]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2532,  0.4088, -0.0698, -0.4722, -0.1999]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3231,  0.1956,  0.3304, -0.5734, -0.4383]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4313, -0.2492, -0.7111,  1.0369,  0.0085]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5587,  0.3602, -0.6013,  0.0258, -0.1824]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8829, -0.1610, -0.7231,  0.7831, -0.3401]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5771, -0.1848, -0.6932,  0.7933, -0.0369]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2970,  0.1664, -0.2677, -0.1165, -0.0498]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0376,  0.8492,  0.0434, -1.0340, -0.0631]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3581,  0.4216, -0.2646, -0.4756,  0.6535]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5019, -0.6049,  0.4041,  0.1414, -1.3805]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9022, -0.3425, -0.7390,  1.1920, -0.3783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2149, -0.3104, -0.8095,  1.3766, -0.7550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6971,  0.1246,  0.4595, -0.1788, -2.0258]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9566, -1.1813, -0.0358,  1.9280, -2.7959]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1197,  0.1327, -0.8094,  0.3504,  0.5305]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9523, -0.2192, -0.3520,  0.5121, -0.5783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4072,  0.7429, -0.0530, -0.5501, -1.6018]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7747, -0.3335, -0.1063,  0.5939, -0.5631]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8396, -0.9897, -0.1167,  1.6179, -1.6557]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4519,  0.3615, -0.0164, -0.4972, -0.3483]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3406, -0.1333, -0.2859,  0.5855, -1.1651]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0768,  0.7558, -0.0820, -0.7220, -0.0375]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4082,  0.0801, -0.1244,  0.1015, -0.3157]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3636, -0.2166, -0.5049,  0.6486,  0.1024]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4444, -0.2284, -0.7450,  1.0235,  0.1214]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6402, -0.4364, -0.1586,  0.6865, -1.3622]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0399,  0.0229, -0.4491,  0.1268, -0.5016]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7199, -0.2618, -0.1452,  0.4698, -0.4972]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3127,  0.6549, -0.1914, -0.6198, -0.2751]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0785,  0.8137, -0.2728, -0.9514,  0.0704]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6505, -0.5774, -0.2768,  1.0199, -1.3549]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4064,  0.4683, -0.4541, -0.1910, -0.1663]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7685, -0.1842, -0.2732,  0.4478, -0.4853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0122, -0.6923, -0.7285,  1.8928, -0.5947]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4871,  0.4027, -0.3348, -0.2419, -0.3060]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4274,  0.7164, -0.4016, -0.4840,  0.5908]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4586,  0.3844, -0.6301,  0.0111,  0.8809]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7467,  0.3098,  0.2335, -0.4329, -1.9163]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5412, -0.0015, -0.3644,  0.2610, -0.2263]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0499,  0.0637, -0.0029, -0.2337,  0.2580]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6880, -0.5720, -0.8227,  1.7238, -0.2075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5465,  0.1741, -0.1465, -0.1209, -0.4189]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3776, -0.0340, -0.3700,  0.5830, -1.2136]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0356,  0.5099, -0.3684, -0.3224,  0.1471]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7842, -0.0788, -0.5651,  0.6501, -0.4121]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3661, -0.6622, -0.8760,  2.1842,  0.0115]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6648, -0.1443, -0.0250,  0.1685, -0.5281]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4864, -0.7125, -0.2773,  1.5931, -1.3258]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3597,  0.1447, -0.6616,  0.4212,  0.0456]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4172, -0.2905, -0.3728,  0.8743, -0.1420]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0050,  0.6482, -0.1029, -0.5701, -0.0976]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0613, -0.1791, -0.1697,  0.5025, -0.8726]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1044, -0.1207, -0.4942,  0.5937,  0.3053]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2269, -0.1733, -0.6116,  0.6324,  0.3241]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4009, -0.3218, -0.5326,  0.9769, -0.0164]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6072,  0.1352, -0.1680,  0.0185, -0.4927]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0724,  0.3654, -0.5032, -0.0830,  0.2649]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8397, -0.5818, -0.4822,  1.3081, -0.4722]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3958,  0.0041, -0.4018,  0.2414, -0.0271]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0543,  0.2830, -0.3949, -0.0829,  0.4002]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2897,  0.0273, -0.7847,  0.6268,  0.2701]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3645,  0.4341, -0.6213, -0.1695,  0.0496]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5838,  0.7364, -0.3760, -0.5815, -0.4580]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2580,  0.1752, -0.0799, -0.3582, -0.0363]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4246,  0.1073, -0.3315,  0.1516, -0.1939]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7521, -0.1459, -0.2885,  0.5970, -0.5911]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1406,  0.3559, -0.0617, -0.3468, -0.1583]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3551,  0.3934, -0.5128,  0.0244, -0.0657]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1172, -0.2868, -0.5392,  0.9875, -0.7564]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1682,  0.5356, -0.1120, -0.7856, -0.0336]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0941,  0.1916, -0.1919, -0.1022,  0.0614]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6440, -0.2515, -0.2605,  0.4267, -0.3144]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1115,  0.2552, -0.1566, -0.1886, -0.0188]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3116,  0.2311, -0.4996,  0.1960, -0.0335]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5541, -0.1878, -0.7038,  1.0325, -1.1365]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8149,  0.0523, -0.4524,  0.3587, -0.5448]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2509, -1.1796, -0.8665,  2.7501, -0.6947]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5089,  0.0911, -0.0471, -0.2821, -0.3295]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8679,  0.1425, -0.0935, -0.2677, -0.6060]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2770,  0.3497, -0.5138,  0.0418,  0.0137]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4267, -0.2005, -0.5173,  0.9349, -0.1201]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1134, -0.2289, -0.7086,  0.8525, -0.5491]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1841,  0.3299, -0.4601,  0.0486,  0.0945]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0810, -0.1445, -1.1463,  1.2330, -0.3583]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4068,  0.8178, -0.3156, -0.8235,  0.5753]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5963, -0.0308, -0.2832,  0.3338, -0.3606]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0174,  0.3497, -0.0075, -0.6751,  0.2339]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4314,  0.2002, -0.4622,  0.1288, -0.0853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7220, -0.0096,  0.3198, -0.4565, -0.7006]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8450,  0.2433, -0.1649, -0.3516, -0.5908]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2253,  0.4021, -0.5029, -0.0630,  0.0747]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0353,  0.4416, -0.3869,  0.0226,  0.1581]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8942, -0.3494,  0.0464,  0.2352, -0.6747]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4988, -0.0788, -0.5214,  0.6593, -0.2137]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3215,  0.0721, -0.2601,  0.0496, -0.0391]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9816, -0.1418, -0.1355,  0.2785, -0.8119]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1844,  0.6029, -0.2083, -0.7700,  0.4073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6783,  0.0926,  0.1552, -0.2794, -0.6806]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0033,  0.0642, -0.3888,  0.2429,  0.3302]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2301,  0.8331, -0.0690, -1.1095,  0.2550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5617,  0.6916, -0.1348, -0.9126,  0.7297]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5122,  0.1263, -0.1195,  0.0083, -0.4791]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6412,  0.2346,  0.2885, -0.6666, -0.6595]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7676,  0.2657, -0.3257, -0.0971, -0.5602]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0031,  0.8719,  0.0721, -1.2543, -0.0945]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2762, -0.4396, -0.2731,  0.8239, -0.9606]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6851,  0.6343, -0.2798, -0.7887,  0.9711]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1613,  0.0127, -0.4249,  0.1007,  0.3497]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3674,  0.7627,  0.3059, -1.1893, -1.6486]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4044,  0.8193, -0.3937, -0.8432,  0.6737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0763,  0.2915, -0.6387,  0.0347,  0.4674]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5059,  0.3665, -0.1450, -0.3721, -0.3953]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0460,  0.5683, -0.7858, -0.1579, -0.5947]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6672, -0.6043, -0.5970,  1.5516, -0.3054]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3176,  1.1382, -0.1409, -1.1786,  0.1657]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0721,  0.0953, -0.6593,  0.3170,  0.6282]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0371,  0.1644, -0.3373,  0.0748,  0.2528]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1807, -0.3590, -0.2528,  0.9630, -1.0432]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4159,  0.1662, -0.6276,  0.2678,  0.0413]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8694,  0.8316,  0.0655, -1.1169, -0.9904]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8669, -0.0915, -0.1166,  0.5415, -0.8708]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0591,  0.5313, -0.3900, -0.4272,  0.1885]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9453, -0.0928, -0.0966,  0.0341, -0.6645]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4717, -0.0730, -0.6645,  0.7736, -0.0744]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6913,  0.4256, -0.0403, -0.3647, -0.7608]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0001, -0.4656, -0.7884,  1.5011, -0.4933]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1393,  0.3252, -0.3239, -0.2263,  0.1636]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7296, -0.0325, -0.2582,  0.4597, -0.6272]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1433,  0.3744, -0.2349, -0.2393,  0.2533]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5247,  0.2916, -0.2017, -0.2875, -0.3518]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2179, -0.2664, -0.5535,  1.0091,  0.1217]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5613, -0.5211, -0.1245,  0.8463, -1.3345]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6975, -0.2916, -0.7682,  1.1653, -0.2146]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1959, -0.1101, -0.7314,  0.6633, -0.6138]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6272,  0.3923,  0.2063, -0.6770, -0.7716]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5549, -0.0450, -0.2114,  0.2557, -0.3774]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6657, -0.2006, -0.6326,  0.8444, -0.2109]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4406, -0.3600, -0.5032,  0.9415, -0.0609]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8885,  0.2501, -0.2409,  0.1479, -0.8323]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0767,  0.8290, -0.4351, -0.6338,  0.2261]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6093, -0.0793, -0.1483,  0.2959, -0.4666]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4391,  0.1417, -0.2869,  0.1381, -0.2189]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6002,  0.2089, -0.2484, -0.0394, -0.4154]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2934,  1.0569,  0.1532, -1.4634,  0.0996]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5834,  1.0333, -0.2282, -1.0465,  0.5646]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6933,  0.2607, -0.6268,  0.2073, -0.2936]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4854, -0.4634, -0.6629,  1.3236,  0.0058]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1497,  1.0835, -0.2398, -1.1488,  0.1773]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0090,  0.2030, -0.0826, -0.0335, -0.0003]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2601, -0.2106, -0.4914,  0.9102, -1.0009]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3823,  0.2955, -0.0885, -0.2612, -0.3459]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6308, -0.5240, -0.6925,  1.4658, -0.1561]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2152,  0.8269, -0.1911, -1.0797,  0.3701]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4919, -0.0187, -0.4414,  0.5321, -0.2258]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4469,  0.7278, -0.7430, -0.3165, -0.0395]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0821,  0.7994,  0.2785, -1.5062,  0.0540]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3494,  0.4119, -0.3824, -0.4701,  0.0269]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3840, -0.2083, -0.5175,  0.7536,  0.0189]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7315,  0.1432, -0.6643,  0.3838, -0.3286]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6176,  0.2244, -0.1098, -0.0458, -0.6455]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5926, -0.0640, -0.4680,  0.5555, -0.2725]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3795,  0.6109,  0.1441, -0.8570, -0.5161]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8471, -0.1109,  0.3491,  0.4131, -2.2044]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0802,  0.4915, -0.3385, -0.3700,  0.1658]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9122,  0.2551, -0.1777, -0.2171, -0.7341]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6718,  0.2732,  0.1383, -0.3619, -0.7734]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1849,  0.5124, -0.4362, -0.5353,  0.2170]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2888, -0.1054, -0.3435,  0.4827, -0.0367]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1567, -0.1443, -0.2459,  0.5932, -1.0218]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3864, -0.0437, -0.6608,  0.5150,  0.1776]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6234, -0.4967, -0.9266,  1.6164, -0.0154]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0015, -0.0606, -0.4728,  0.4858,  0.3558]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3334, -0.4015, -0.6774,  1.2685, -1.8730]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7773, -0.0048, -0.5216,  0.6338, -0.4911]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6251,  0.3629, -0.0299, -0.4392, -0.5898]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0328,  0.4567, -0.0021, -0.7813,  0.1818]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5336, -0.4322, -0.3987,  0.8717, -1.1493]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0664,  0.9310, -0.0383, -0.9372, -0.2916]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2790,  0.0796, -0.4935,  0.2461,  0.1194]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3818,  0.4362, -0.3027, -0.2532, -0.2182]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6313, -0.4641, -0.3648,  1.0385, -0.3476]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7832, -0.3687, -0.7568,  1.2287, -0.2344]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6030, -0.1356, -0.5304,  0.8067, -0.2865]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9416, -0.1680, -0.2401,  0.5852, -0.8415]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2014,  0.0009, -0.3083,  0.2571,  0.1075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9477, -0.0633, -0.3982,  0.5821, -0.7187]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3751,  0.4425, -0.3845, -0.5281,  0.7627]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6847, -0.1747, -0.2349,  0.4889, -0.4938]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7361, -0.2712, -0.2235,  0.5869, -1.4853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0388,  0.6733, -0.0085, -0.8897,  0.0289]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3751,  0.8051, -0.0677, -1.1071,  0.5038]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9340, -0.4992, -0.8475,  1.4725, -0.3154]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8984, -0.2736, -0.8338,  1.2965, -0.3952]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8539, -0.1088, -0.7972,  0.9742, -0.3737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7120,  0.1214, -0.2871, -0.0816, -0.3224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7869, -0.4238, -0.5430,  1.1413, -1.3464]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4705,  0.0703, -0.3240,  0.3469, -0.3019]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2523,  0.5074, -0.1863, -0.4210,  0.3184]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2963,  0.0231, -0.4880,  0.3948,  0.0515]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8305, -0.0365, -0.3750,  0.3506, -0.4853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7931,  0.3247, -0.5174, -0.0077, -0.4718]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3883,  0.8989, -0.1953, -0.9970,  0.4055]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1516,  0.4401,  0.1077, -0.6663, -0.1751]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3109, -0.3797, -0.8958,  1.4971,  0.2151]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1443,  0.6615, -0.4287, -0.4377,  0.3228]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4613, -0.3936, -0.7720,  1.3468,  0.0569]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0560,  0.5034, -0.4748, -0.3555,  0.3802]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6455, -0.0818, -0.5321,  0.3468, -0.1161]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8130, -0.1098, -0.2640,  0.5885, -0.7289]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6356, -0.1623, -0.4793,  0.5471, -0.2392]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0927,  0.7355, -0.1782, -0.9026,  0.0315]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6502,  1.0255, -0.0615, -1.3421,  0.6567]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2823, -0.5455, -0.4579,  1.2667, -0.9553]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3078,  0.5991, -0.5714, -0.2873, -0.0256]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4960, -0.4859, -0.6621,  1.5375, -1.1744]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0725,  0.1701, -0.2920, -0.0216,  0.1568]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4962,  0.5015, -0.3652, -0.2819,  0.6886]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2678,  0.4129, -0.1546, -0.7398,  0.0101]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2361, -0.1287, -0.3120,  0.5223, -1.0138]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1783, -0.4410, -0.3579,  1.0092, -1.8587]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4810, -0.1065, -0.5557,  0.6939, -0.1552]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4397, -0.4572, -0.4144,  1.0155, -0.0601]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0916,  0.2906,  0.2681, -0.4820, -1.2383]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4991,  1.1014, -0.0676, -1.5683,  0.5553]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0255, -0.1416, -0.6269,  0.9168, -0.6861]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2289,  0.1320, -0.7303,  0.6794,  0.1314]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9051,  0.1808, -0.1533, -0.1644, -0.6793]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4718e-04,  4.2514e-01, -4.2908e-02, -5.4987e-01,  4.9504e-02]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1137, -0.2296, -0.5442,  0.8756, -0.7658]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2966, -0.3811, -0.6277,  1.2648, -0.9259]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0144, -0.0850,  0.3924,  0.3280, -2.4246]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6629, -0.1357, -0.5925,  0.8503, -0.3033]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4212, -0.7375, -0.6302,  1.4931, -0.8122]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3717,  0.1711, -0.3263,  0.0318, -0.1301]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3551,  0.3697, -0.0966, -0.3007, -0.3577]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2358,  0.2470, -0.1785, -0.1817, -0.0994]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0107,  0.5599, -0.1561, -0.5862,  0.0676]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0404,  0.3970, -0.4875, -0.1983,  0.3107]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5528,  0.4629, -0.5241, -0.0763, -0.3038]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8449,  0.3918, -0.2847, -0.3543, -0.5963]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7457, -0.1748, -0.3835,  0.5763, -0.4253]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3842, -0.6552, -0.5742,  1.5278, -0.9373]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9294, -0.0983, -0.5369,  0.7889, -0.6629]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1132,  0.7143, -0.2989, -0.7548,  0.0910]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3001, -0.1212, -0.0907,  0.2644, -1.1335]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4216,  0.2962,  0.2437, -0.5602, -0.5591]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5257, -0.8044, -0.0261,  1.2760, -1.3698]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3246,  0.2296, -0.2508, -0.3461, -0.0084]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2752,  0.3280, -0.4201,  0.1229, -0.1490]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6287,  0.1220,  0.4237, -0.8176, -0.6546]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3946,  0.1281,  0.3298, -0.5464, -0.4322]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2340,  0.2016, -0.2006, -0.1240, -0.0572]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3384,  0.4676, -0.3042, -0.1349, -0.3373]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2644,  0.8561,  0.0366, -0.8214, -0.5550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6240, -0.3634, -0.4217,  0.8839, -0.2334]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0125,  0.1225,  0.0966, -0.4070, -0.9188]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4027,  0.8358,  0.0941, -1.2063, -0.5235]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0937,  0.1728, -0.3204, -0.0896,  0.2025]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8629, -0.2042, -0.0150,  0.1841, -1.6329]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6502,  1.3184, -0.0792, -1.4788,  0.4738]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8428,  0.2290,  0.4791, -0.5100, -1.0868]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1337, -0.3043, -0.2864,  0.6721,  0.1880]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1142,  0.6452, -0.1931, -0.7038,  0.1822]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1593,  0.3833, -0.3182, -0.0765, -0.0368]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5239,  0.9671, -0.5110, -1.0579,  0.9693]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3515,  0.5205, -0.3118, -0.4115, -0.2165]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0383,  0.3276, -0.1437, -0.2494,  0.0444]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5014,  0.1282, -0.2082,  0.0875, -0.4292]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0979,  0.0933, -0.6350,  0.6459,  0.2257]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2838,  0.6227, -0.4342, -0.4285,  0.5012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2052,  0.5265, -0.4187, -0.5867,  0.5986]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3841,  0.4819, -0.1846, -0.5570, -0.1467]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4407,  0.2540, -0.0734, -0.2944, -0.3568]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2159,  0.4675, -0.3059, -0.1894, -0.1391]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0952,  0.4806, -0.2972, -0.6053,  0.2314]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9020, -0.1557, -0.4872,  0.5120, -0.4268]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0912,  0.7302, -0.1778, -0.7421, -0.0558]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0230,  0.3035, -0.0100, -0.3477, -0.0305]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3017, -0.0880, -0.4636,  0.3915,  0.1583]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2818,  0.2607, -0.4079,  0.0109,  0.5771]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3731,  0.7721,  0.3829, -1.2824, -0.6268]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0655,  0.2908, -0.7071,  0.1481,  0.3715]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1108,  1.0404, -0.2783, -1.0247,  0.1191]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2870,  0.4437, -0.2882, -0.3836, -0.0683]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3932,  0.3041, -0.3826, -0.1947,  0.7262]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0068,  0.9042, -0.3600, -1.0057,  0.2413]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1368,  0.2221, -0.6460,  0.5271,  0.1018]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2949,  0.5288, -0.0278, -0.8552,  0.4269]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0878,  0.8199, -0.0232, -0.9460, -0.0186]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7075,  0.1143,  0.0184, -0.4116, -0.5035]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6251,  0.0983, -0.2546,  0.2793, -0.5444]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2203,  0.4453,  0.1040, -0.8542, -0.1576]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1737, -0.0703, -0.5931,  0.6378, -0.8020]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1679,  0.4819, -0.6998,  0.0432,  0.1738]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6884,  1.0235, -0.1618, -1.4250,  0.8798]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4473,  0.4907, -0.4164, -0.4472, -0.0790]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1190,  0.6496, -0.2183, -0.7462,  0.0605]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4202, -0.3057, -0.6645,  0.9350,  0.1243]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0397,  0.8421, -0.1659, -1.0898,  0.1404]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4295,  0.8457, -0.1309, -0.9053,  0.3751]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0836,  0.4450, -0.1112, -0.5372,  0.1631]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1903,  0.5127, -0.2844, -0.3221, -0.0574]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3028, -0.1309, -0.4066,  0.6493, -0.0395]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2343,  1.2071, -0.0770, -1.3598,  0.1273]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2469, -0.1567, -0.1495,  0.3179,  0.0198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6383,  0.6674, -0.4070, -0.5294, -0.3771]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0702,  0.5786, -0.3922, -0.3900,  0.1216]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3900,  0.7771,  0.1284, -1.1772,  0.3682]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1340,  0.6648, -0.2575, -0.8090,  0.0956]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4179,  0.9558, -0.1328, -1.0961,  0.3851]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5604,  0.6686, -0.2542, -0.7970,  0.7903]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1295,  0.3926, -0.4995, -0.2053,  0.5417]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4975,  0.9889, -0.1550, -1.2634,  0.5991]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3526,  0.6649, -0.2573, -0.9175,  0.6486]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1270,  0.2187, -0.3043,  0.0929,  0.2839]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0043,  0.1200, -0.5137,  0.3810,  0.2956]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1901,  0.1039,  0.1933, -0.2479, -1.2357]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3559,  0.4434,  0.1405, -0.7258, -0.4363]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2812, -0.1929, -0.4928,  0.7666,  0.0736]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1809,  0.3835, -0.2905, -0.2361, -0.0423]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6967,  0.3480, -0.5900,  0.0337, -0.3111]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3578, -0.1584,  0.2438,  0.1793, -1.4074]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7488,  0.4723, -0.2400, -0.6703,  1.0768]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6602,  0.3453,  0.1195, -0.8102, -0.5521]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4284, -0.2627, -0.4762,  0.7104,  0.0208]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1513,  0.3019,  0.0059, -0.4663,  0.2359]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3334,  1.3470, -0.1088, -1.5273,  0.1672]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6525,  0.0077, -0.5320,  0.5162, -0.2917]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3300,  0.4253, -0.6437,  0.0235,  0.6978]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3336, -0.1436, -0.0218,  0.1153, -0.1582]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4076,  0.7831, -0.1053, -1.1630, -0.2465]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8052, -0.1640, -0.1145,  0.0656, -0.4719]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7730,  0.1890, -0.2850,  0.0652, -0.5925]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8296,  0.1957, -0.0372, -0.3762, -0.6620]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7378,  0.8404, -0.0511, -1.1366, -0.7029]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0207,  0.5717, -0.0448, -0.9186,  0.1508]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3496,  0.1280, -0.4755, -0.0099,  0.1884]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3896,  0.0155,  0.3785, -0.3759, -1.4432]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0418,  0.2135, -0.3332, -0.0088,  0.2910]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3697,  0.2301, -0.1709, -0.2009, -0.1450]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2265,  0.3140, -0.2341, -0.3134,  0.0242]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5636,  0.2500, -0.2732,  0.0191, -0.4141]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4701, -0.0759, -0.2583,  0.3469, -0.2419]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1259,  0.4297, -0.3248, -0.3064,  0.0624]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2145,  0.4892, -0.5126, -0.2596,  0.5634]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4159, -0.3530, -0.5597,  1.1546, -0.0707]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3331,  0.2764, -0.3160, -0.1046, -0.1141]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1171,  0.6241, -0.2975, -0.7134,  0.3881]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0607,  0.6093, -0.1401, -0.5653, -0.0194]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1201,  0.3801, -0.2065, -0.3803,  0.0449]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3263,  0.4163, -0.0949, -0.2614, -0.3622]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1537,  0.1249, -0.5866,  0.1391,  0.6934]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2149,  0.6872,  0.0302, -0.7708,  0.0793]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6791,  0.5332, -0.4076, -0.6833,  1.1274]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1524,  0.8993, -0.3302, -0.9728,  0.0181]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7315,  0.1283, -0.3785,  0.3666, -0.5726]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0744,  0.4797,  0.3462, -1.0040, -0.0548]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0097,  0.5624, -0.5390, -0.2813,  0.2944]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5705,  0.6999, -0.6038, -0.4766, -0.2368]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2125,  0.3411, -0.4380, -0.2214,  0.1396]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0073,  0.1616, -0.3730,  0.0942,  0.2824]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2830,  0.5396, -0.2198, -0.9175,  0.7293]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2790,  0.2471, -0.0750, -0.4427, -0.1022]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2862,  0.1790,  0.1250, -0.4792, -0.2387]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3967,  0.5579, -0.4798, -0.1903, -0.1734]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4463,  0.1307, -0.3289,  0.0340, -0.1595]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3291, -0.0430, -0.2485,  0.0598,  0.0681]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1583,  0.2429, -0.4287,  0.1149,  0.4030]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0240,  0.8785, -0.2466, -1.0907,  0.1927]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7112,  0.4409, -0.2939, -0.0763, -0.7021]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9385, -0.0869, -0.3468,  0.5658, -0.7373]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4774, -0.1014, -0.2955,  0.5935, -0.3499]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1444,  0.1716, -0.4153,  0.1923,  0.0878]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5682,  0.6159, -0.2528, -0.5760, -0.4401]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5164,  0.1274, -0.4014,  0.2306, -0.2335]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0810,  0.6040, -0.4050, -0.5029,  0.3899]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1258,  0.4704, -0.2763, -0.4271,  0.0779]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3679,  0.0413, -0.6056,  0.5489,  0.0319]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0182,  0.1723, -0.2626, -0.2573, -0.6609]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4824,  0.3424, -0.1360, -0.3092, -0.4150]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6354,  1.1894,  0.4369, -1.6906, -1.1323]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3710,  0.7351, -0.4927, -0.6352,  0.7151]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1869,  0.3955, -0.5018, -0.0787,  0.1576]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1523,  0.3161, -0.3900, -0.0681,  0.0676]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0149,  0.3728, -0.4773, -0.2454,  0.4015]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3923,  1.0307, -0.1254, -1.2213,  0.3746]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2271, -0.0796, -0.4107,  0.5574,  0.0513]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2454,  0.8529, -0.0765, -0.9425, -0.3113]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9511, -0.4014, -0.4568,  1.0013, -0.5994]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5011,  0.1812, -0.3993,  0.1814, -0.2800]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4057,  0.2300, -0.5007,  0.1239, -0.0569]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3750,  0.4172,  0.2482, -0.9493, -0.3606]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3783, -0.1265,  0.0746,  0.1172, -1.2944]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1974,  0.2282, -0.3014, -0.1042,  0.0832]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1058,  0.5228,  0.6751, -1.1966, -1.4805]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1062,  0.5346, -0.5449, -0.4869,  0.5799]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0255,  0.2758, -0.2439, -0.1761,  0.2066]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5967,  0.4889, -0.1255, -0.4748, -0.6127]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2703,  0.0995, -0.5811,  0.5251,  0.0525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0488,  0.3574, -0.4487, -0.1263,  0.3840]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5637,  0.9057, -0.2174, -1.1863,  0.7793]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1806,  0.7588, -0.1130, -0.8194,  0.1542]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5304, -0.0370, -0.3937,  0.5515, -0.3182]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4058, -0.2232, -0.5366,  0.7067,  0.1293]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0352,  0.6740, -0.1959, -0.8039,  0.1543]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3924,  0.0252, -0.4219,  0.1499,  0.0615]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4620,  0.0891, -0.0629, -0.0361, -0.3567]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8073,  0.3539, -0.2348, -0.1801, -0.7029]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9128, -0.0591, -0.6615,  0.8708, -0.5217]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0941,  0.1916, -0.1919, -0.1022,  0.0614]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1039,  0.1393, -0.1432, -0.0738,  0.0204]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5852,  0.4769, -0.5496, -0.2983, -0.1783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1454, -0.3471, -0.6109,  1.0208, -0.6639]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1646,  0.3179, -0.6872,  0.0924,  0.3148]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1512,  0.1814, -0.3334,  0.1781,  0.3156]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1941,  0.2310, -0.1522, -0.0289, -0.0877]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3384,  0.2895, -0.2438, -0.2706,  0.6092]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6743,  0.8513, -0.3231, -0.9167,  0.8456]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0878,  0.5312, -0.2841, -0.3063,  0.1557]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0228,  0.3114, -0.4628, -0.0818,  0.3935]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1459, -0.3246, -0.1736,  0.6428, -0.9023]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2822,  0.7084,  0.3922, -1.2772, -0.5280]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7855,  0.8742, -0.5469, -0.8067,  1.1224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3844,  0.2812, -0.0506, -0.1661, -0.3482]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1023,  0.6102,  0.1868, -0.9062, -0.0627]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 9.5488e-04,  8.8706e-01, -3.0024e-01, -9.6606e-01,  1.4822e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0212,  1.0850, -0.2028, -1.2670,  0.0674]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0385,  0.8153, -0.0537, -1.1651,  0.1550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0735,  0.1398, -0.2573,  0.1988,  0.0327]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5442,  0.0260, -0.5449,  0.3903, -0.1286]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1684,  0.3618, -0.0910, -0.3350,  0.1889]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0399,  1.6190,  0.0688, -2.2450,  0.9041]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4985,  0.0566, -0.4861,  0.2574, -0.0908]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0786,  0.8313,  0.0179, -1.1427, -0.1102]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3077,  1.6641,  0.5291, -2.3640, -0.9165]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 6.5342e-01,  5.0779e-04, -2.8485e-01,  3.9369e-01, -4.8373e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2952,  0.3791, -0.2337, -0.3932, -0.1059]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3877, -0.0747, -0.2412,  0.2968, -0.1687]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1214,  0.4899, -0.3028, -0.3506,  0.0111]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3580,  0.0128, -0.7604,  0.6113,  0.2143]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1250,  0.3433, -0.2983, -0.0566,  0.0263]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5917, -0.1196, -0.3154,  0.6097, -0.4255]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5005,  0.0490, -0.1748,  0.0895, -0.3215]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1823,  1.2578, -0.0965, -1.5729,  0.1804]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6024, -0.0752, -0.4077,  0.4582, -0.2881]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3092,  0.3043, -0.4079,  0.1490, -0.1618]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0073,  0.6875, -0.1550, -0.8732,  0.1064]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6054,  0.1239, -0.2035, -0.1018, -0.3977]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4348,  0.5055, -0.2472, -0.2734, -0.4310]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0091,  0.4006, -0.0860, -0.4109,  0.0396]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6139, -0.0109, -0.5491,  0.5520, -0.2394]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1275,  0.4105, -0.4475, -0.0052,  0.0590]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5933, -0.1706, -0.0897,  0.3363, -0.4624]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2426,  0.4123,  0.0832, -0.7797,  0.3313]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8284, -0.2631, -0.4329,  0.7860, -0.4737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1932, -0.0088, -0.2608,  0.3047,  0.0148]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4342, -0.1760,  0.0414,  0.1912, -0.2366]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4414,  0.0067, -0.6841,  0.5720,  0.0038]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1559,  0.0356, -0.4746,  0.3132, -0.7575]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9057,  0.5758, -0.3711, -0.2990, -0.7904]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3180,  0.7989, -0.0571, -0.9114,  0.2968]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5147,  0.1790, -0.3512,  0.2276, -0.2900]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8501, -0.0422, -0.1948, -0.1136, -0.4553]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6378,  0.4601, -0.4321, -0.4179,  1.0268]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8040, -0.1977, -0.2933,  0.3246, -0.3909]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7958,  0.6774, -0.2099, -0.8480, -0.6116]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3073,  0.2153, -0.4570,  0.3241, -0.1474]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5190,  0.2175, -0.1763, -0.1577, -0.3669]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7416,  0.4703, -0.0607, -0.6742, -0.6390]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1975,  0.5600, -0.0717, -0.7983,  0.3289]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4495,  0.3482, -0.4216, -0.1208, -0.2043]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0799,  0.4153, -0.1943, -0.4134,  0.2186]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3074,  0.8720, -0.1346, -0.9705,  0.2560]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6268,  0.2162, -0.3150, -0.1148, -0.3187]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6046,  1.3404,  0.0235, -1.7654,  0.5194]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0479, -0.1682,  0.0459,  0.3240, -0.9407]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1704, -0.3701, -0.5848,  1.1315, -0.7473]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7961,  0.1372, -0.1223, -0.1319, -0.6788]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8705e+00,  3.3629e-01, -2.4660e-04, -5.1952e-02, -2.0297e+00]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1626,  0.3057, -0.2663, -0.2386,  0.0330]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5292,  0.0065, -0.4674,  0.2590, -0.0733]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0090,  0.4157, -0.1035, -0.4860,  0.1043]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2850,  1.9207, -0.1920, -2.7144,  1.4330]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5009,  0.0079,  0.0364,  0.1813, -1.5744]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3802,  0.8933,  0.0544, -1.1767, -0.4953]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4381,  0.5264, -0.2501, -0.6596,  0.7220]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0769,  0.5835, -0.1279, -0.6422, -0.0174]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4204,  0.4678,  0.0898, -0.7627, -0.3721]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1856,  0.6444, -0.1562, -0.8759,  0.3715]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8378, -0.1743,  0.2096, -0.2051, -0.7117]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1922,  0.9925,  0.1413, -1.3634, -0.4116]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0680,  0.1367, -0.1472, -0.0556,  0.0488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4502,  0.8548,  0.1472, -1.1410, -0.6268]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2918,  0.9913,  0.3620, -1.3397, -0.0717]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2168,  0.4269, -0.0253, -0.8256, -0.0398]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6023,  0.5504, -0.1845, -0.8894,  0.9853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6139,  0.3173, -0.3702, -0.0588, -0.4147]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0397,  0.2997, -0.1932, -0.2733,  0.2075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1836,  0.6860,  0.0563, -0.5287, -0.3762]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8556,  1.3589, -0.0916, -1.7619,  0.8784]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0053,  0.4525,  0.2291, -0.9840, -1.0523]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7462,  0.8617, -0.0507, -1.1280, -0.7950]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9545,  0.0032,  0.0246, -0.0113, -0.8909]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1150,  0.2359, -0.1425, -0.2767,  0.0502]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4483,  0.3358, -0.5326,  0.1576, -0.1941]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2411, -0.0010, -0.2463,  0.0574,  0.1193]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7960,  1.2056, -0.4336, -1.3478,  1.0455]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3218,  0.3199, -0.5141, -0.1273,  0.7365]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5133,  0.5843, -0.3499, -0.5367,  0.7305]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1797,  0.0037, -0.4722,  0.5683,  0.0718]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1441,  0.4196, -0.1568, -0.3559, -0.0682]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2778,  0.1974, -0.0700, -0.2771, -1.0706]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1826,  0.0859, -0.5055,  0.3743,  0.0926]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5567,  0.4123, -0.3310,  0.0142, -0.5591]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1680,  0.3078, -0.0267, -0.3827, -0.1484]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1036,  0.5897,  0.1952, -0.8454, -0.3009]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0716,  0.2116, -0.5421,  0.0761,  0.5104]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5731, -0.1529, -0.4745,  0.6221, -0.2478]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0960,  0.2100, -0.5300,  0.1073,  0.3216]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2724,  0.3195, -0.0595, -0.4125, -0.1594]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0822,  0.3279, -0.2724, -0.1903,  0.0956]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9523,  0.2842, -0.2237, -0.0265, -0.8802]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8184, -0.1526,  0.4306, -0.1920, -0.8904]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1783,  0.4234, -0.1781, -0.4176, -0.0456]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0330,  0.6166, -0.3822, -0.4308,  0.2007]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2813,  0.9124,  0.1513, -1.2862,  0.1426]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7117,  0.2612,  0.0339, -0.5493, -0.5978]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3724, -0.1799, -0.5145,  0.6718,  0.0464]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2080,  0.8365, -0.1117, -1.1035,  0.3298]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0050,  0.4987, -0.3249, -0.2034,  0.1198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4243,  0.2219, -0.7851,  0.4432,  0.0842]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6747,  0.1283, -0.2492,  0.1312, -0.5123]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0566,  0.7925, -0.0856, -0.8966,  0.0481]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7921, -0.0562, -0.2219,  0.1965, -0.5525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6770, -0.1192, -0.7607,  0.7164, -0.0715]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1830,  0.6810, -0.4780, -0.5082,  0.4540]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2983,  0.5690, -0.5161, -0.3656,  0.6393]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6738,  0.3775, -0.1478, -0.3195, -0.5711]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1860,  0.2917, -0.4237, -0.0677,  0.5286]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2796,  0.2379, -0.4800, -0.1538,  0.2331]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4156,  0.4782, -0.1227, -0.5064, -0.3987]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7918,  0.1091,  0.6353, -0.6843, -1.0487]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2817,  0.2186, -0.3501,  0.0057, -0.0805]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5442,  0.2459,  0.5370, -0.4565, -0.9686]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4371,  1.7008,  0.1490, -2.2501,  0.1422]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1124, -0.2554, -0.0339,  0.2139, -0.8160]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1309, -0.0540, -0.6652,  0.5867,  0.4073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5053,  0.4234, -0.1576, -0.3457, -0.4080]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5013,  0.6260, -0.3862, -0.5487,  0.7914]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0939,  0.6103, -0.4352, -0.4098,  0.0914]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3460,  0.3558, -0.3281, -0.3031,  0.6496]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4338,  1.5357, -0.1514, -1.6811,  0.2227]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3281,  0.5287, -0.2363, -0.4819, -0.2237]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5870,  0.7874, -0.4090, -0.8931,  0.9276]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4186, -0.3576, -0.4266,  1.0815, -1.1619]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1625,  0.0512, -0.4284,  0.2724,  0.1514]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2383,  0.0777, -0.0984, -0.1722,  0.0056]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1574,  0.7850,  0.1030, -1.0091, -0.3614]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0168, -0.1657, -0.3625,  0.5719, -0.7645]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4191,  0.3485, -0.2827, -0.0474, -0.3783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6482,  0.1185, -0.2110,  0.0502, -0.5023]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8190,  0.3067, -0.4557, -0.0684, -0.5099]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0622, -0.3080, -0.5984,  0.9814, -0.5762]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2606,  0.1226, -0.1272, -0.1528, -0.0633]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2628,  0.5429, -0.1584, -0.4956, -0.2464]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1927,  0.8947, -0.2293, -1.2677,  1.5205]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4753,  0.5540, -0.1361, -1.0203, -0.1610]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1775,  0.9431, -0.2336, -1.0911,  0.3038]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1832,  0.8021,  0.2823, -1.5187, -0.2177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2636,  0.3944,  0.2304, -0.6518, -1.3161]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3289,  0.8774,  0.1417, -1.2216,  0.2183]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2746,  0.5281, -0.2384, -0.6451,  0.5243]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0412,  0.3587, -0.4108, -0.0557,  0.1638]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7563,  0.3070,  0.0371, -0.2890, -0.8292]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5962,  0.6657, -0.3974, -0.6259,  0.8757]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0993,  0.9024, -0.3455, -0.8479,  0.1790]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2389,  0.7466, -0.4351, -0.6354,  0.0111]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0469,  0.3904, -0.3822, -0.3807,  0.3073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0544,  0.8526, -0.4602, -0.8491,  0.2547]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2994,  0.1683, -0.1284, -0.1532, -0.1234]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3093,  0.3824, -0.1382, -0.3930,  0.4098]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1095,  0.4843, -0.2096, -0.4750,  0.2361]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0858,  0.1828, -0.1614, -0.1375,  0.3056]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1080,  0.0705, -0.5062,  0.2833,  0.5306]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2372,  0.2045, -0.1628, -0.1059, -0.1380]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2605,  0.2113, -0.3886, -0.1597,  0.1345]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0104,  0.5322,  0.0785, -0.9747,  0.1248]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0493,  1.0125, -0.1622, -1.2411,  0.0975]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2688,  0.8803, -0.3294, -0.8016,  0.3547]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0540,  0.6478, -0.1669, -0.8614,  0.2476]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5433,  1.0331, -0.2323, -1.2823,  0.6951]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8810,  0.2118,  0.0790, -0.2081, -0.9298]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0260,  0.6906,  0.0136, -0.7906, -0.1037]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5352,  0.6994, -0.1745, -0.9459,  0.7334]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8705,  0.3447, -0.2654, -0.0739, -0.8042]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2616,  0.5860, -0.3296, -0.5686,  0.4870]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6438,  0.0732, -0.2992,  0.2395, -0.4806]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2317,  0.8022, -0.5198, -0.7106,  0.5411]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1537,  0.2092, -0.0695, -0.2684, -0.0195]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1654,  0.5463, -0.3951, -0.2770, -0.0067]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5962,  1.0410,  0.0511, -1.4602,  0.5514]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2672,  0.5615, -0.7193,  0.0606,  0.0929]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3835, -0.2808,  0.0046,  0.3322, -0.2231]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2350,  0.0568, -0.3549,  0.1566,  0.0982]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4343,  0.1914, -0.5797,  0.3135, -0.0858]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0380,  0.7012, -0.1246, -0.5931, -0.0182]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4496,  0.3751, -0.5954,  0.1508, -0.1234]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5296,  1.0344, -0.2259, -1.2967,  0.6785]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3646,  0.4459, -0.3510, -0.4575, -0.0533]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7296,  0.3786,  0.3364, -0.9353, -0.8509]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5295,  0.9500, -0.4643, -1.1524,  0.9802]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2094,  0.9354, -0.0894, -1.3537,  0.3680]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0101,  0.5102, -0.2911, -0.4171,  0.1629]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4714,  0.6174, -0.1756, -0.6617,  0.5658]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3251,  0.8845,  0.0025, -1.2230, -0.3414]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4427,  0.6619, -0.3399, -0.4465, -0.3321]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1740,  1.2250, -0.2166, -1.4841,  1.2782]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5276, -0.0708, -0.9969,  0.9975,  0.1012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1127,  0.3481, -0.2099, -0.5224,  0.3970]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0910,  0.2661, -0.2200, -0.0872,  0.0389]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9276,  0.7184,  0.3759, -1.5626, -0.8927]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5396,  0.6064, -0.4843, -0.3888, -0.2601]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0833,  0.2743, -0.2266, -0.1105,  0.2354]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5548,  0.1950, -0.2534, -0.0345, -0.3475]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4240,  0.6305, -0.1869, -0.8471,  0.6500]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0981,  0.3972, -0.4900, -0.1214,  0.2123]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2586,  0.4929, -0.2274, -0.7669,  0.0988]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1005,  0.7199, -0.2337, -0.7678,  0.1925]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4845,  1.3569, -0.1652, -1.7063,  0.5031]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4743,  0.5933, -0.4934, -0.3574, -0.2103]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0992,  0.9095, -0.2954, -1.3037,  0.5360]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6685,  0.3459, -0.0282, -0.5283, -0.5620]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0731,  0.2861, -0.4628, -0.1111,  0.3619]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1525,  0.2104,  0.2932, -0.5403, -1.1706]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2042, -0.2842, -0.2824,  0.7318,  0.0363]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1377,  0.4791,  0.0108, -0.9622,  0.0681]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0621,  0.5412, -0.3207, -0.3702,  0.0687]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2637,  0.3534, -0.5791,  0.0331,  0.1224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2486,  0.1474, -0.2249,  0.2225, -1.2038]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3290,  0.5465, -0.2062, -0.5596,  0.4200]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1089,  0.1882, -0.1828, -0.1143,  0.0739]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5212,  0.9475, -0.0656, -1.3148,  0.5837]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0560,  0.5442, -0.0606, -0.6152,  0.0419]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3267,  0.3172,  0.0315, -0.3077, -1.3945]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0385,  0.6235, -0.2913, -0.5957,  0.2252]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5851,  0.0712, -0.0616, -0.2670, -0.3112]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0854,  0.7127, -0.4018, -0.5898,  0.2939]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1376,  0.6885,  0.1407, -0.9594, -0.2820]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7189, -0.4971, -0.6008,  1.2663, -0.2669]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0367, -0.2321, -0.4506,  0.6514, -0.6073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7543, -0.2067, -0.0532,  0.1197, -0.4828]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3099,  0.1478, -0.3560,  0.0855, -0.0405]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3498,  0.4330, -0.3360, -0.4708,  0.6468]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0904,  0.5894, -0.2862, -0.6133,  0.2788]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3857,  0.5996, -0.1736, -0.7083,  0.5121]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1260,  0.2362, -0.3248, -0.1858,  0.2201]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7096, -0.2034, -0.4069,  0.6430, -0.4075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4299,  0.4557, -0.4225, -0.3780,  0.8200]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2312,  0.3869, -0.4443, -0.0390,  0.0035]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1886,  0.2320,  0.0038, -0.1541,  0.1180]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2559,  0.2432,  0.0845, -0.5623, -0.2057]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1782,  0.0710, -0.2568,  0.0359,  0.1266]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1348,  1.1794,  0.3286, -1.8983, -0.1176]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6494,  0.2513, -0.1661, -0.2500, -0.4884]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5637,  0.0144, -0.3798,  0.5434, -0.4152]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5445,  0.0116, -0.1100,  0.0038, -0.3342]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3025,  0.5884, -0.1900, -0.6521, -0.1756]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0972,  0.7697, -0.1064, -0.9751, -0.0459]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3624,  0.1937, -0.1485, -0.1945, -0.2289]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8026,  0.2594, -0.3998, -0.0927, -0.5174]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8371, -0.0644, -0.3563,  0.5620, -0.6415]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0205,  0.4676, -0.3267, -0.4708,  0.3177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0962,  0.3970, -0.2854, -0.2963,  0.2826]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1539,  0.1834, -0.1078,  0.0612, -0.1403]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3505,  0.5178, -0.1233, -0.5278,  0.3901]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0453,  0.5631, -0.5866, -0.0750,  0.1660]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3115,  0.5317, -0.1522, -0.6778,  0.4648]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0023,  0.6234, -0.2915, -0.5519,  0.1672]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3398,  0.4318, -0.2868, -0.5287, -0.0153]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6820,  0.3249, -0.0398, -0.3788, -0.6240]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1570,  0.5893, -0.4067, -0.5035,  0.1290]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2645,  0.3332,  0.0301, -0.6209, -0.1849]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7012,  0.5824, -0.2992, -0.7147,  0.9890]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2986,  0.5440, -0.4167, -0.6272,  0.7160]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2078,  0.2027, -0.4401,  0.0582,  0.5338]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6104,  0.3022, -0.4746,  0.0969, -0.3586]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0861,  0.4404, -0.1731, -0.2779, -1.0472]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7676,  0.4796, -0.3844, -0.4758, -0.4179]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9518,  0.2623, -0.1370, -0.1637, -0.8419]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7286,  0.9846, -0.1428, -1.6970,  1.0850]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1710,  0.0515, -0.1169, -0.1588,  0.1639]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4120,  0.2678, -0.4450,  0.0868, -0.1097]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0234,  0.4409, -0.4754, -0.2237,  0.3205]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2597,  0.2753, -0.1406, -0.2556,  0.4043]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4139,  0.2071, -0.2014, -0.2520, -0.1685]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0097,  0.1764, -0.0573, -0.2328,  0.0858]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0058,  0.2108, -0.1233, -0.2040,  0.1331]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1095,  0.1777, -0.0887, -0.1574, -0.0210]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2573,  0.5523, -0.4040, -0.4803,  0.4992]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2793,  0.2644, -0.3251, -0.0022, -0.1089]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2899, -0.1741, -0.3547,  0.6481, -0.0105]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0849,  0.4710, -0.2044, -0.3499, -0.0093]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2155,  0.1415, -0.0427, -0.2869, -0.0745]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6423,  1.2065, -0.1746, -1.3429,  0.6455]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4742, -0.2185, -0.7729,  1.1910, -0.0343]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1556,  0.1213, -0.6837,  0.3476,  0.3539]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5581,  0.7127,  0.3360, -0.7922, -1.9115]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7469,  0.2557,  0.4779, -0.6436, -0.9801]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2394,  0.2047, -0.5392,  0.2107,  0.1202]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5418,  0.5903,  0.1415, -0.7880, -0.6861]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4675,  0.8214, -0.3909, -0.9180,  0.7754]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1233,  0.7588, -0.2727, -0.8639,  0.0673]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2823, -0.1458, -0.0594,  0.2274, -0.0821]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2952,  0.5498, -0.1933, -0.4687, -0.2737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4078,  0.2020, -0.1198, -0.1655, -0.3004]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7223,  0.0862, -0.5312,  0.4764, -0.4662]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7735, -0.0101, -0.0990,  0.0292, -0.6012]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3096,  0.1634, -0.2608, -0.0461,  0.5786]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7494, -0.4381, -0.5958,  0.9743, -1.1868]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1562,  0.4022, -0.2615, -0.3264, -0.0085]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4363,  0.0563, -0.1107,  0.1258, -0.3676]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2789,  0.1997, -0.3006, -0.0106, -0.0659]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8538,  0.4724,  0.1101, -0.5047, -0.9383]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2903, -0.5686,  0.0045,  0.8236, -1.0642]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4310,  0.5824,  0.0150, -0.8408, -0.3811]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9675, -0.1032, -0.3588,  0.4742, -0.6995]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7980, -0.0355, -0.4377,  0.4521, -0.4826]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7313,  0.2656, -0.1665, -0.3586, -0.4521]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1214,  0.6286,  0.4777, -0.9491, -1.5945]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8222, -0.1238, -0.4656,  0.6511, -0.4951]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8130, -0.3234, -0.1413,  0.6467, -0.6327]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1105,  0.3621, -0.1198, -0.3718,  0.2188]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2729,  0.3322, -0.1505, -0.4518, -0.0973]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6307, -0.0007, -0.3979,  0.5583, -0.4254]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2247,  0.5422, -0.0899, -0.6423, -0.1694]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3665,  0.6741, -0.3801, -0.4815, -0.2742]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0196,  1.0393,  0.0777, -1.4533, -0.1410]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5059,  0.8662, -0.4837, -0.8996,  0.8377]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0213,  0.1789, -0.0634, -0.2364,  0.1600]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8374,  0.3041, -0.3498, -0.0438, -0.6708]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6425, -0.5499, -0.2859,  1.0766, -0.3770]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6373, -0.0815, -0.4488,  0.4241, -0.2352]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1892,  0.5035, -0.2250, -0.5736,  0.0084]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2651,  0.9270,  0.1575, -1.1943,  0.0541]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4278,  0.9124,  0.3114, -1.3259, -0.7098]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4495,  0.4875,  0.0553, -0.6304, -0.5117]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5934,  0.4123, -0.4360, -0.0853, -0.3710]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6951,  0.1845, -0.4180,  0.2698, -0.4844]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8847, -0.4525, -0.5265,  0.8807, -0.2883]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4254,  0.0783, -0.2143,  0.0913, -0.2531]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2274,  0.4697, -0.0384, -0.8141,  0.3857]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0231,  0.2451, -0.3698, -0.0606,  0.2660]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0590,  0.5203, -0.2138, -0.5213,  0.0852]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4494,  0.2619, -0.2211, -0.1811, -0.2263]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4192,  0.2678, -0.2713, -0.0853, -0.2406]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2052,  0.9990, -0.2593, -0.9745, -0.1958]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4464,  1.0562, -0.2481, -1.1705,  0.4951]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3835,  0.2270, -0.1203, -0.2040, -0.2738]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5618,  0.1432, -0.4164,  0.1848, -0.3107]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9278, -0.0138, -0.0593,  0.0882, -0.8087]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7464,  0.8069, -0.6197, -0.6255,  1.1298]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1593,  0.0885, -0.3888,  0.5033,  0.2724]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1715,  0.7317, -0.1921, -0.8455,  0.2636]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4740,  0.1082, -0.2227,  0.0913, -0.3301]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0793,  0.4928, -0.1891, -0.5275, -0.9194]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2029, -0.0127, -0.7894,  0.6955,  0.3654]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0657,  0.6732, -0.4493, -0.6389,  0.4526]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1891,  0.2870, -0.1937, -0.3644,  0.0430]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0789,  0.1493, -0.4429,  0.0543,  0.3158]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7225,  0.0292,  0.0796, -0.0376, -0.7328]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2006,  1.1609, -0.2874, -1.3356,  0.2992]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2725,  0.1519, -0.4251,  0.0502,  0.1213]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1831,  0.1649, -0.2283, -0.1469,  0.1181]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4699,  0.3979, -0.4181, -0.2717, -0.1668]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4214,  0.9979, -0.3061, -1.0232,  0.5152]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1672,  0.5917,  0.0885, -0.8876,  0.1490]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5886,  0.2419, -0.1236, -0.1449, -0.5405]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4226,  0.2624, -0.3219, -0.1852, -0.1139]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4846,  0.8768,  0.0473, -1.0776, -0.5813]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8621,  0.5267,  0.3837, -0.8236, -1.1463]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0303,  0.5790, -0.3239, -0.4210,  0.1540]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3990,  0.4292, -0.0780, -0.5907, -0.2687]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0154,  0.6090, -0.2879, -0.5215,  0.1717]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4044,  0.4395, -0.1230, -0.6499, -0.2041]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4463,  0.0146, -0.1682,  0.1787, -0.3458]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5606,  0.2200, -0.1204, -0.0544, -0.5369]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2248, -0.0312, -0.4981,  0.4642,  0.1721]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1454,  0.1766, -0.4426,  0.1006,  0.1608]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4283,  0.1970, -0.3601, -0.0051, -0.1229]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1671,  0.8993, -0.4117, -0.9362,  0.4124]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2246,  0.2147, -0.3604, -0.0563,  0.0635]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1619,  0.5313,  0.0156, -0.7098, -0.1754]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3787,  0.3551, -0.5733,  0.0932, -0.0657]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3952,  0.6269, -0.0249, -0.9366, -0.3435]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2075,  0.3092, -0.4137, -0.2194,  0.1634]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7399, -0.2898, -0.3656,  0.8539, -1.3996]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4972,  0.9016,  0.2917, -1.7166, -0.5074]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3475,  0.7741, -0.0909, -0.8673,  0.3525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5407,  0.3299,  0.3089, -0.5542, -0.7436]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1414, -0.0204, -0.5787,  0.6188,  0.2253]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1051, -0.1383, -0.2008,  0.2945,  0.1347]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1856,  0.7277, -0.1142, -0.9480, -0.1171]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0552,  0.4099, -0.2442, -0.2370,  0.1386]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2332,  0.4135, -0.4108, -0.0486, -0.0634]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5006,  0.1252, -0.3837,  0.2016, -0.2566]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3209,  0.2787, -0.5055, -0.0648,  0.1069]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1666,  0.2783, -0.1873, -0.2670,  0.0062]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8312,  1.0263, -0.2801, -1.3303,  1.0374]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3824,  0.4834, -0.2903, -0.7140,  0.7750]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8354, -0.1874, -0.4307,  0.5971, -0.4578]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4263,  0.5369, -0.5631, -0.2113, -0.1326]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1731,  0.4504, -0.2556, -0.3263, -0.0408]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1414,  0.0918, -0.3581, -0.0150,  0.2501]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2266, -0.0664, -0.7544,  0.7887,  0.2515]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4737,  0.6779, -0.2050, -0.8702,  0.6783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2853,  0.5047, -0.1972, -0.6073,  0.5153]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2936,  0.2010, -0.4142, -0.0196,  0.0085]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2700,  0.2479,  0.0189, -0.2696, -0.2749]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4126,  0.7074, -0.1964, -0.7650, -0.3390]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0989,  0.4977, -0.3734, -0.4507,  0.1788]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7630,  0.2730, -0.4286, -0.0471, -0.4563]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5255,  0.1010, -0.1879, -0.1558, -0.2559]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5484,  0.0462, -0.5414,  0.6001, -0.2679]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0829,  0.4895, -0.4549, -0.4104,  0.4270]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1923,  0.2296, -0.4476, -0.0102,  0.5632]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4415,  0.0468,  0.1080,  0.1010, -0.5822]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0566,  0.3420, -0.3967, -0.0746,  0.2084]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0177,  0.6402, -0.3426, -0.3007,  0.0299]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0628,  0.3639, -0.1910, -0.1523, -0.0045]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0368,  0.2971, -0.2105, -0.3360,  0.3088]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3792,  0.7094,  0.1080, -1.1188, -0.4214]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0975, -0.0228, -0.2398,  0.1106,  0.2341]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3720, -0.0461, -0.1182,  0.0856, -0.1431]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4067,  0.9664,  0.3706, -1.4869, -0.7308]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1137,  0.6518, -0.1051, -0.7022, -0.1323]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9909, -0.4428, -0.4832,  1.0015, -0.5670]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9139,  0.0601, -0.6813,  0.6246, -0.4705]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6292,  0.5152, -0.6545,  0.0321, -0.3092]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0148,  0.6955, -0.2508, -0.6979,  0.0862]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1998,  0.8868, -0.0595, -1.2644, -0.1043]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1904,  0.6585, -0.4970, -0.4753,  0.4399]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3107,  0.3050, -0.3474, -0.0704, -0.1561]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7339,  0.1182, -0.0033, -0.1187, -0.7068]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3285,  0.3005, -0.3997, -0.1519, -0.0171]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3342, -0.1193, -0.1629,  0.3717, -0.1604]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5215, -0.0797, -0.5175,  0.5968, -0.1539]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0921,  0.4279, -0.4802, -0.1390,  0.4063]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4375,  0.7618, -0.3955, -0.8167,  0.7454]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0239,  0.4838, -0.3236, -0.4426,  0.2310]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0990,  0.2033, -0.1052, -0.1798, -0.0073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5027,  0.1755, -0.1038, -0.0216, -0.4667]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0021,  0.5653, -0.2101, -0.5301,  0.0871]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0174,  0.8450,  0.0101, -1.0239, -1.1326]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0673, -0.0607, -0.7190,  0.8584,  0.4226]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0298, -0.2290,  0.4070, -0.0305, -1.1188]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1748,  0.6553, -0.1749, -0.7669, -0.0597]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0593,  0.6846, -0.3433, -0.5397,  0.0681]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4303, -0.0944, -0.2009,  0.3756, -0.2219]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2288,  0.6254, -0.3430, -0.5000, -0.0574]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0680,  0.1367, -0.1472, -0.0556,  0.0488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0510,  0.3760, -0.2249, -0.3318,  0.2118]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1736,  0.4039, -0.3280, -0.2674,  0.0475]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2046,  0.4403, -0.3437, -0.2990,  0.0220]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0958,  0.2742,  0.1458, -0.4412, -0.1510]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3249,  0.0607, -0.6367,  0.5287,  0.0738]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7479,  0.3054, -0.1500, -0.2659, -0.6188]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2084,  0.7773, -0.1515, -1.0189,  0.3847]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4160,  0.4053, -0.0667, -0.3653, -0.4187]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3551,  0.6136, -0.2234, -0.6818, -0.2044]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1662, -0.4569, -0.4312,  1.2994, -0.9871]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9078, -0.2360, -0.1893,  0.4959, -0.6928]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3391,  0.4348, -0.4415, -0.3710,  0.0416]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2562,  0.2628, -0.0732, -0.4972,  0.5101]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9098, -0.0411, -0.2481,  0.3619, -0.7672]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6731, -0.0093, -0.1635,  0.2934, -0.5162]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5629,  0.6098, -0.3242, -0.6228,  0.8391]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8064,  1.1418, -0.4881, -1.2289, -0.5531]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5794,  0.5175,  0.0839, -0.9989,  0.6948]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5351,  0.1962, -0.6709,  0.4208, -0.1381]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1437,  0.6403, -0.3859, -0.7532,  0.2202]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9637, -0.1459, -0.2169,  0.4808, -0.7542]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1367,  0.2621, -0.2751, -0.2726,  0.1724]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0095,  1.2601, -0.1004, -1.5039, -0.1110]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0110,  0.4214, -0.4363, -0.0823,  0.2482]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0293,  0.9643, -0.1044, -1.2732,  1.1290]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7432, -0.1833, -0.5449,  0.7736, -0.3653]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3450,  0.3228, -0.7270,  0.1731,  0.1157]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1853,  0.7331,  0.0293, -1.0300, -0.2199]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3826,  0.5020, -0.2704, -0.6366,  0.7445]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8147,  0.1580,  0.5063, -0.5848, -1.0191]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0543,  0.6523, -0.1556, -0.7394,  0.1506]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5646, -0.0329,  0.1102, -0.2862, -1.3829]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5652,  0.7662, -0.2444, -0.8189,  0.7256]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3478,  0.2613, -0.5064, -0.2095,  0.8952]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1694,  1.0047,  0.3922, -1.6265, -0.1209]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5051,  0.6981, -0.0466, -0.9565, -0.4730]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7449,  0.5491, -0.3285, -0.3310, -0.6254]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2245,  0.0929, -0.2293, -0.1747,  0.1484]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0408, -0.0931, -0.1452,  0.2256, -0.8886]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3739,  0.7842, -0.2591, -0.9310, -0.2101]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1648,  0.3587, -0.6580,  0.0487,  0.3140]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5691,  0.7803, -0.0757, -0.8933,  0.5374]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5250,  0.2479, -0.1318, -0.4141, -0.3147]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5965,  0.9669, -0.0303, -1.3133,  0.5794]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0370,  0.2844, -0.5186,  0.0693,  0.2925]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0644,  0.5475, -0.3703, -0.4104,  0.1196]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0628,  0.3751, -0.2395, -0.5530,  0.3467]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4937,  0.9073, -0.3686, -0.9143,  0.6693]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8111,  1.1095,  0.0711, -1.6588,  0.8539]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2883,  0.2252, -0.4063,  0.0310, -0.0198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0356,  0.3004, -0.3298,  0.1660,  0.0969]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7438,  0.9455, -0.1654, -1.3301,  0.9209]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6869,  0.6234,  0.4423, -1.0272, -0.9800]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0529,  0.3311, -0.4901, -0.2476,  0.4177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7000, -0.0680, -0.3293,  0.3378, -0.4249]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3453,  0.1464, -0.4987,  0.4273, -0.1081]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3067,  1.1512, -0.1717, -1.3884,  0.3057]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1930, -0.0696, -0.3451,  0.2939,  0.1925]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2366,  0.1802, -0.2459,  0.0876, -0.1518]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0395,  0.2930, -0.1581, -0.1088,  0.0960]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7216,  0.5536,  0.0656, -0.7631, -0.7546]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1146,  0.4397, -0.2795, -0.2686,  0.2150]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3048,  0.2020, -0.4708,  0.3460, -0.1097]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4951,  0.3724,  0.0295, -0.3242, -0.5324]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1296,  1.1654,  0.1928, -1.6151, -0.1185]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2164,  0.1543,  0.0070, -0.2603, -0.0993]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1580,  0.5661, -0.1856, -0.7032,  0.0025]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7514, -0.3194, -0.6143,  0.9087, -0.2199]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4401, -0.1108, -0.5480,  0.5226,  0.0440]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5273,  0.2513,  0.1280, -0.4384, -0.5631]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1083,  0.5447,  0.0314, -0.7081, -0.1610]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0478,  0.7685, -0.3947, -0.7516,  0.1965]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2157,  0.4573, -0.3536, -0.2939, -0.0242]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3178,  0.1182, -0.5494,  0.3149,  0.0163]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3140,  0.9072, -0.4645, -0.6486,  0.4658]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0851,  0.3443, -0.0601, -0.4346, -0.0237]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2144,  0.3466,  0.0694, -0.5109, -0.2697]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0457,  0.7208, -0.2261, -0.8842,  0.1398]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7405,  0.2527, -0.6439, -0.1531, -0.1366]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2225,  0.2849, -0.3947, -0.2749,  0.2165]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2217,  0.8939, -0.2298, -1.0304,  0.3570]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3472,  0.3321, -0.4928, -0.1347,  0.0527]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1845,  0.5387, -0.2032, -0.5092, -0.1063]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0349,  0.2266, -0.2392, -0.0728,  0.1751]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9217, -0.1830, -0.1451,  0.2843, -0.6715]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2215,  0.4026,  0.1844, -0.6604, -0.3060]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5908,  0.6586, -0.2706, -0.7589,  0.8103]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3027,  0.0715, -0.3548,  0.1365,  0.0198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1896, -0.1638, -0.3397,  0.4029,  0.1841]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2279,  0.1819, -0.1981, -0.0962, -0.0162]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8760,  0.5429, -0.4582, -0.2419, -0.7066]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4970,  0.5422,  0.6302, -1.0858, -0.8978]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1626, -0.1731, -0.4218,  0.8545, -0.9670]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1880,  0.7480, -0.2033, -0.8869,  0.3230]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1563,  0.2446, -0.3345, -0.1288,  0.1321]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2898,  0.4881, -0.4633, -0.4228,  0.1287]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2480, -0.3699, -0.2459,  0.6639, -0.9049]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1791,  0.6899, -0.0936, -0.6376,  0.0979]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 8.0839e-01, -3.6742e-04,  1.1926e-01, -2.4248e-01, -7.1294e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4656,  0.3652, -0.2344, -0.3350, -0.2648]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0371,  0.5045, -0.1863, -0.5613,  0.1101]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3545,  0.1123, -0.5909,  0.3780,  0.0514]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6669, -0.1960, -0.3823,  0.9123, -0.5391]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1288,  0.7690, -0.5090, -0.4879,  0.3727]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5022,  0.1579, -0.3673,  0.2351, -0.3040]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7548,  0.8663, -0.2060, -1.0198,  0.8815]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1413, -0.3303, -0.7221,  1.0697, -0.6237]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0890,  0.2360,  0.0037, -0.2838, -0.0295]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1788, -0.1016, -0.2321,  0.1916,  0.1759]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1116,  1.2939, -0.1949, -1.3904,  0.0098]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5242,  0.6544, -0.2918, -0.6692, -0.3565]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4144,  0.1451, -0.6303,  0.2322,  0.0410]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3593,  0.4033, -0.2305, -0.1540, -0.2778]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4525,  0.4000, -0.1597, -0.4428, -0.3192]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0506,  0.5163, -0.0256, -0.6946,  0.0540]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6320, -0.1406, -0.5164,  0.7585, -0.3247]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7018, -0.0992, -0.2917,  0.4272, -1.4599]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4014,  0.6129, -0.2013, -0.5292, -0.3626]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4507, -0.4200, -0.4037,  0.9850, -1.0102]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2748,  0.0689, -0.5529,  0.3405,  0.1189]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0321,  0.4944, -0.1637, -0.6755,  0.1593]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3827,  0.4236, -0.1285, -0.5923, -0.2245]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0319,  0.0975, -0.3419,  0.0905,  0.3156]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2898,  0.2738, -0.4080, -0.2549,  0.1082]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1103,  0.3592, -0.1875, -0.2072, -0.0714]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4756,  0.8318, -0.2059, -1.0867,  0.7163]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1129,  1.2655, -0.3830, -1.2676,  0.1797]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0102,  0.4372, -0.1547, -0.4507,  0.1000]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0376,  0.2359, -0.2949, -0.0722,  0.2187]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1153,  0.2704, -0.4304,  0.0292,  0.1590]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1515,  0.4730, -0.1946, -0.5251,  0.3075]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2769,  0.4039, -0.3754, -0.4687,  0.7049]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3772,  0.5642, -0.4063, -0.5355,  0.6967]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1683,  0.6031,  0.4957, -1.1823, -0.4872]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5286,  0.2565, -0.0720, -0.4221, -0.2487]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5610,  0.2684,  0.1734, -0.0491, -0.8714]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9836,  0.3864, -0.0068, -0.3178, -1.0422]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6749,  0.0999, -0.1450, -0.2203, -0.3493]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5419,  0.4264,  0.6028, -0.8305, -0.9973]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5391,  1.0178,  0.0547, -1.4556,  0.4703]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1245,  1.0487, -0.6220, -0.8872,  0.4089]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2884,  1.4706, -0.1756, -1.9431,  0.3658]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1423,  0.2795, -0.4008, -0.0749,  0.4530]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1072,  0.7488, -0.1225, -1.0601,  0.2600]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0495, -0.1109, -0.2727,  0.7171, -0.9822]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5629,  0.2681, -0.4016, -0.0840, -0.2603]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0221,  0.4531, -0.1993, -0.4020,  0.1434]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0978,  0.2548, -0.2189, -0.0734, -0.9746]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3630,  0.5176, -0.2680, -0.3874, -0.2684]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6071,  0.1888, -0.6305,  0.4601, -0.3220]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2204,  0.0891, -0.3466,  0.1090,  0.0629]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2473,  0.8036, -0.1859, -0.7059,  0.2086]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1255,  0.3518, -0.1299, -0.1179,  0.0715]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5816,  0.9133,  0.1903, -1.2200, -0.8230]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5497,  0.6090, -0.2975, -0.6970,  0.8310]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3500,  0.3743, -0.3319, -0.1288, -0.2251]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0464,  0.4981, -0.3990, -0.2890,  0.2376]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6376,  0.3730, -0.3336, -0.0809, -0.4778]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5330, -0.6565, -0.3303,  1.5311, -1.3462]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5856,  0.2438, -0.0823, -0.6702, -0.2026]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6590,  0.1255, -0.2279,  0.0555, -0.5023]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0755,  0.2265, -0.5249,  0.1411,  0.4136]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6396, -0.1029, -0.5437,  0.5529, -0.2139]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7115,  0.2440, -0.1542, -0.5518, -0.3358]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2198,  0.5259,  0.0472, -0.8223, -0.1710]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4715,  0.0594, -0.3915,  0.4295, -0.3019]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5010,  0.3563, -0.4765, -0.2854, -0.0898]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3866,  0.9795, -0.1625, -0.9280, -0.4659]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5567, -0.1161, -0.4922,  0.6078, -0.1622]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2447,  0.1183,  0.0827, -0.3416, -0.1353]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3719,  0.3910, -0.4211,  0.0474, -0.2172]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4652,  0.3877,  0.5473, -0.8889, -0.7747]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1387,  0.5389,  0.0384, -0.9921,  0.0263]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0721,  1.3530, -0.1546, -1.6398,  0.0558]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3468,  1.2264,  0.9016, -1.9932, -1.1086]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1410,  0.0553, -0.3947,  0.0292,  0.3328]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3399,  0.7950, -0.2870, -0.9070,  0.5509]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0315,  0.2532, -0.4951, -0.0006,  0.3884]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1643,  0.9145,  0.1064, -1.0164, -0.4398]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7223,  0.6570, -0.1227, -0.5082, -0.8709]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0479,  0.6397, -0.0467, -0.9239,  0.1315]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3571,  0.0490, -0.2731,  0.2129, -0.1610]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1821,  0.0776, -0.5070,  0.2952,  0.2487]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3680,  0.1147, -0.2901,  0.0973, -0.1861]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7558,  0.6559, -0.4841, -0.4874,  1.0385]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1906,  0.7894, -0.3167, -0.7043,  0.3287]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0892,  0.1622, -0.0704, -0.2306,  0.0399]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1402,  0.1641,  0.8272, -0.7612, -0.5910]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3751, -0.2010, -0.2466,  0.4772, -0.1190]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7681,  0.5141, -0.1298, -0.4989, -0.7148]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6933, -0.2738, -0.0114,  0.3431, -0.5785]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7786, -0.2067, -0.1276,  0.5157, -0.6704]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5868,  0.8223, -0.2004, -0.9241,  0.6974]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0458,  0.5519, -0.4210, -0.3106,  0.2007]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6237,  0.6193, -0.1718, -0.7771,  0.8147]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4659,  0.1350, -0.0906, -0.1058, -0.3157]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1840,  0.7192, -0.0581, -1.1508, -0.0097]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0079,  0.9954, -0.2697, -1.0764,  0.0781]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6191,  0.7464, -0.4911, -0.4106, -0.4851]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0985,  0.2325, -0.4033, -0.0858,  0.2681]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0538,  0.3883, -0.6967, -0.1450,  0.5325]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1921,  0.2482, -0.1537, -0.4100,  0.5164]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9013, -0.0547,  0.0992,  0.3076, -0.9670]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4194,  1.1998, -0.3950, -1.3146,  0.5967]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4381,  0.1010, -0.5844,  0.1639,  0.0465]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8921,  0.4868,  0.3416, -0.9462, -1.0264]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1294,  0.7606, -0.1559, -0.9643,  0.2524]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2986,  0.6211,  0.0084, -1.0118,  0.3982]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3434, -0.2298, -0.8414,  1.2381,  0.1438]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5869, -0.0352, -0.5823,  0.4839, -0.0920]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3282,  0.5246, -0.0427, -0.5811,  0.2780]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4194,  0.4686, -0.3060, -0.3259, -0.2918]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5667,  0.4990, -0.5343, -0.3721, -0.1760]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1889,  0.3134, -0.5296, -0.0024,  0.1728]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4894, -0.2314, -0.5888,  0.8503, -0.0315]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3710,  0.7639, -0.3276, -0.8454,  0.5763]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2521,  0.8751,  0.3171, -1.4486,  0.0462]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0198,  0.2031, -0.2693, -0.0340,  0.1928]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2691,  0.1529, -0.6319,  0.5628,  0.0026]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5483, -0.0223, -0.2271, -0.0876, -0.1403]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2635,  0.2354, -0.3317, -0.1913,  0.6489]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3618,  0.2345, -0.5443,  0.2633, -0.0488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5771,  0.2092, -0.5063,  0.1449, -0.2292]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0012,  0.6491, -0.3487, -0.7529,  1.3133]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0941,  0.1916, -0.1919, -0.1022,  0.0614]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6814,  0.2596, -0.3758,  0.2437, -0.5595]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1234,  1.1188,  0.6600, -1.4988, -1.8412]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1719, -0.2412, -0.4967,  0.8810, -0.8809]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0236,  0.1839, -0.4122,  0.1437,  0.2780]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1128,  0.2944, -0.2400, -0.2531,  0.3413]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4267,  0.3720,  0.0909, -0.4636, -0.4992]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2894,  1.2563,  0.4429, -1.7633, -0.7586]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1387,  0.3172, -0.3963, -0.2077,  0.2341]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2735,  0.3305, -0.2374, -0.4039,  0.5737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1185,  0.3059, -0.3377, -0.1449,  0.3913]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3383,  0.4342, -0.2211, -0.5573, -0.0456]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2706,  0.0464, -0.4939,  0.4522,  0.0494]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9990,  1.1928,  0.2164, -1.7614,  0.7967]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5586,  0.2670,  0.0085, -0.4246, -0.5215]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5384,  0.7379, -0.3021, -0.7608, -0.3380]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0429, -0.3028, -0.2092,  0.4821, -0.7071]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2843,  0.5556, -0.2892, -0.5327,  0.4866]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3476,  0.0139, -0.4987,  0.2076, -0.8157]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3679e-01,  4.8042e-04, -5.0178e-01,  5.4266e-01, -2.4516e-02]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0925,  0.5543, -0.2413, -0.4665, -0.0049]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5018,  0.3369, -0.2045, -0.1452, -0.4503]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1633,  0.8003,  0.0913, -0.9241, -0.0503]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0214,  0.6548, -0.2612, -0.6534,  0.1499]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1067,  0.7760,  0.1080, -1.0009, -1.2529]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0708,  1.1035, -0.1033, -1.3383,  0.0731]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1726,  0.0204, -0.6544,  0.4930,  0.3343]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4709,  0.2439, -0.3237,  0.1376, -0.3650]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3373,  0.7382,  0.1532, -1.1352, -0.4596]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2964,  0.1868, -0.6347,  0.6620, -1.0940]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6729,  0.3996, -0.4056, -0.1746, -0.4490]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4504,  0.5100, -0.1300, -0.7436, -0.2380]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1034,  0.1087, -0.3150, -0.0843,  0.2696]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4529,  0.4263, -0.1637, -0.5545,  0.6645]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1897, -0.1874, -0.2017,  0.4652, -1.0052]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6197, -0.3797, -0.4109,  0.7483, -0.1649]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5049,  0.3957, -0.0895, -0.3951, -0.4428]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0018,  0.4332, -0.1716, -0.5305,  0.1776]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4723,  0.2748, -0.2444, -0.2984, -0.2224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7929, -0.1156, -0.5089,  0.7984, -0.5710]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9066,  0.0967, -0.6564,  0.4267, -0.4418]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8940, -0.9777,  0.0102,  1.4957, -2.6718]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4270,  0.5598, -0.0301, -0.9027,  0.5978]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0891,  0.8808, -0.2996, -0.8979,  0.1764]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3280,  0.3404, -0.1983, -0.6313,  0.6868]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0610,  1.1316,  0.1514, -1.5325, -0.1431]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8890, -0.1284, -0.5798,  0.7872, -0.5287]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5183,  1.3450,  0.3009, -2.2093,  0.3771]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1576,  0.2374, -0.6260,  0.2987,  0.5325]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3242, -0.1470, -0.6141,  0.6670,  0.1626]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2447,  0.8621, -0.3624, -0.7793,  0.4094]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8891,  0.1276, -0.1444,  0.2158, -0.9053]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3200,  1.0181,  0.0968, -1.5074,  0.2833]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6982, -0.2054, -0.3895,  0.5368, -0.3259]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5347,  0.8485,  0.0842, -1.5263,  0.6617]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2263,  0.4913, -0.2869, -0.4418,  0.4607]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5975, -0.0164, -0.6386,  0.7459, -0.2265]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1886,  0.3348, -0.4548, -0.0389,  0.0941]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4875,  0.9566, -0.4086, -0.9005,  0.6790]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5989, -0.0898, -0.3828,  0.6323, -0.3469]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2354,  0.2974, -0.4360, -0.0211,  0.0735]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4197,  0.4239, -0.0331, -0.3618, -0.4783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2127,  0.1567, -0.3613,  0.3109,  0.3747]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4089,  0.2731, -0.1847, -0.3639, -0.1816]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0556,  0.6378, -0.0154, -0.8165, -0.0992]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0073,  0.6657, -0.0986, -0.9012,  0.1081]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4047,  0.2901, -0.1518, -0.5113,  0.7063]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3406,  0.3433, -0.0833, -0.7189, -0.1160]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3488,  0.0797, -0.1965, -0.1977,  0.0019]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3249,  1.0265, -0.3094, -1.1358,  0.4764]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2669,  0.3848, -0.2241, -0.5782,  0.5889]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0536,  0.2111, -0.4214,  0.1856,  0.2417]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6070,  0.4218, -0.2231, -0.2196, -0.5717]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1152,  0.8161,  0.1588, -0.9521, -0.1714]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1708,  0.3246, -0.3465, -0.1287,  0.4675]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2120,  0.5524, -0.0422, -0.8424, -0.0513]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2349,  0.0170, -0.7429,  0.5569,  0.7676]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2939,  0.8003,  0.0890, -0.9323, -0.4841]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5091,  1.3982, -0.0692, -1.6949,  0.4077]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1806,  1.0075, -0.3450, -1.1414,  0.3937]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1461,  0.7003, -0.0236, -0.5831, -0.0419]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7163,  0.4920,  0.0757, -0.6954, -0.8133]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1470,  0.6745, -0.4319, -0.5498,  0.3683]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0542,  0.5340, -0.3606, -0.1837,  0.1507]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6244,  0.0393, -0.0946, -0.0130, -0.4578]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1638,  0.9962,  0.0893, -1.4307,  0.1277]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0569,  0.5934, -0.2064, -0.6246,  0.1942]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1488,  0.5388, -0.2918, -0.6085,  0.0759]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1930,  0.4005, -0.0277, -0.6527, -0.0982]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0150,  1.1986, -0.0590, -1.4043, -0.1218]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5655,  0.1327, -0.1352, -0.3207, -0.3349]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0085, -0.4952, -0.3593,  0.9846, -0.6622]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2794, -0.1058, -0.4767,  0.5192,  0.1547]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3869,  0.0393, -0.4167,  0.1230,  0.0732]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0810,  0.6634,  0.0543, -1.2074, -0.8984]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3789,  0.2737, -0.0921, -0.4236,  0.5482]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0568,  0.3352,  0.0590, -0.6458,  0.1521]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9283, -0.0620, -0.6552,  0.8087, -0.5796]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7545,  0.3829, -0.2477, -0.2048, -0.6831]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1419,  0.4826, -0.6143, -0.2043,  0.3485]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6448, -0.1749, -0.0950,  0.3905, -0.4960]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4744,  0.3133, -0.3160, -0.0104, -1.3741]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2072,  0.1448, -0.5282,  0.2079,  0.6274]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4291,  0.0103,  0.0257, -0.1986, -0.2907]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3761, -0.3587, -0.3732,  0.9346, -1.1121]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3146,  0.8835, -0.2824, -1.0258,  0.4928]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3609,  0.1317, -0.4527,  0.2214, -0.0057]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2865,  0.4962, -0.1602, -0.6648,  0.4804]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2861,  0.7664, -0.3099, -0.7809,  0.4321]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1205,  0.3558, -0.1740, -0.2970,  0.2130]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3409,  0.4368, -0.0685, -0.5472, -0.2813]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0818,  0.2921, -0.1216, -0.3961,  0.2881]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1890,  0.3702,  0.0672, -0.7373, -0.0794]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5407,  0.5761, -0.2592, -0.5454,  0.6669]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4632,  1.1163, -0.3389, -1.2687,  0.6336]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7985,  0.0722, -0.3861,  0.6725, -0.7337]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8200, -0.3743, -0.4031,  0.9222, -0.5047]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1907,  0.0530, -0.3750,  0.1700, -0.9206]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5456,  0.5527, -0.2806, -0.5676, -0.3651]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9700,  0.3409, -0.0785, -0.4123, -0.8545]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3979,  0.3635, -0.8472, -0.0094,  1.1099]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1920,  0.3154, -0.3396, -0.2040,  0.0762]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4212,  0.7696, -0.1582, -0.7542,  0.3869]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7894, -0.7799, -0.9466,  2.1129, -0.1883]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3022,  0.2040, -0.2191, -0.1591, -0.0743]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9275, -0.2968, -0.4337,  1.0156, -0.6957]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1534,  0.4368, -0.3999, -0.2923,  0.1001]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2024,  0.7714, -0.5648, -0.7434,  0.6372]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3865,  0.4512,  0.2828, -0.6393, -0.6073]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2999,  0.7580,  0.0634, -1.2541,  0.3850]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1216, -0.5959, -0.4664,  1.2213, -0.6649]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4205,  0.2245, -0.5908,  0.2240, -0.0809]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3199,  0.8572, -0.1221, -0.8914, -0.3623]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5684,  0.4932,  0.2989, -0.8309, -0.7794]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1752,  0.5417, -0.1707, -0.5790,  0.2800]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1367,  0.2295, -0.3387, -0.0504,  0.1104]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4630,  0.1725, -0.3121, -0.1665, -0.0924]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1986,  0.9919, -0.3069, -0.9535,  0.2496]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0146,  0.3867, -0.1271, -0.6526,  0.2370]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9075,  0.1155, -0.0309, -0.1660, -0.8282]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1395,  0.2220, -0.3758, -0.0943,  0.4832]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5640,  0.2383,  0.5370, -0.8303, -1.7394]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7209,  0.0136, -0.3608,  0.1190, -0.3473]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3159, -0.1748,  0.3815, -0.2295, -1.2853]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6513,  0.4331, -0.4575, -0.1023, -0.3922]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1100,  0.4817, -0.3635, -0.1044,  0.0224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8586,  0.3803,  0.5570, -0.8192, -1.1760]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0855,  0.9120, -0.2735, -1.3380,  0.4238]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2746,  0.4823, -0.4182, -0.1107, -0.1098]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3454,  0.3105, -0.3992,  0.1281, -0.1595]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6355,  1.0775,  0.6439, -1.9489, -1.0525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3867,  0.5801, -0.3578, -0.5856,  0.6563]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9362,  0.1811, -0.0023, -0.2085, -0.8887]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1430,  0.2113, -0.2564, -0.1892,  0.4656]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1567,  0.2406, -0.0984, -0.2307, -0.0634]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0647,  0.4263, -0.2380, -0.3076,  0.1823]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6253,  0.3021, -0.1473, -0.4495, -0.3551]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8449,  0.8146, -0.2380, -0.6457, -0.8737]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8447,  0.4360,  0.3179, -0.9684, -0.8878]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7857, -0.1474, -0.4676,  0.7482, -0.4951]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2510,  0.4389, -0.2030, -0.3794, -0.1544]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9550,  1.0384, -0.1782, -1.3595,  1.1224]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1671,  0.8494, -0.0548, -0.9953,  0.0766]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0525,  0.4796, -0.3140, -0.5136,  0.3218]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6850,  1.2871, -0.5922, -1.3591,  1.0425]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8868,  0.3365, -0.3083, -0.2438, -0.6404]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4287,  0.3354, -0.4555, -0.0101, -1.1004]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6452,  0.7732, -0.1950, -0.9114,  0.7533]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7303,  0.5414,  0.4029, -1.3347, -0.7692]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2960,  0.1923, -0.2657,  0.0476, -0.1449]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5923, -0.3094, -0.5823,  0.9648, -1.1306]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5258,  0.0297, -0.4625,  0.4665, -0.2361]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7080,  0.0819, -0.3948,  0.3443, -0.5309]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0588,  0.8393,  0.1038, -1.2530, -0.1295]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4650,  0.2365, -0.3201, -0.0595, -0.2294]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7547,  0.0728, -0.3411,  0.3501, -0.6475]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4615,  1.6105, -0.1821, -1.9102,  0.4266]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0381,  0.4861, -0.3119, -0.3778,  0.2080]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3568,  0.4203, -0.1469, -0.5059,  0.5126]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4645,  0.4998, -0.5760, -0.2447, -0.0787]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3804,  0.6629, -0.3484, -0.7689, -0.1338]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1341,  0.1569, -0.1838,  0.0927, -0.0318]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4543,  0.8043, -0.3286, -1.0990,  0.8176]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5743,  0.5891, -0.0370, -0.5480, -0.6372]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4661,  0.4481, -0.6125, -0.0382, -0.1313]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2474,  0.1073, -0.2313, -0.0621,  0.0264]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2926,  0.3252, -0.3402, -0.1432,  0.5558]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4456,  0.0023,  0.3603, -0.0203, -0.7025]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6199,  0.5920, -0.4882, -0.5687,  1.0599]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4570,  0.9691, -0.6364, -0.8117,  0.8150]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7744, -0.0927, -0.5701,  0.7340, -0.4849]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0945,  0.6831, -0.2072, -0.6540, -0.0384]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4390,  0.5458, -0.0942, -0.5208, -0.4777]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0725, -0.0157, -0.6830,  0.8791,  0.2628]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5926,  0.6721,  0.2251, -1.1771, -0.6708]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3790,  0.2820, -0.1834, -0.1146, -0.3340]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8260,  0.1148, -0.2788,  0.1160, -0.6510]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9483, -0.8115, -0.3580,  1.6288, -1.6166]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3524,  0.5864,  0.0267, -0.9426, -0.2831]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1206,  0.7492,  0.0451, -0.9620, -0.0041]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2142,  0.4443,  0.0855, -0.8361, -0.1083]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1117,  0.0709, -0.5231,  0.3482,  0.3003]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2521,  0.4095, -0.4641, -0.1835,  0.5733]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0084,  0.8213, -0.2752, -1.0042,  0.2192]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3211, -0.2264, -0.6928,  0.8897,  0.1888]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0998,  0.4684, -0.3255, -0.4735,  0.2350]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6600,  0.4296, -0.3682, -0.1111, -0.5700]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0680,  0.1367, -0.1472, -0.0556,  0.0488]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0693,  1.1293, -0.2692, -1.1977, -0.0413]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4341,  0.2867, -0.0641, -0.4818, -0.2647]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7445, -0.4223, -0.4999,  1.1925, -0.4006]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7374,  0.2570, -0.1595, -0.2587, -0.5200]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6676,  0.9017, -0.2831, -1.1437,  0.9351]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5073,  0.7833, -0.2224, -0.9674,  0.6860]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2655,  0.1215, -0.4352,  0.1462,  0.0739]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2936,  0.5004, -0.1396, -0.6440,  0.4417]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0362,  0.1562,  0.0109, -0.2059,  0.0935]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0327,  0.4499, -0.2678, -0.3810,  0.1043]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1836,  0.9326,  0.1596, -1.4236,  0.0690]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0425,  0.1941, -0.3196, -0.0013,  0.3057]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4921,  1.6089, -0.0421, -1.8646,  0.2556]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5386,  0.0956, -0.3717,  0.0860, -0.1932]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3963,  0.5789, -0.4403, -0.4888,  0.7104]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6444,  1.1723, -0.2300, -1.2677,  0.6514]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4927,  0.3184, -0.4763,  0.0895, -0.2637]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5013,  0.2650, -0.2341, -0.1438, -0.3255]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1883, -0.0975,  0.0418,  0.3467, -1.2114]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7576,  0.1243, -0.4740,  0.2588, -0.4408]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8547,  0.1073, -0.0214, -0.2401, -0.6793]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9691, -0.0487, -0.2124,  0.2353, -0.7405]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0887,  0.6513, -0.0497, -0.7431,  0.0169]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1665,  0.0985,  0.4553, -0.7178, -1.2326]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0502,  0.6568, -0.4011, -0.7270,  0.3908]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3416,  0.4932,  0.2450, -1.0708, -0.2982]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1411,  0.5426,  0.1117, -0.8619,  0.1093]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1708,  0.0669, -0.6789,  0.5308,  0.2525]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0132,  0.2721, -0.4820, -0.0929,  0.3980]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3158,  0.2057, -0.2556, -0.1230, -0.0404]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1992,  0.5304,  0.0652, -0.7849, -0.1807]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3860,  0.4369, -0.1902, -0.4569,  0.5082]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4864,  1.1888, -0.2446, -1.4377,  0.5925]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1419,  0.4086, -0.2232, -0.4853,  0.3879]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4035,  0.0793, -0.4398,  0.0441,  0.0725]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0633, -0.1471, -0.5658,  0.9005, -0.7774]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2195,  0.9933, -0.2763, -0.9735,  0.2475]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3856,  0.9559, -0.1002, -1.2726,  0.4441]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5473,  0.2744, -0.2141, -0.1792, -0.3587]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0905,  0.6688, -0.0180, -0.7212, -0.2107]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6558, -0.2542, -0.4328,  0.7840, -0.2670]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7272,  0.0816, -0.0272, -0.2242, -0.5774]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8680,  0.0919, -0.0569,  0.1455, -0.9312]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6496,  0.4113, -0.1915, -0.5331, -0.4467]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3068,  0.5075, -0.2593, -0.3375, -0.2541]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1239,  0.7069, -0.3777, -0.5770,  0.1059]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3885,  0.2603, -0.5536,  0.1125,  0.0106]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5056, -0.6260, -0.2700,  1.2845, -1.2806]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7973,  0.4746, -0.1385, -0.2891, -0.8228]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8020,  0.1992, -0.2978,  0.0798, -0.6757]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1642,  0.5156, -0.5956, -0.3402,  0.6137]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6506,  1.1543, -0.3478, -1.5071,  0.9159]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0868,  0.1327, -0.4742,  0.3864,  0.1744]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0577,  0.2042, -0.2972, -0.0266,  0.1428]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3381,  1.8403,  0.2494, -2.0704, -0.9491]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0008,  0.3495, -0.3439, -0.2828,  0.2889]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3779, -0.0707, -0.2889,  0.5938, -1.2516]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2748,  0.4232, -0.4161, -0.2718, -0.0089]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6557,  0.4540, -0.0448, -0.5201, -0.6742]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3373,  0.2288, -0.2782, -0.0359, -0.1485]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1734,  0.5982,  0.0303, -0.8368, -0.1919]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0037,  0.5607, -0.0666, -0.9345,  0.1774]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3069,  0.4494, -0.0849, -0.6397,  0.4857]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3370, -0.3124, -0.5154,  1.1149, -0.0769]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0978,  0.4030,  0.0125, -0.5045, -0.1362]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3135, -0.0898, -0.2369,  0.3909, -0.0838]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2812,  0.5116, -0.5686, -0.2951,  0.1177]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6495,  0.4704, -0.2809, -0.3999, -0.4721]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3499,  0.3131, -0.2692,  0.1014, -0.3260]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1407,  0.4678, -0.5615, -0.2952,  0.2874]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0439,  0.7274, -0.4438, -0.8797,  0.4109]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2411,  0.8990, -0.0970, -1.1209,  0.2344]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5093,  0.9879, -0.2447, -1.2057, -0.3413]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1277,  0.3993, -0.3707, -0.1701,  0.0627]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0097,  0.4312, -0.1664, -0.5930,  0.2167]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9718,  0.3704, -0.4464,  0.1050, -0.8295]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1691,  0.6305, -0.5023, -0.2826,  0.4477]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3220,  0.2316, -0.5272,  0.2187,  0.0099]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1293,  0.7776, -0.2016, -0.9122, -0.0289]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1119,  0.1174, -0.3588,  0.3730, -1.0014]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2046,  0.6675, -0.2590, -0.6869, -0.0348]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2329,  0.2453, -0.4252,  0.0133,  0.0666]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5755,  0.7613,  0.3861, -1.4769, -0.7601]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1510,  0.5665,  0.1076, -1.1084, -0.0207]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4092,  0.7267, -0.2159, -0.7834,  0.5145]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7868,  0.8744, -0.1096, -1.0133,  0.7838]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8598,  0.8774,  0.2449, -1.0792, -1.1424]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2709,  0.5885, -0.0457, -1.0182,  0.4379]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3337,  0.2095, -0.5101,  0.3927, -0.1550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8845, -0.1072, -0.1605,  0.2494, -1.6094]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1758, -0.3021, -0.0574,  0.7251, -1.1270]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0424, -0.0282, -0.5766,  0.5646, -0.6917]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5543,  0.1928, -0.3267,  0.0068, -0.3299]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1663,  0.3674, -0.6040,  0.0362,  0.5415]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0824,  0.0409, -0.1632, -0.0734,  0.2094]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6989,  0.9902, -0.1711, -1.0829,  0.6604]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0053,  0.5121, -0.3669, -0.3787,  0.2832]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5865,  0.8649, -0.1598, -1.1059,  0.7401]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4202, -0.3865, -0.2290,  0.6714, -1.0764]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1468,  0.5015,  0.0882, -0.6856, -0.2153]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1096,  1.0209, -0.4098, -0.7895, -0.0640]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9465,  0.2588,  0.1278, -0.4943, -0.9550]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0654,  0.1036,  0.1607, -0.5309,  0.2394]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4348,  0.2034, -0.2550, -0.2033,  0.7057]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3592, -0.1033, -0.4607,  0.6695, -0.0739]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7261,  0.1805, -0.2844,  0.0788, -0.5635]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4333,  0.2080, -0.4271,  0.1644, -0.2198]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0482,  0.3847, -0.3433, -0.1666,  0.1196]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1039,  0.4583, -0.2302, -0.4578,  0.2727]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "LcfeDi85imYn",
        "outputId": "9955dd9a-5db6-4660-8ecf-c9257045dd20"
      },
      "source": [
        "test1.head(20)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>The film provides some great insight into the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Offers that rare combination of entertainment ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>Perhaps no picture ever made has more literall...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>Steers turns in a snappy screenplay that curls...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>But he somehow pulls it off .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>Take Care of My Cat offers a refreshingly diff...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>This is a film well worth seeing , talking and...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>What really surprises about Wisegirls is its l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>( Wendigo is ) why we go to the cinema : to be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>One of the greatest family-oriented , fantasy-...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>Ultimately , it ponders the reasons we need st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "      <td>An utterly compelling ` who wrote it ' in whic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>Illuminating if overly talky documentary .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4</td>\n",
              "      <td>A masterpiece four years in the making .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3</td>\n",
              "      <td>The movie 's ripe , enrapturing beauty will te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4</td>\n",
              "      <td>Offers a breath of the fresh air of true sophi...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4</td>\n",
              "      <td>A thoughtful , provocative , insistently human...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label                                           sentence pred_label\n",
              "0       2                     Effective but too-tepid biopic          1\n",
              "1       3  If you sometimes like to go to the movies to h...          0\n",
              "2       4  Emerges as something rare , an issue movie tha...          0\n",
              "3       2  The film provides some great insight into the ...          0\n",
              "4       4  Offers that rare combination of entertainment ...          3\n",
              "5       3  Perhaps no picture ever made has more literall...          1\n",
              "6       3  Steers turns in a snappy screenplay that curls...          1\n",
              "7       3                      But he somehow pulls it off .          0\n",
              "8       3  Take Care of My Cat offers a refreshingly diff...          3\n",
              "9       4  This is a film well worth seeing , talking and...          0\n",
              "10      3  What really surprises about Wisegirls is its l...          1\n",
              "11      3  ( Wendigo is ) why we go to the cinema : to be...          0\n",
              "12      4  One of the greatest family-oriented , fantasy-...          0\n",
              "13      2  Ultimately , it ponders the reasons we need st...          1\n",
              "14      3  An utterly compelling ` who wrote it ' in whic...          0\n",
              "15      2         Illuminating if overly talky documentary .          0\n",
              "16      4           A masterpiece four years in the making .          0\n",
              "17      3  The movie 's ripe , enrapturing beauty will te...          0\n",
              "18      4  Offers a breath of the fresh air of true sophi...          3\n",
              "19      4  A thoughtful , provocative , insistently human...          3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_KuECd6lVxq",
        "outputId": "76474f76-c2ce-43b7-ebf5-1a2b2fbd6d64"
      },
      "source": [
        "test1.pred_label.value_counts()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    928\n",
              "1    782\n",
              "3    301\n",
              "4    193\n",
              "2      6\n",
              "Name: pred_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ggBD_nVsIgm",
        "outputId": "2202f4bd-64fa-4b63-f180-2aa1258b902b"
      },
      "source": [
        "test1.label.value_counts()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    633\n",
              "3    510\n",
              "4    399\n",
              "2    389\n",
              "0    279\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anI9SJ-ajycV"
      },
      "source": [
        "test1.to_csv(path+\"result_test.csv\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FVcu2cPkQoF"
      },
      "source": [
        "test_correct =test1[test1['label'] == test1['pred_label']]\n",
        "test_incorrect =test1[(test1.label != test1.pred_label ) ]                  "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYQATniQlOeu"
      },
      "source": [
        ""
      ],
      "execution_count": 98,
      "outputs": []
    }
  ]
}