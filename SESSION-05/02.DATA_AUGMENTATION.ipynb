{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02.DATA_AUGMENTATION.ipynb","provenance":[],"authorship_tag":"ABX9TyO3AnKj6ig7t+SaEyZaZ1hc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"T78hi_kf7A7n"},"source":["# Below are some text augmentation techniques "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nwWUhl0KCVCW"},"source":["### 01.Back Translation\n","\n","Another popular approach for augmenting text datasets is back translation. This involves translating a sentence from our target language into one or more other languages and then translating all of them back to the original language. We can use the Python library googletrans for this purpose. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"4qgBH-SmCVsx","executionInfo":{"status":"ok","timestamp":1622987888188,"user_tz":-330,"elapsed":3035,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"ac8216e4-4c50-4808-ec33-973b9b795a2a"},"source":["!pip install google_trans_new\n","\n","import random\n","import google_trans_new\n","from google_trans_new import google_translator  \n","\n","def back_translation( sentence):\n","    translator = google_translator()\n","\n","    available_langs = list(google_trans_new.LANGUAGES.keys()) \n","    trans_lang = random.choice(available_langs) \n","\n","    translations = translator.translate(sentence, lang_tgt=trans_lang) \n","\n","    translations_en_random = translator.translate(translations, lang_src=trans_lang, lang_tgt='en') \n","\n","    return translations_en_random\n","back_translation(\"The dog hide itself under the rug \")\n","\n","# l=back_translation(\"Quick brown fox jumps over the lazy dog\".split())\n","# \"\".join(l)\n"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: google_trans_new in /usr/local/lib/python3.7/dist-packages (1.1.9)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The dog hides under the carpet '"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"MYeAFLcqglu7"},"source":["### 02.Random Insertion\n","A random insertion technique looks at a sentence and then randomly inserts synonyms of existing non-stopwords into the sentence n times. Assuming you have a way of getting a synonym of a word and a way of eliminating stopwords (common words such as and, it, the, etc.), shown, but not implemented, in this function via get_synonyms() and get_stopwords(), an implementation of this would be as follows:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNevcmQ5iIXp","executionInfo":{"status":"ok","timestamp":1622986525340,"user_tz":-330,"elapsed":948,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"430e8512-aaf1-4c07-9650-d6b7caeba514"},"source":["import nltk \n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"iwaZImbYg_hF","executionInfo":{"status":"ok","timestamp":1622986504724,"user_tz":-330,"elapsed":388,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}}},"source":["def remove_stopwords(sentence):\n","    from nltk.corpus import stopwords\n","    tokenized = sentence #custom_tokenize(sentence) #data['text'].apply(custom_tokenize) # Tokenize tweets\n","    lower_tokens = [t.lower() for t in tokenized] #tokenized.apply(lambda x: [t.lower() for t in x]) # Convert tokens into lower case\n","    alpha_only = [t for t in lower_tokens if t.isalpha()] #lower_tokens.apply(lambda x: [t for t in x if t.isalpha()]) # Remove punctuations\n","    no_stops = [t for t in alpha_only if t not in stopwords.words('english')] #alpha_only.apply(lambda x: [t for t in x if t not in stopwords.words('english')]) # remove stop words\n","\n","    return no_stops\n","\n","def get_synonyms(word):\n","    import nltk\n","    from nltk.corpus import wordnet\n","    synonyms = []\n","      \n","    for syn in wordnet.synsets(word):\n","        for l in syn.lemmas():\n","            synonyms.append(l.name())\n","            # if l.antonyms():\n","            #     antonyms.append(l.antonyms()[0].name())\n","    synonyms = list(set(synonyms))\n","    if len(synonyms) > 0:\n","      new_synonym = random.choice(synonyms)\n","    else:\n","      new_synonym = word\n","\n","    return new_synonym\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6ck8uFGCd2g","executionInfo":{"status":"ok","timestamp":1622986857550,"user_tz":-330,"elapsed":414,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}}},"source":["  def random_insertion(sentence, n): \n","      from random import randrange\n","      words = remove_stopwords(sentence) \n","      if len(words)<=0:\n","        words = sentence\n","      for _ in range(n):\n","          word = random.choice(words)\n","          new_synonym = get_synonyms(word)\n","          sentence.insert(randrange(len(sentence)+1), new_synonym)\n","      return sentence"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"WfgkJGzogqcn","executionInfo":{"status":"ok","timestamp":1622987078125,"user_tz":-330,"elapsed":334,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"921dc1d9-e930-41e6-dc58-dd14d518bfef"},"source":["l=random_insertion(\"Quick brown fox jumps over the lazy dog\".split(),2)\n","\" \".join(l)\n"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'confuse Quick brown fox jumps over the work-shy lazy dog'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"Ylama5F_krhV"},"source":["## 03.Random Deletion\n","As the name suggests, random deletion deletes words from a sentence. Given a probability parameter p, it will go through the sentence and decide whether to delete a word or not based on that random probability. Consider of it as pixel dropouts while treating images."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mmugnLE5ktOl","executionInfo":{"status":"ok","timestamp":1622987343963,"user_tz":-330,"elapsed":11,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"cd6579e1-bf8c-45ca-dd04-ad45b6f6ef2b"},"source":["def random_deletion(words, p=0.5): \n","    if len(words) == 1: # return if single word\n","        return words\n","    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n","    if len(remaining) == 0: # if not left, sample a random word\n","        return [random.choice(words)] \n","    else:\n","        return remaining\n","\n","\n","l=random_deletion(\"Quick brown fox jumps over the lazy dog and dog is happy standing on rug\".split(),p=0.5)\n","\" \".join(l)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'brown over the dog and happy standing on rug'"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"3vl8rldTlg5M"},"source":["### 04.Random Swap\n","The random swap augmentation takes a sentence and then swaps words within it n times, with each iteration working on the previously swapped sentence. Here we sample two random numbers based on the length of the sentence, and then just keep swapping until we hit n."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CnWkD6Cck-3y","executionInfo":{"status":"ok","timestamp":1622987546464,"user_tz":-330,"elapsed":470,"user":{"displayName":"jitendra mishra","photoUrl":"","userId":"12539005625154324635"}},"outputId":"511bb950-dff4-4fd0-8430-2ed461d4cef1"},"source":["def random_swap(sentence, n=5): \n","    length = range(len(sentence)) \n","    for _ in range(n):\n","        idx1, idx2 = random.sample(length, 2)\n","        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n","    return sentence\n","l=random_swap(\"Quick brown fox jumps over the lazy dog\".split(),n=2)\n","\" \".join(l)"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'fox over Quick jumps brown the lazy dog'"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"GSuKKy7VlnQO"},"source":[""],"execution_count":null,"outputs":[]}]}